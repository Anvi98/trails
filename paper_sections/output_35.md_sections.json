[
    {
        "level": "#",
        "title": "Expanding The Resolution Boundary Of Outcome-Based Imperfect-Recall Abstraction In Games With Ordered Signals",
        "content": "\nYanchang Fu1, 2\n                                              fuyanchang2020@ia.ac.cn\nJunge Zhang2\n                                                 jgzhang@nlpr.ia.ac.cn\nDongdong Bai3\n                                              baidongdong@nudt.edu.cn\nLingyun Zhao1, 2\n                                              zhaolingyun2021@ia.ac.cn\nJialu Song1, 2\n                                                songjialu2023@ia.ac.cn\nKaiqi Huang2\u2217\n                                                kqhuang@nlpr.ia.ac.cn\n1 School of Artificial Intelligence, University of Chinese Academy of Sciences, Beijing, China\n2 Center for Research on Intelligent System and Engineering, Institute of Automation, Chinese\nAcademy of Sciences, Beijing, China\n3 China RongTong Artificial Intelligence Research Center, Beijing, China\n"
    },
    {
        "level": "##",
        "title": "Abstract",
        "content": "\nHand abstraction has successfully contributed to the development of powerful AI in Texas Hold'em, a popular testbed for imperfect-information games. However, the hand abstraction task lacks the necessary tools for modeling within the general imperfect-information games framework, impeding not only theoretical study but also guiding algorithm design and evaluation. This paper aims to rigorously mathematically model the hand abstraction task. It then identifies the flaw of excessive abstraction in outcome-based imperfect-recall hand abstraction algorithms and addresses it accordingly. We first refines the games of ordered signals model to enhance its conciseness and expand its descriptive capacity, applying it to model Texas Hold'em-style games. By transitioning to games with ordered signals, infoset abstraction and action abstraction in imperfect-information games are decoupled, allowing for independent study of signal abstraction, which provides a mathematical framework for the hand abstraction task. We introduce potential outcome isomorphism (POI) with the aim of constructing the highest resolution signal abstraction considering future outcomes only, and identify its issue of excessive abstraction. Additionally, a novel common refinement principle is introduced to describe the resolution boundary of signal abstraction algorithms. Futher, We demonstrate that POI serves as a common refinement for leading outcome-based imperfect-recall hand abstraction algorithms, such as E[HS] and PA&PAEMD. Consequently, excessive abstraction also inherently affects these algorithms, leading to suboptimal performance. Finally, a higher-resolution hand abstraction, k-recall outcome isomorphism (KROI), is constructed by considering early-game information.\n\nExperimental results highlight compromised performance of strategies developed through low-resolution signal abstraction. KROI provides a framework to guide the design of higher-resolution outcome-based imperfect-recall abstraction algorithms. Keywords:\ngame theory, imperfect-information games, games with ordered signals, computer poker , automated abstraction, hand abstraction, signal abstraction, imperfect-recall\n\n\u2217. Corresponding author\n"
    },
    {
        "level": "##",
        "title": "1 Introduction",
        "content": "\nIn the realm of artificial intelligence (AI) research, developing competitive AI agent in largescale adversarial imperfect-information games is a pressing and important challenge. Texas Hold'em poker, as a quintessential example of such games, offers an ideal testbed for AI research.\n\nRecent years have witnessed significant advancements in AI within the context of Texas Hold'em poker. Pioneering systems like DeepStack (Morav\u02c7c\u00b4\u0131k et al., 2017), Libratus (Brown and Sandholm, 2018), and Pluribus (Brown and Sandholm, 2019) have demonstrated extraordinary capabilities against professional human players. Much of their success owes to innovative hand abstraction algorithms. These algorithms transform complex hand combinations into simpler, more manageable representative classes, effectively condensing the vast decision space. Such simplification facilitates strategic searches in large-scale games with limited computational resources while maintaining the robustness of the strategies.\n\nTraditionally, Texas Hold'em is modeled as an imperfect-information game, where the task of hand abstraction is categorized as an infoset abstraction task.\n\nThis modeling paradigm is notably expansive, capturing the essence of Texas Hold'em yet not fully encompassing its nuanced complexities. In Texas Hold'em, hands and actions collectively form the foundational elements that define the infoset, with hand abstraction serving as just one facet of the broader concept of infoset abstraction. The task of hand abstraction poses a unique and independent challenge; however, the model of imperfect-information games fails to capture key concepts such as stages, which are essential in the process of hand abstraction. Previous studies have attempted to engineer the task of hand abstraction from various perspectives, yet this task still necessitates a more precise mathematical model for accurate depiction. Gilpin and Sandholm (2007b) proposed a more detailed game modeling method for this specific type of imperfect-information game, termed ordered signal games. This model skillfully applies the concepts of signals and public action sequences to distinctly outline the two independent components of the infoset in Texas Hold'em-style games: hands and action sequences. However, the model's reliance on forests to depict the various game stages contributes to its complexity. Moreover, it is confined to describing scenarios where the signal distribution is governed by a combinatorial model with replacement.\n\nThe first part of this paper aims to provide a mathematical definition of the hand abstraction task. In Section 4, we refine the definition of the games with ordered signals, opting for trees instead of forests to simplify the model, and we generalize the distribution of signals, thereby broadening the applicability of the games with ordered signals model. In Section 5, we formally define the tasks of signal abstraction and action abstraction within the context of games with ordered signals, employing signal abstraction to model the task of hand abstraction.\n\nIn the context of signal abstraction, Gilpin and Sandholm (2007b) developed a lossless abstraction, lossless isomorphism (LI), grounded in the game's rules and showed that the Nash equilibrium of the abstracted game, derived from LI, can be seamlessly mapped back to the Nash equilibrium of the original game. Although LI offers substantial theoretical insights, its practical implementation in artificial intelligence development is constrained by the large scale of the infosets even after abstraction. Currently, in the domain of hand abstraction for Texas Hold'em, imperfect-recall clustering algorithms based on showdown outcomes have achieved success, with systems like DeepStack, Libratus, and Pluribus employing this method. However, this raises a series of questions:\n\n- To what extent can outcome-based imperfect-recall algorithms approximate LI? In\nother words, do these algorithms possess a closer resolution boundary than LI?\n- If so, is it possible to expand the resolution boundary of outcome-based imperfectrecall algorithms?\nIn the second part of this paper, we discuss these questions. Section 6 introduces the concept of potential outcome isomorphism (POI), which aims to construct a signal abstraction based on future showdown outcomes only, striving to identify as many abstracted signal infosets as possible.\n\nIn Section 7, a theoretical tool called Common Refinement is introduced, which is specifically designed to evaluate the resolution boundaries of signal abstraction algorithms. We demonstrate that POI serves as a common refinement for expected hand strength (E[HS]) and potential-aware methods (PA&PAEMD), the dominant outcome-based imperfect-recall signal abstraction algorithms, thereby effectively establishing the resolution boundary for these methods.\n\nFurther, we expose a significant resolution gap between POI and LI, highlighting the issue of excessive abstraction present in current outcome-based imperfect-recall algorithms. In Section 8, we analyze the reasons behind the excessive abstraction, pinpointing the neglect of game history sequences as a key factor. To address this, we developed K-Recall Outcome Isomorphism (KROI) by incorporating the historical information, thereby extending the resolution boundary of outcome-based imperfect-recall algorithms. Experimental results indicate that under the one-player-abstraction-perspective, strategies derived from KROI are almost on par with LI and significantly outperform those derived from POI. Even in scenarios of symmetric abstraction, KROI demonstrates substantial strength, significantly surpassing POI. KROI provides us with a new outcome-based imperfect-recall abstraction framework, from which higher-resolution signal abstraction algorithms can be derived.\n"
    },
    {
        "level": "##",
        "title": "1.1 Related Research",
        "content": "\nOur research is dedicated to hand abstraction techniques in AI systems for Texas Hold'emstyle games, a field originating from the works of Shi and Littman (2001) and Billings et al. (2003). These seminal works introduced the concept of game abstraction, aiming to represent games in simplified forms while preserving essential characteristics. Initially, researchers manually categorized hands based on their experience. The first automated approach to hand abstraction was proposed by Gilpin and Sandholm (2006). Subsequently, Gilpin and Sandholm (2007b) introduced games with ordered signals model for Texas Hold'em and developed LI with signal rotation. Despite the elegance of LI, its low compression rates hinder its application in large-scale games, whereas lossy abstraction shows potential for such application. In their work, Gilpin and Sandholm (2007a) proposed expectation-based clustering method and Gilpin et al. (2007) introduced histogram-based clustering method. The former is known as E[HS], while the latter is referred to as potential-aware method. Subsequent studies by Gilpin and Sandholm (2008) and Johanson et al. (2013) compared E[HS] and potential-aware methods, concluding that the latter holds an advantage in large-scale games. Johanson et al. (2013) also introduced the use of earthmover's distance1 (EMD)\nin Potential-aware methods. Ganzfried and Sandholm (2014) presented a more efficient approximation algorithm for earthmover's distance in potential-aware methods, which has been successfully applied in various Texas Hold'em AI systems, marking it as the SOTA work in the field of hand abstraction.\n\nAnother area of interest concerns the competitiveness of game-solving strategies after abstraction. Waugh et al. (2009b) noted a non-monotonic relationship between the exploitability of Nash equilibrium in abstracted games and the refinement level of abstraction profiles, a phenomenon termed as abstraction pathology. In a pioneering effort, Sandholm and Singh (2012) developed the first lossy abstraction algorithm that establishes bounds on solution quality for stochastic games. Following this, Kroer and Sandholm (2014) introduced lossy abstraction with quality bounds in general perfect-recall extensive-form games. In practical scenarios, simplified methods with imperfect-recall demonstrate heightened competitiveness, as introduced by Waugh et al. (2009c). Additionally, Lanctot et al. (2012) and Kroer and Sandholm (2016) tailored abstraction algorithms for imperfect-recall extensive-form games under varied conditions, alongside establishing associated solution quality bounds. Essentially, Kroer and Sandholm (2018) unified this collection of research efforts into a cohesive framework while maintaining comparable bounds on solution quality.\n"
    },
    {
        "level": "##",
        "title": "2 Preliminary 2.1 Texas Hold'Em-Style Poker Games",
        "content": "\nTexas Hold'em, a globally popular multiplayer card game, has gained significant prominence in the fields of game theory and artificial intelligence, particularly in Heads-up No-Limit Hold'em (HUNL) variant, which has become a focal point of research. The game of Texas Hold'em unfolds in up to four stages: Preflop, Flop, Turn, and River. At the beginning of each stage, the dealer, representing elements of randomness, draws a specific number of cards from the deck. During the Preflop stage, the dealer distributes two private cards to each player from a standard poker deck, excluding jokers. Subsequently, in the Flop stage, the dealer reveals three community cards from the remaining deck. In the Turn and River stages, one additional community card is revealed in each. Players have the option to raise/bet, call/check, or fold during their turn. If at any point only one player remains, they win all the chips. If multiple players are still present at the end of the River stage without further raises, the pot is allocated based on each player's betting and the best five-card combination that can be made from his two private cards and the five community cards.\n\nStandard Texas Hold'em, even in Heads-up Limit Hold'em (HULHE) variant, encompasses a vast decision space.\n\nTo facilitate research, various simplified games have also garnered academic interest, collectively known as Texas Hold'em-style games. For instance, Kuhn Poker (Kuhn, 1950), Leduc Hold'em (Waugh et al., 2009a) and Rhode Island Hold'em (Shi and Littman, 2001) are variants of Texas Hold'em-style games, which employ fewer cards and more streamlined decision-making stages, thereby simplifying the complexity of the game while retaining the core elements. In the experimental section, we introduce Numeral211 Hold'em, a simplified game that closely simulates standard Texas Hold'em with more stages and cards. For details, see Appendix D.\n"
    },
    {
        "level": "##",
        "title": "2.2 Imperfect-Information Games",
        "content": "\nTexas Hold'em-style games are often described using the model of imperfect-information games, the mathematical specifics of which are detailed in Appendix A. These games involve complex decision-making processes where players may not have complete knowledge of the overall state of the game. In such games, each player, denoted as i, makes decisions at nonterminal nodes h in the game, leading to either a terminal node z or another non-terminal node. Each non-terminal node is associated with a specific set of actions \u03c7(h), and the progression of the game can be influenced by random events controlled by a special player, nature c, also called the chance palyer. At terminal nodes z, each player receives a specific payoff ui(z). A key concept in imperfect-information games is the infoset I, representing the different game nodes indistinguishable to a certain player. Players maintain consistent decision preferences across the nodes within an infoset. The decision preferences of player i across all infosets constitute his strategy \u03c3i, and the strategies of all players form a strategy profile \u03c3. The (behavioral) strategy profile influences the probability of reaching each node, whether a non-terminal node h or a terminal node z, denoted as \u03c0\u03c3(h) for non-terminal nodes and \u03c0\u03c3(z) for terminal nodes. This, in turn, affects the expected payoff for player i in the game, which is calculated as vi(\u03c3) = \ufffd\nz\u2208Z \u03c0\u03c3(z)ui(z). In imperfect-information games, each player aims to maximize his expected payoff.\n\nThe solution to an imperfect-information game involves finding a strategy profile \u03c3\u2217\nthat is known as a Nash equilibrium (Nash, 1951; Harsanyi, 1995). In a Nash equilibrium, no player can gain additional payoff by unilaterally changing their strategy. Each player's strategy is the best response to the strategies of others, that is, vi(\u03c3\u2217) = max\u03c3i\u2208\u03a3i vi(\u03c3i, \u03c3\u2217\n\u2212i), where \u03c3\u2212i represents the strategy profile of all players other than i within the strategy profile \u03c3. In imperfect-information games, identifying a Nash equilibrium is crucial as it allows players to make optimal decisions amidst uncertainty. To some extent, the Nash equilibrium embodies the optimal solution in these games, especially in the context of twoplayer scenarios with imperfect-information.\n"
    },
    {
        "level": "##",
        "title": "2.3 Current Paradigm For Solving Large-Scale Imperfect-Information Games.",
        "content": "\nIn the field of computational game theory, a widely adopted paradigm for solving largescale imperfect-information games involves the abstraction of original games into simplified versions by classifying similar states (Sandholm, 2010), as illustrated in Figure 1. This process reduces complexity and facilitates the identification of a Nash equilibrium in the abstracted game, which is then applied back to the original game in hopes of deriving competitive strategies. Typically, the equilibrium found in the abstracted game is expected to closely approximate the Nash equilibrium of the original game. However, this approach has its limitations, one of the main concerns being the **abstraction pathology** (Waugh et al., 2009b), where the degree of abstraction between the original and the abstracted game does not always correlate monotonically with the distance in their respective Nash equilibrium. This can lead to unpredictable outcomes when applying the equilibrium from the abstracted game to the original one.\n\nDespite these theoretical limitations, this paradigm has proven highly effective in practical applications. For instance, in HUNL, computer programs developed using this approach have surpassed human experts (Brown and Sandholm, 2018, 2019).\n\nHence, this problem-solving paradigm has become a popular and powerful tool in addressing large-scale imperfect-information games.\n\nTwo simplification approaches are often employed: infoset abstraction and action abstraction. Detailed mathematical definitions can be found in the Appendix B. Infoset abstraction involves partitioning each player's infoset space into several abstracted infosets, each of which contains similar infosets. This partitioning allows players to treat infosets on the simplified level as equivalent, ensuring consistent decision preferences on abstracted infosets.\n\nOn the other hand, action abstraction focuses on simplifying the action space within the game.\n\nEach player has a set of possible actions at non-terminal nodes, and action abstraction involves dividing this action set into similar action groups. Then, one action is sampled from each action group to form a abstracted action set. For the same abstracted infoset, players have access to the same abstracted action set. Infoset abstraction and action abstraction collectively work to reduce the size and complexity of the game tree.\n"
    },
    {
        "level": "##",
        "title": "3 Imperfect-Recall Games And Abstraction",
        "content": "\nPerfect/imperfect-recall are a pair of characteristics in imperfect-information games.\n\nIf all players in the game can remember any information they observe during the game, the game is said to have perfect-recall; otherwise, it is said to have imperfect-recall.\n\nFor a detailed description of this concepts, please refer to Appendix C. Perfect-recall games have several advantages (Kuhn, 1953), with the most important being that the existence of Nash equilibrium is ensured when using behavioral strategies, which are a form of strategy with smaller space cost. However, in practical situations, even if the game does not have perfectrecall, researchers typically use behavioral strategies for strategy solving (Lanctot et al., 2012; Kroer and Sandholm, 2016).\n\nWhen perfect/imperfect-recall is used to describe abstraction, it refers to whether the abstracted game has perfect/imperfect-recall. However, despite the term imperfect-recall means that players are allowed to forget some memories, in practice, the imperfect-recall abstraction is often used in a more extreme way: requiring players to not retain any memory and make decisions based on future information only (Waugh et al., 2009c; Johanson et al., 2013; Ganzfried and Sandholm, 2014).\n"
    },
    {
        "level": "##",
        "title": "4 Games With Ordered Signals",
        "content": "\nIn imperfect-information games, directly conducting infoset abstraction and action abstraction can be a challenging task. This is because, in the process of infoset abstraction, one must first identify infosets that can be merged, and these infosets must share the same action space. Furthermore, not all infosets with identical action spaces can be combined into the same abstracted infoset. In HUNL, for instance, when the first player in both the Flop and Turn stages faces the same chip pot, their action spaces are identical. However, due to the difference in game stages, it is not suitable to merge these two infosets into the same abstracted infoset.\n\nIn practical development of Texas Hold'em AI, we do not simplify the game directly through infoset abstraction and action abstraction. Instead, we consider simplification in two dimensions: hand abstraction and action abstraction. This approach is favored because Texas Hold'em belongs to a special category of imperfect-information games where the description of infosets can be divided into two unrelated dimensions: hands and the action sequences. By focusing on hand abstraction, we can streamline the process of infoset abstraction, allowing us to merge infosets that share the same action sequence. The modeling of this class of games, known as **games with ordered signals**, was first introduced by Gilpin and Sandholm (2007b).\n\nThe original definition of games with ordered signals is somewhat complex. It defines branches at different stages as trees and uses a forest to describe the entire game, involving a significant amount of node mapping. Additionally, its definition of signals is solely based on a combinatorial model without replacement. However, games with ordered signals have the potential for broader applicability. For instance, games similar to Texas Hold'em, such as Liar's Dice (Freeman, 1989), exhibit significant similarities. Still, due to the distinct nature of signals (with or without replacement), they cannot be modeled using games with ordered signals. In this section, we've refined the definition of games with ordered signals for greater clarity and versatility in modeling. We've employed this framework to model Texas Hold'em-style games in this paper. Subsequently, our focus in the upcoming sections will be on studying abstraction techniques within this framework.\n\nDefinition 1 *A game with ordered signals* \u02dc\u0393 =\n\ufffd\n\u02dc\nN, \u02dcH, \u02dcZ, \u02dc\u03c1, \u02dcA, \u02dc\u03c7, \u02dc\u03c4, \u03b3, \u0398, \u03c2, O, \u03c9, \u2ab0, \u02dcu\n\ufffd\nis a structured tuple, where \u02dc\nN is the extended player set, \u02dcH is the set of non-terminal public nodes, \u02dcZ is the set of terminal public nodes, \u02dc\u03c1 is the player function, \u02dcA is the action set, \u02dc\u03c7\nis the action mapping function, \u02dc\u03c4 is the successor function, \u03b3 is the stage function, \u0398 is the signal set, \u03c2 is the signal revelation function, O is the observation function vector, \u03c9 is the survival status function vector, \u2ab0 is the signal partial order function, and \u02dcu is the utility function vector. In more detail:\n\n\u2022\n\u02dc\nN = N \u222a {c, pub}, where N = {1, ..., N} represents the set of players, c denotes the\nnature player, and pub is defined as a special observer player who does not participate\nin game actions but has access to information available to all players. For simplicity,\nwe define Nc = N \u222a {c} and Npub = N \u222a {pub}.\n- \u02dc\u03c1 : \u02dcH \ufffd\u2192 Nc assigns each non-terminal public node to the unique extented player able\nto take actions at that non-terminal public node.\n- \u02dcX = \u02dcH \u222a \u02dcZ comprises the set of public nodes. Specifically:\n- \u02dcxo \u2208 \u02dcX is identified as the initial public node of the game.\n- \u02dcHi =\n\ufffd\n\u02dch \u2208 \u02dcH|\u02dc\u03c1(\u02dch) = i\n\ufffd\ndenotes the set of non-terminal public nodes where\nplayer i is the action player, and these non-terminal public nodes where nature acts are termed chance public nodes.\n- \u02dc\u03c7 :\n\u02dcH \ufffd\u2192 2 \u02dc\nA maps each non-terminal public node to its possible set of actions.\nSpecifically, for chance public nodes, the action set is exclusively {Reveal}, where\nReveal \u2208 \u02dcA is the sole virtual action nature performs to disclose signals.\n- \u02dc\u03c4 : \u02dcH \u00d7 \u02dcA \ufffd\u2192 \u02dcX illustrates the transition to a new public node upon taking action\n\u02dca \u2208 \u02dc\u03c7(\u02dch) at non-terminal public node \u02dch \u2208 \u02dcH, with each public node following a unique\ntransition path. That is, if \u02dc\u03c4(\u02dch1, \u02dca1) = \u02dc\u03c4(\u02dch2, \u02dca2), then it implies \u02dch1 = \u02dch2 *and* \u02dca1 = \u02dca2.\n- \u03b3 : \u02dcX \ufffd\u2192 N+ assigns to each public node \u02dcx the number of chance public nodes encountered from the initial public node \u02dcxo to \u02dcx, defined as the stage of \u02dcx. Notably, the stage\nof every public node is at least 1, indicating that the initial public node is a chance public node.\n- Each element within \u0398 corresponds to a signal revealed by nature at chance public\nnodes.\n- \u03c2 : \u0398 \ufffd\u2192 \u2206(\u0398) specifies the probability distribution for the next signal given the current\nsignal \u03b8, with \u03c2(\u03b8\u2032|\u03b8) representing the likelihood of revealing \u03b8\u2032 following \u03b8.\n- O = (O1, ..., ON, Opub), where Oi(\u03b8) denotes the observation made by player i \u2208 Npub\non the signal \u03b8 \u2208 \u0398.\n- \u03c9 = (\u03c91, ..., \u03c9N), where \u03c9i : \u02dcZ \ufffd\u2192 {true, false} indicates whether player i remains in\nthe game at terminal public nodes, with true signifying active participation and false\nindicating elimination.\n- \u2ab0: \u02dc\u0398 \u00d7 N \u00d7 N \ufffd\u2192 {true, false} serves as a partial order function, where the terminal\nsignal set \u02dc\u0398 is a subset of \u0398. \u2ab0 (*\u03b8, i, j*) = true suggests player i is at least as preferred\nas player j on signal \u03b8; \u2ab0 (*\u03b8, i, j*) = false means the opposite, indicating player i is\nless preferred.\n- u = (u1, ..., uN)*, where* ui : \u0398\u00d7 \u02dcZ \ufffd\u2192 R, represents the utility function of player i \u2208 N,\nwhich specifies the payoff obtained by player i at terminal public node \u02dcz \u2208 \u02dcZ with the\nsignal \u03b8 \u2208 \u0398. It is required that for any terminal signal \u03b8 \u2208 \u02dc\u0398 and \u02dcz \u2208 {\u02dcz\u2032 \u2208 \u02dcZ |\n\u03c9i(\u02dcz\u2032) = \u03c9j(\u02dcz\u2032) = true}, if \u2ab0 (*\u03b8, i, j*) = true, then ui(\u03b8, \u02dcz) \u2265 uj(\u03b8, \u02dcz).\nFigure 2 illustrates the game tree with ordered signal for Leduc Hold'em. According to rules of Leduc Hold'em rules, see Appendix D.1, all subtrees rooted at chance public nodes in the second stage are identical. For the sake of simplicity in visualization, we represent the Leduc game tree as a forest of two trees. However, it is worth noting that the game with ordered signals model defined in Definition 1 is a complete tree. We can concatenate a subtree from the first stage with five subtrees from the second stage to form the complete Leduc game tree. It is important to distinguish between two types of terminal public nodes.\n\nWhen \u02dcz is a terminal public node with fold, it implies \ufffdN\ni=1 \u03c9i(\u02dcz) = 1, indicating that only one player remains in the game. On the other hand, when \u02dcz is a terminal public node with showdown, it means that more than one player is still participating in the game, and their payoffs need to be determined through a showdown. In Leduc Hold'em, Rhode Island Hold'em, HULHE, HUNL, and the Numeral211 Hold'em introduced in the experimental section, all terminal public nodes with fold are located in the final stage. Meanwhile, the signal set is solely dependent on the stage, implying that the terminal signal set \u02dc\u0398 in these games corresponds exclusively to the signal set of the final stage. Unlike the definition in Gilpin and Sandholm (2007b), signals in Leduc Hold'em, as defined in Definition 1, refer to the complete set of cards currently dealt. For example, JQ in the first stage (the first player dealt a J, the second player dealt a Q) and JQK in the second stage (the first player dealt a J, the second player dealt a Q, and the community card is K) are signals in their respective stages. In the case of JQK in the second stage, the cards dealt to each player and the individual community card are observations of the signal from their respective perspectives.\n\n\u03d11(\u03b8) = J*K \u03d12(\u03b8) = Q*K \u03d1pub(\u03b8) = **K .\nThat is, if \u03b8 = JQK, then\n\uf8f1 \uf8f2\n\n\uf8f3\nWe can define other games with ordered signals where signal unveiling follows various probability distributions, not just the model of sampling without replacement, as we are familiar with.\n\nGiven a signal \u03b8 and a player i \u2208 N, we can define the signal infoset that player i cannot distinguish related to \u03b8 as \u03d1i(\u03b8) = {\u03b8\u2032 \u2208 \u0398 | Oi(\u03b8) = Oi(\u03b8\u2032) \u2227 Opub(\u03b8) = Opub(\u03b8\u2032)}.\n\nFor example, in Figure 2, JJQ and JQJ belong to the same signal infoset for player 1.\n\nAdditionally, the concept of a signal infoset space \u0398 = (\u03981, . . . , \u0398N, \u0398c) is introduced, where \u0398i = {\u03d1i(\u03b8)|\u03b8 \u2208 \u0398} denotes the collection of signal infosets pertinent to player i. A\ngame with ordered signals is a special type of imperfect-information game. We can transform a game with ordered signals into an imperfect-information game, a process illustrated in Appendix E.\n\nCompared to the definition of games with ordered signals introduced by Gilpin and Sandholm (2007b), Definition 1 is more generalized and concise. Specifically:\n\n1. **The definition of stages is more flexible.** In the original definition, stages were\npredefined non-negative integers.\nIn Definition 1, stages are defined based on the\nnumber of chance public nodes along a path. This allows games with ordered signals to be treated as a single tree structure, eliminating the need to split them into a forest based on chance public nodes.\n2. **The revelation of signals is more versatile.** In the original definition, signal\nrevelation involved combinatorial model without replacement. In Definition 1, the revelation of signals can follow any arbitrary random distribution.\nFurthermore, we have also adjusted the way signal orders are defined. In the original definition, signal orders reflected the dominance relationships between each player's signal observations. In the current definition, signal orders refer to the dominance relationships of players over a signal. This change brings several benefits, one of which is the ability to statistically compute the dominance probabilities of each player over the signal infoset. Combined with the survival functions, this makes the constraints on the payoffs of each player in games with ordered signals more specific and clear.\n"
    },
    {
        "level": "##",
        "title": "5 Abstraction For Games With Ordered Signals",
        "content": "\nThe model of games with ordered signals divides the description of nodes in imperfectinformation games into two dimensions: the signals and the public nodes. Correspondingly, it categorizes the description of infosets in imperfect-information games into signal infosets and public nodes. The infosets in an imperfect-information game that can be traced back to a common public node will have the same action space and action history sequence. As long as the signal infosets are suitable for merging together, their corresponding infosets should also be suitable for merging into the same abstracted infoset. The game with ordered signals simplifies the process of infosets abstraction in imperfect-information games, eliminating the need for pre-filtering infosets. This also implies that infosets at the same stage will have consistent abstraction results based on the signal infosets abstraction. In other words, if \u03d11\ni and \u03d12\ni are two r-stage signal infosets for player i and can be grouped into the same abstracted signal infoset during a abstraction process, then for any public node\n\u02dchi corresponding to player i in the r-stage, the infoset related to \u02dchi and \u03d11\ni will always be classified into the same abstracted infoset as the one related to \u02dchi and \u03d12\ni . This simplifies the workload of infoset abstraction, even though it sacrifices some flexibility in infosets abstraction, this constraint is reasonable. We introduce the following definition to provide a clearer description of the abstraction process in games with ordered signals:\nDefinition 2 *In games with ordered signals,* \u02dc\u03b1 = (\u02dc\u03b11, ..., \u02dc\u03b1N) is referred to as an abstraction profile. For player i*, the abstraction* \u02dc\u03b1i =\n\ufffd\n\u02dc\u03b1\u0398\ni , \u02dc\u03b1\u02dc\u03c7\ni\n\ufffd\nconsists of two components:\n\n- \u02dc\u03b1\u0398\ni\nis a partition of \u0398, known as the signal (infoset) abstraction. For any \u02c6\u03d1 \u2208 \u02dc\u03b1\u0398\ni ,\nreferred to as an abstracted signal infoset, we can identify several signal infosets within\n\u0398i, and these signal infosets collectively form a partition of \u02c6\u03d1.\n- \u02dc\u03b1\u02dc\u03c7\ni is a function defined on \u02dcHi, known as the (public) action abstraction. \u02dc\u03b1\u02dc\u03c7\ni (\u02dch) \u2286 \u02dc\u03c7(\u02dch)\nrepresents the abstracted (public) action set for non-terminal public node \u02dch \u2208 \u02dcHi.\nThe **null abstraction** for player i is defined as \u03d5i = \u27e8\u0398i, \u02dc\u03c7\u27e9. The abstracted game \u02dc\u0393\u02dc\u03b1\nwas derived by substituting \u0398i with \u02dc\u03b1\u0398\ni and \u02dc\u03c7(\u02dch) with \u02dc\u03b1\u02dc\u03c7\n\u02dc\u03c1(\u02dch)(\u02dch) across all \u02dch \u2208 \ufffd\ni\u2208N \u02dcHi. This process highlights how, in games with ordered signals, the abstractions of signals and actions can be dissected and analyzed independently. To this end, we introduce \u02dc\u03b1\u0398 = (\u02dc\u03b1\u0398\n1 , ..., \u02dc\u03b1\u0398\nN)\nas the signal abstraction profile and \u02dc\u03b1\u02dc\u03c7 = (\u02dc\u03b1\u02dc\u03c7\n1, ..., \u02dc\u03b1\u02dc\u03c7\nN) as the action abstraction profile.\n\nConsequently, \u02dc\u0393\u02dc\u03b1\u0398 and \u02dc\u0393\u02dc\u03b1\u02dc\u03c7 represent the signal abstracted game and the action abstracted game, respectively.\n\nIn a game with ordered signals, the performance of different abstractions is typically assessed through experimental validation, as there currently lacks a theoretical method for directly analyzing the performance of two abstractions. However, when two abstractions exhibit a refinement relationship, we can discuss their performance in such cases.\n\nDefinition 3 In a game with ordered signals, consider \u02dc\u03b1i and \u02dc\u03b2i as abstractions for player i. We define the following refinement relationships:\n\n- If, for any \u02c6\u03d1 \u2208 \u02dc\u03b2\u0398\ni , there exist one or more abstracted signal infosets on \u02dc\u03b1\u0398\ni , such\nthat their collection forms a partition of \u02c6\u03d1, then we say \u02dc\u03b1\u0398\ni\nrefines \u02dc\u03b2\u0398\ni , denoted as\n\u02dc\u03b1\u0398\ni \u2292 \u02dc\u03b2\u0398\ni .\n- If, for any \u02dch \u2208 \u02dcHi, it holds that \u02dc\u03b2 \u02dc\u03c7\ni (\u02dch) \u2286 \u02dc\u03b1\u02dc\u03c7\ni (\u02dch), then we say \u02dc\u03b1\u02dc\u03c7\ni refines \u02dc\u03b2 \u02dc\u03c7\ni , denoted\nas \u02dc\u03b1\u02dc\u03c7\ni \u2292 \u02dc\u03b2 \u02dc\u03c7\ni .\n- If \u02dc\u03b1\u0398\ni \u2292 \u02dc\u03b2\u0398\ni\nand \u02dc\u03b1\u02dc\u03c7\ni \u2292 \u02dc\u03b2 \u02dc\u03c7\ni , then we say \u02dc\u03b1i refines \u02dc\u03b2i, denoted as \u02dc\u03b1i \u2292 \u02dc\u03b2i.\nIntuitively, one might expect that more refined abstractions would result in superior strategies. However, the discovery of abstraction pathology refutes this notion.2 It is crucial to stress that the issue of abstraction pathology arises from abstracting the opponent's decision space, essentially modeling the opponent's behavior based on a fundamental assumption: that the opponent exclusively acts within the defined abstracted decision space. However, this assumption may not always hold true. A more reasonable perspective called one-player-abstraction-perspective is that players make decisions within the abstracted decision space as a simplification to adapt to the opponent's decisions in the complete decision space. The study conducted by Waugh et al. (2009b) demonstrated that when the opponent's decision space is not abstracted, increasing the precision of one's own abstraction can lead to reduced exploitability of the abstracted Nash equilibrium solution in the original game.3\nIn the subsequent sections, we will focus on the task of signal abstraction and the algorithms associated with it.\n\nThe signal abstraction task aims to find suitable signal abstraction within a given game with ordered signals, while the signal abstraction algorithm serves as the method to accomplish this goal.\n\nAlthough the task of signal abstraction in games with ordered signals were not explicitly defined in prior research, earlier studies employed various rudimentary terms to describe similar problems and methods. This was particularly evident in tasks such as hand abstraction in the domain of Texas Hold'em game. For instance, Shi and Littman (2001) referred to it as **bins**, Billings et al. (2003) as **buckets**, Johanson et al. (2013) mentioned state-space abstraction, and Gilpin and Sandholm (2007b) used the term **signals** to describe analogous concepts. Building upon these analogous descriptions of signal abstraction tasks, numerous approaches have been proposed to solve it. Among them, Gilpin and Sandholm (2007b) and Waugh (2013) developed **lossless isomorphism** (LI), Johanson (2007) introduced the **expected hand strength** (E[HS]) algorithm, while Gilpin et al. (2007); Gilpin and Sandholm (2008) introduced the **potential-aware** (PA) algorithm, which later led to the derivation of the potential-aware based on the earthmover's distance (PAEMD) algorithm introduced by Ganzfried and Sandholm (2014). Our definition of the signal abstraction task has been significantly influenced by the work of Gilpin and Sandholm\n(2007b) and is also more closely aligned with the essence of the hand abstraction task in Texas Hold'em-style game.\n"
    },
    {
        "level": "##",
        "title": "6 Potential Outcome Isomorphism",
        "content": "\nIn some games with ordered signals, the game rules establish equivalence among certain signal infosets. For example, consider Texas Hold'em poker, where a deck of cards comprises\n\nsignals.\nfour suits, and the strength of a hand remains unchanged when only the suits are rotated.\n\nThe hand [\u2660A, \u2661A|\u26633, \u26635, \u2662Q, \u2662K, \u2662T] holds the same strength as [\u2663A, \u2660A|\u26623, \u26625, \u2661Q,\n\u2661K, \u2661T]; this property is known as **suit-insensitivity**. LI serves as a signal abstraction, aiming to eliminate such redundancy.\n\nHowever, in standard Texas Hold'em poker, the quantity of abstracted signal infosets in LI remains quite large, reaching the dimension of\n109, and the differentiation between abstracted signal infosets cannot be quantified, thereby impeding further reduction of the scale of abstracted signal infosets through techniques such as clustering. These limitations constrain the application of LI in AI development.\n\nIn game theory, calculating the expected payoff at each node relies on the utility backpropagated from the terminal nodes. Consequently, mainstream signal abstraction algorithms cluster signals based on the showdown outcomes in the terminal stage, such as E[HS], PA, and PAEMD. These algorithms are referred to as outcome-based imperfect-recall algorithms. They possess the flexibility to adjust the scale of abstracted infosets. Our inquiry pertains to the resolution boundary, which refers to the quantity of signal infosets that the algorithm can recognize without exceeding, of such outcome-based imperfect-recall signal abstraction algorithms and whether they can achieve LI. The objective of this section is to develop a signal abstraction, termed as potential outcome isomorphism (POI), which aims to identify as many abstracted signal infosets as possible based on future showdown outcomes only. In the next section, we will elucidate why the POI can represent the resolution boundary of outcome-based imperfect-recall algorithms.\n\nThe construction of POI, as shown in Algorithm 1, is described as follows. The algorithm begins at the last stage, r = |r|, where r = {r = \u03b3(\u02dcx) | \u02dcx \u2208 \u02dcX}, and proceeds bottom-up, computing each stage down to r = 1. For any player i and signal information set \u03d1 at stage r, we construct a potential outcome feature f(r)\ni\n(\u03d1). These feature vectors consist of natural numbers and have varying dimensions across stages but remain consistent within the same stage.\n\nAfter removing duplicates from the potential outcome features of all signal infosets for player i at stage r, we form a set denoted as C(r)\ni\n. Upon sorting the potential outcome features in C(r)\ni in lexicographical order, a unique lexicographical identifier in the range of\n0 to |C(r)\ni\n| \u2212 1 is assigned to each potential outcome feature f(r)\ni\n. This identifier is referred to as the lexicographical order identifier (*lexid*) for f(r)\ni\n. If two signal information sets, \u03d11\nand \u03d12, in \u0398(r)\ni share the same potential outcome feature f(r)\ni\n, they are categorized as the same abstracted signal infoset.\n\nFor player i at the last stage, r = |r|, the potential outcome feature for a signal infoset\n\u03d1 \u2208 \u0398(r)\ni is defined as\n\n$$f_{i}^{(r)}(\\vartheta)=(f_{i}^{(r),0}(\\vartheta),f_{i}^{(r),1}(\\vartheta),\\ldots,f_{i}^{(r),N}(\\vartheta)),\\tag{1}$$\nwhere each component is calculated as follows\n\n$$f_{i}^{(r),l}(\\theta)=\\left\\{\\begin{array}{ll}\\sum\\limits_{\\theta\\in\\Theta}\\mathds{1}\\left\\{\\exists j\\neq i,\\succeq(\\theta,i,j)=\\text{False and}\\succeq(\\theta,j,i)=\\text{True}\\right\\}&\\text{if}l=0,\\\\ \\sum\\limits_{\\theta\\in\\Theta}\\mathds{1}\\left\\{\\sum\\limits_{j\\neq i}\\mathds{1}\\left\\{\\succeq(\\theta,j,i)=\\text{True}\\right\\}=l\\text{and}\\forall j\\neq i,\\succeq(\\theta,i,j)=\\text{True}\\right\\}&\\text{if}l\\neq0.\\end{array}\\right.$$\n\nWhere\nAlgorithm 1 Potential outcome isomorphism Require:\nr \u2208 {1*, . . . ,* |r|}. Stages.\n\n\u0398(r)\ni . Signal infoset space.\n\nIndexi(r, \u00b7) : \u0398(r)\ni\n\ufffd\u2192 N. Signal infoset index function.\n\nD(r+1)\ni\n: N \ufffd\u2192 N. Next stage potential outcome isomorphism map, if r = |r|, D(r+1)\ni\n= \u2205.\n\n1: **procedure** StagePotentialOutcomeIsomorphism(r, \u0398(r)\ni , D(r+1)\ni\n)\n\n2:\nInitialize C(r)\ni\nvector as empty.\n3:\nInitialize D(r)\ni\narray arbitrarily with length |\u0398(r)\ni |.\n4:\nfor \u03d1 \u2208 \u0398(r)\ni\ndo\n5:\nfeature \u2190 f(r)\ni\n(\u03d1).\n6:\nAppend *feature* to C(r)\ni\n.\n7:\nend for\n8:\nEliminate duplicates from C(r)\ni\n.\n9:\nSort the elements of C(r)\ni\nin lexicographical order.\n10:\nConstruct hash table CI(r)\ni\nfrom C(r)\ni\n. Store the index *lexid* and value *feature* of\nC(r)\ni\nin CI(r)\ni\nas key-value pairs (*feature, lexid*).\n11:\nfor \u03d1 \u2208 \u0398(r)\ni\ndo\n12:\nfeature \u2190 f(r)\ni\n(\u03d1).\n13:\nidx \u2190 Indexi(*r, \u03d1*).\n14:\nUpdate D(r)\ni [idx] with CI(r)\ni [*feature*].\n15:\nend for\n16:\nreturn D(r)\ni .\n17: end procedure\n- f(r),0\ni\n(\u03d1) represents the number of signals in \u03d1 where player i is ranked lower than at\nleast one other player.\n- f(r),l\ni\n(\u03d1) represents the number of signals in \u03d1 where player i is ranked no less than\nall other players and is ranked exactly l times higher than the other players.\nSpecifically, for a two-player game with ordered signals at the last stage, r = |r|, the feature vector has a dimension of 3. In this case, f(r),0\ni\n(\u03d1) denotes the number of signals in \u03d1 where player i is ranked lower than the opponent, f(r),1\ni\n(\u03d1) denotes the number of signals where player i is ranked equally with the opponent, and f(r),2\ni\n(\u03d1) denotes the number of signals where player i is ranked higher than the opponent.\n\nThe potential outcome feature of player i for the signal infoset \u03d1 at stage *r <* |r| represents the histogram distribution of possible abstracted signal infosets that it can transition to in the next stage. Due to the potentially large size of C(r+1), a histogram distribution with a length of |Cr+1| can incur significant computational overhead. Fortunately, in games like Texas Hold'em, we can simplify this data structure. D = {0, . . . , |D| \u2212 1} represents a deck of cards. In each game stage, the dealer sequentially deals a certain number of community and private cards from this deck without replacement. We define U = (U1*, . . . ,* U|r|) as a vector indicating the number of community cards dealt in each stage of a single game, and K = (K1*, . . . ,* K|r|) as a vector indicating the number of private cards dealt to each player in each stage of a single game. Additionally, we use \u03c5 = (\u03c51*, . . . , \u03c5*|r|) to denote the vector of community cards dealt in a single game, where |\u03c5r| = Ur. The private cards received by player i in a single game are represented by \u03bai = (\u03ba1\ni , . . . , \u03ba|r|\ni ), where |\u03bar i | = Kr. In the r-th stage, a signal \u03b8 can be described by the vector (\u03c51, . . . , \u03c5r, \u03ba1\n1, . . . , \u03bar\n1*, . . . , \u03ba*1\nN, . . . , \u03bar N), and the signal infoset \u03d1i(\u03b8) for player i to which signal \u03b8 belongs can be described by the vector (\u03c51, . . . , \u03c5r, \u03ba1\ni , . . . , \u03bar i ). Firstly, Texas Hold'em-style games have perfect-recall, which implys that in a given stage, all signals within a signal infoset share the same predecessor signal infoset in the earlier stages. For example, during the Turn stage in a game of Texas Hold'em, the preceding signal infoset for the signal infoset [\u2660A, \u2661A|\u26633, \u26635, \u2662Q, \u2662K] can only be [\u2660A, \u2661A|\u26633, \u26635, \u2662Q] during the Flop stage, and [\u2660A, \u2661A] during the Preflop stage.\n\nSecondly, in Texas Hold'em-style games, the transition of signal infosets between different stages is a **classical probability model**. In stage r, a signal infoset transition to n(r+1)\nsignal infosets in stage r + 1, all with equal probability, where n(r+1) is calculated as\n\n$$n^{(r+1)}=\\binom{|D|-\\sum_{j=1}^{r}(\\mathcal{U}^{j}+N\\mathcal{K}^{j})}{\\mathcal{U}^{r+1}}\\Big{(}|D|-\\sum_{j=1}^{r}(\\mathcal{U}^{j}+N\\mathcal{K}^{j})-\\mathcal{U}^{r+1}\\Big{)}.$$\n\nFor example, in Texas Hold'em, the signal infoets from the Predop, Flop, and Turn stages can transition to signal infoets in the Flop, Turn, and River stages, respectively, with $\\binom{50}{3}$, $\\binom{47}{1}$, and $\\binom{49}{1}$ possible cases. We can simplify these histograms using **sparse representation**. Specifically, for a signal infoets $\\vartheta$ in stage $r$ that can transition to signal infoets $\\vartheta_{1},\\ldots,\\vartheta_{n^{(r+1)}}$ in stage $r+1$, the potential outcome feature for $\\vartheta$ is calculated as\n\n$$f_{i}^{(r)}(\\vartheta)=\\texttt{@NONLATSTAGEFeature}(r,\\vartheta,\\mathcal{D}_{i}^{(r+1)}).$$\nWhere the NonlastStageFearure operator is defined as shown in Algorithm 2.\n\nAlgorithm 1 and Algorithm 2 both involve an Indexi operator, which is responsible for mapping the signal infoset \u03d1 \u2208 \u0398(r)\ni at stage r to a unique integer ranging from 0 to\n|\u0398(r)\ni | \u2212 1. In games like Texas Hold'em, an effective mapping method is to use colexicographic order (Bollob\u00b4as, 1986). As described by Waugh (2013), grouped colexicographic encoding can be used to encode grouped combinations.\n\nThe order of the signal infoset\n\u03d1i = (\u03c51, . . . , \u03c5r, \u03ba1\ni , . . . , \u03bar i ) \u2208 \u0398(r)\ni can be represented as follows\n\n$$\\mathrm{Index}_{i}(r,\\vartheta_{i})=\\mathrm{Indexgroup}_{\\mathcal{U}^{1},\\mathcal{K}^{1},\\ldots\\mathcal{U}^{r},\\mathcal{K}^{r}}^{|D|}(v^{1},\\kappa_{i}^{1},\\ldots,v^{r},\\kappa_{i}^{r}).$$\nHere, Indexgroup is an operator used to compute the order of grouped combinations. Let l1*, . . . , l*k be grouped combinations extracted from the set {0*, . . . , m* \u2212 1}, where lj has Lj elements. The index of this grouped combination can be defined as\n\n$$\\text{Indexgroup}_{L^{1},\\ldots,L^{k}}^{m}(l^{1},\\ldots,l^{k})=\\binom{m}{L^{k}}\\text{Indexgroup}_{L^{1},\\ldots,L^{k-1}}^{m-L^{k}}(l^{1}|_{l^{k}},\\ldots,l^{k-1}|_{l^{k}})+\\text{coker}_{L^{k}}^{m}(l^{k}).\\tag{2}$$\n\nHere, $\\text{coker}$ represents the colexicographic order operator. Let $l=(c_{1},\\ldots,c_{n})$ be an $n$-dimensional vector, where $c_{1},\\ldots,c_{n}$ are elements extracted from the set $\\{0,\\ldots,m-1\\}$\nAlgorithm 2 Non-last stage feature Require:\nr \u2208 {1, . . . , |r| \u2212 1}. Stages.\n\n\u03d1 \u2208 \u0398(r)\ni . Signal infoset.\n\nn(r+1) \u2208 N. The number of signal infosets that \u03d1 can transfer to at stage r + 1.\n\nIndexi(r, \u00b7) : \u0398(r)\ni\n\ufffd\u2192 N. Signal infoset index function.\n\nD(r+1)\ni\n: N \ufffd\u2192 N. Next stage potential outcome isomorphism map.\n\n1: **procedure** NonlastStageFearure(r, \u03d1, D(r+1)\ni\n)\n2:\nInitialize *feature* array arbitrarily with length n(r+1).\n3:\nfor j = 0 to |n(r+1)| \u2212 1 do\n4:\n\u03d1j \u2190 the j-th possible signal infoset in next stage of \u03d1.\n5:\nidxj \u2190 *Index*i(r + 1, \u03d1j).\n6:\nfeature[j] *\u2190 D*(r+1)\ni\n[idxj].\n7:\nend for\n8:\nSort the elements of *feature* in ascending order.\n9:\nreturn *feature*.\n10: end procedure\nwithout replacement. Generally, we assume that c1 *< . . . < c*n. Additionally, we specify\n\ufffdn1\nn2\n\ufffd\n= 0 when n1 *< n*2. Based on these definitions, the colexicographic order of vector l can be expressed as\n\ncolexm n (l) = colexm n (c1*, . . . , c*n) = j=1 \ufffdcj j \ufffd . n \ufffd\nIn Equation (2), lj|lk is a shifting operation that maps the elements from lj in the original space {0*, . . . , m* \u2212 1} to a new space {0*, . . . , m* \u2212 1 \u2212 Lk}. Specifically, if c is an element in lj, and there are x elements in lk that are smaller than c, then in lj|lk, the element corresponding to c will become c \u2212 x.\n\nFigure 3 illustrates the process of building POI in Leduc Hold'em. In the second stage, each hand corresponds to four possible opponent hole combinations, resulting in four signals per signal infoset. We tally the win-tie-loss outcomes for each signal in each infoset after showdown and group signal infosets with identical distributions into the same abstracted signal infoset, assigning a label to each. In the first stage, each hand will form different second-stage abstracted signal infosets as five different flop cards are dealt. We tally these distributions and consider hands with the same distribution as belonging to the same abstracted signal infoset. It can be observed that in Leduc Hold'em, the quantity of abstracted signal infosets in the first stage is equal to the quantity of signal infosets, indicating good identification capability. However, in the second stage, POI can only identify three abstracted signal infosets, significantly fewer than the nine signal infosets. In Leduc Hold'em, the quantity of signal infosets equals the quantity of lossless abstracted signal infosets. This also indicates that in Leduc Hold'em, POI has much lower resolution than LI. We will analyze this phenomenon in the next section.\n"
    },
    {
        "level": "##",
        "title": "7 The Resolution Boundary Of Mainstream Signal Abstraction Algorithms",
        "content": "\nIn this section, we aim to assess the resolution boundary of mainstream signal abstraction algorithms such as E[HS] and PA&PAEMD. To achieve this, we introduce a novel technique called common refinement, which is utilized to delineate the resolution boundaries of signal abstraction algorithms. Subsequently, we demonstrate that POI serves as a common refinement of the prevailing outcome-based imperfect-recall algorithms.\n"
    },
    {
        "level": "##",
        "title": "7.1 Common Refinement",
        "content": "\nWe first consider the common refinement of several signal abstractions:\n\nDefinition 4 In games with ordered signals, we refer to the common refinement of sev-\neral signal abstractions \u02dc\u03b1\u0398,1\n                       i\n                         , . . . , \u02dc\u03b1\u0398,n\n                               i\n                                   for player i as \u02dc\u03b1\u0398\n                                                   i , if \u02dc\u03b1\u0398\n                                                          i\n                                                            \u2292 \u02dc\u03b1\u0398,j\n                                                                 i\n                                                                    holds for all\nj \u2208 {1, . . . , n}.\n\n    If \u02dc\u03b1\u0398\n        i serves as the common refinement of \u02dc\u03b1\u0398,1\n                                                    i\n                                                       , . . . , \u02dc\u03b1\u0398,n\n                                                               i\n                                                                  , then any signal infoset identifi-\nable by \u02dc\u03b1\u0398,1\n          i\n             , . . . , \u02dc\u03b1\u0398,n\n                     i\n                         can all be identified by \u02dc\u03b1\u0398\n                                                     i . This implies that for \u03d11, \u03d12 \u2208 \u0398i, if there\nexists j \u2208 {1, . . . , n} such that \u02dc\u03b1\u0398,j\n                                      i\n                                          assigns \u03d11, \u03d12 to different abstracted signal infosets,\nthen \u02dc\u03b1\u0398\n       i will definitely assign \u03d11, \u03d12 to different abstracted signal infosets; if \u02dc\u03b1\u0398\n                                                                                          i considers\n\u03d11, \u03d12 to belong to the same abstracted signal infoset, then \u02dc\u03b1\u0398,1\n                                                                      i\n                                                                         , . . . , \u02dc\u03b1\u0398,n\n                                                                                i\n                                                                                     will all consider\n\u03d11, \u03d12 to belong to the same abstracted signal infoset. From the one-player-abstraction-\nperspective, let (\u02dc\u03b1\u0398\n                     i , \u0398\u2212i) denote the signal abstraction profile where player i adopts \u02dc\u03b1\u0398\n                                                                                                     i\nwhile others maintain their original signal infosets. In this context, the exploitability of\nthe strategy transition from the Nash equilibrium of the abstracted game \u02dc\u0393(\u02dc\u03b1\u0398\n                                                                                       i ,\u0398\u2212i) is lower\nthan that of any \u02dc\u0393(\u02dc\u03b1\u0398,1\n                       i\n                          ,\u0398\u2212i), . . . , \u02dc\u0393(\u02dc\u03b1\u0398,n\n                                        i\n                                           ,\u0398\u2212i).\n    The signal abstraction algorithm, denoted as Alg, yields a signal abstraction given a set\nof parameters \u03c8. Hereafter, we provide the definition of common refinement for a signal\nabstraction algorithm:\n\nDefinition 5 In a game with ordered signals, given a signal abstraction algorithm Alg,\nif there exists a signal abstraction \u02dc\u03b1\u0398\n                                i\n                                  such that, for any set of parameters \u03c8, the signal\nabstraction \u02dc\u03b2\u0398\n           i generated by algorithm Alg can be refined by \u02dc\u03b1\u0398\n                                                      i , then we refer to \u02dc\u03b1\u0398\n                                                                        i as the\ncommon refinement of algorithm Alg in the game, and simply as the common refinement of\nalgorithm Alg.\n\n   The common refinement of a signal abstraction algorithm reflects, on one hand, the\nextent to which the algorithm retains information across the parameter space, and, on\nthe other hand, the algorithm's ultimate performance in generating abstractions under the\noptimal set of parameters.\n                           Having a high-quality common refinement for an algorithm\ndoesn't necessarily imply that the algorithm itself is excellent. However, the presence of a\nlow-quality common refinement can indicate certain deficiencies in the algorithm.\n"
    },
    {
        "level": "##",
        "title": "7.2 Potential Outcome Isomorphism Serves As The Common Refinement Of Mainstream Signal Abstraction Algorithms",
        "content": "\nThe current mainstream signal abstraction algorithms, E[HS] and PA&PAEMD, are based on showdown outcomes clustering for lossy signal abstraction with imperfect-recall. These bottom-up clustering relies on the distance between cluster centroids and signal infosets (hand combinations). As shown in Equation (3), Algdis is the function within algorithm Alg used to calculate the distance between cluster centroids and signals, CT t j (Alg*, \u03c8,* \u0398) represents the j-th cluster centroids generated by algorithm Alg with parameter \u03c8 in iteration t, and v(Alg, \u03d1) is a computational metric of \u03d1 involved in the clustering process.\n\n$$d^{t}_{j}(\\vartheta)=\\mbox{Algdis}(CT^{t}_{j}(\\mbox{Alg},\\psi,\\Theta),v(\\mbox{Alg},\\vartheta)).\\tag{3}$$\nWe will demonstrate that POI serves as a common refinement for E[HS], PA&PAEMD\nalgorithms. It is essential to emphasize that the key to this argument lies in showing that within any potential outcome isomorphism class, two signal infosets in the same class belong to the same abstracted signal infoset generated by the above-mentioned algorithms.\n\nIn the following discussion, we employ a skill where, if we can establish that within the same potential outcome isomorphism class, different signal infosets \u03d11 and \u03d12 share identical computational metrics involved in the calculation of Equation (3), i.e., v(Alg, \u03d11) =\nv(Alg, \u03d12), we need not consider the specific implementation details of Algdis. As long as Algdis is a deterministic algorithm devoid of random factors, and for any j and t, we have dt j(\u03d11) = dt j(\u03d12), it ensures that \u03d11 and \u03d12 will certainly be categorized into the same abstracted signal infoset in iteration t.\n"
    },
    {
        "level": "##",
        "title": "7.2.1 E[Hs] Algorithm",
        "content": "\nThe E[HS] algorithm is a signal abstraction algorithm designed for 2-player Texas Hold'em. For a player $i$'s signal infoset $\\vartheta$, the E[HS] algorithm defines a metric for measuring the distance between a signal and cluster centroids, called **equity**. The formula for calculating this metric is as follows\n\n$$e=0\\cdot l+\\frac{1}{2}\\cdot t+w.\\tag{4}$$\n\nHere, $l,t,w$ represent the probabilities of signals in the infoset $\\vartheta$ for player $i$ to lose, tie, and win in future shadow stages, respectively.\n\nThe E[HS] algorithm evenly assigns signal infosets to different classes based on their equity values. For instance, if the total number of classes is n, signals with equity values in the range 0 to 1\nn, 2\nn\n\ufffd\nare assigned to class 2, and so on.\n\nn are assigned to class 1, signals in the range\n\ufffd 1\nTheorem 6 The POI serves as a common refinement of algorithm E[HS]. Proof We employ mathematical induction to prove that within the same potential outcome isomorphism class, different signal infosets will be assigned to the same abstracted signal infoset in the E[HS] algorithm for a set of parameters. To do this, it is sufficient to demonstrate that each signal infoset within the same potential outcome isomorphism class has the same equity value.\n\nFirst, consider the last stage r = |r|. According to the expression in Equation (1), in this final stage of a 2-player scenario, the outcome isomorphism vector (f(r),0\ni\n(\u03d1), f(r),1\ni\n(\u03d1), f(r),2\ni\n(\u03d1))\nfor a signal infoset \u03d1 is simply the signal's losing rate, tying rate, and winning rate for player i, each multiplied by the number of signals in \u03d1. This is in accordance with Equation (4), confirming our assumption holds.\n\nNext, assuming the conclusion holds at stage r + 1, let's consider stage r. According to Algorithm 1, we can conclude that signal infosets within the same potential outcome isomorphism class \u02dc\u03d1(r) share the same potential outcome feature. As stage r is not the final stage, the potential outcome feature of a signal infoset \u03d1 at this stage can be represented as (\u02dc\u03d1(r+1)\n1\n, . . . , \u02dc\u03d1(r+1)\nn(r+1)), where \u02dc\u03d1(r+1)\n1\n\u2264 *. . .* \u2264 \u02dc\u03d1(r+1)\nn(r+1) are the indices of potential outcome isomorphism classes to which the signal infoset in \u02dc\u03d1(r) can transition at stage r + 1, sorted in ascending order. According to our assumption, at stage r + 1, signal infosets within the same potential outcome isomorphism class have the same equity values. Therefore, for any potential outcome isomorphism class \u02dc\u03d1(r) within stage r, the equity value vectors of signal infosets \u03d1 are the same and can be represented as\n\n$$e=\\sum_{i=1}^{n^{(r+1)}}\\frac{1}{n^{(r+1)}}e_{i}.$$\nHere, ei represents the equity value of \u02dc\u03d1(r+1)\ni in stage r + 1. This completes the proof by mathematical induction, demonstrating that in all stages, the signal infosets within the same potential outcome isomorphism class have the same equity values.\n"
    },
    {
        "level": "##",
        "title": "7.2.2 Pa&Paemd Algorithm",
        "content": "\nThe E[HS] algorithm, while proficient in reflecting the expected strength of hand rankings, lacks the ability to characterize the changes in hand strength across different stages of the game. In response to this limitation, Gilpin et al. (2007) introduced the PA algorithm. This algorithm employs a bottom-up approach, starting from the final stage, to perform k-means clustering on hands. Clustering in the final stage is based on the distances between cluster centroids and hand equities. For other stages, histograms are constructed for each cluster centroid to the next stage's centroids, as well as for each hand to the next stage's centroids.\n\nThe clustering process utilizes the L2 distance between the histograms of cluster centroids and hand histograms, ensuring a more nuanced understanding of hand strength dynamics throughout the game. Building upon the PA algorithm, Ganzfried and Sandholm (2014) further enhanced it with the PAEMD algorithm.\n\nThis iteration incorporates the EMD\nbetween histograms of cluster centroids and hand histograms in non-final stages, alongside an efficient approximate method for calculating this distance.\n\nIt's crucial to note that these algorithms involve techniques such as approximating equity expectations using sampling and approximating the EMD using heuristics.\n\nWhile effective, these techniques inherently entail certain randomness and distance asymmetry characteristics. Therefore, the subsequent proof will be applicable only under conditions where accurate equity values and standard EMD distances are maintained.\n\nTheorem 7 The POI serves as a common refinement of algorithm PA and PAEMD.\n\nProof We first consider the last stage, r = |r| . It suffices to demonstrate that every signal infoset within the same potential outcome isomorphism class holds the same equity value, akin to the E[HS] algorithm's case, i.e., the conclusion holds.\n\nNext, assuming that the conclusion holds at stage r + 1, it suffices at stage r to prove that every distinct signal infoset within the same potential outcome isomorphism class has the same histogram of PA algorithm's next-stage cluster centroids. For any potential outcome isomorphism class \u02dc\u03d1(r+1) at stage r, any pair of signal infosets \u03d1 and \u03d1\u2032 from \u02dc\u03d1(r+1)\nshare an identical potential outcome feature. Since r is not the final stage, this potential outcome feature is represented as a sparse histogram over potential outcome isomorphism classes from stage r + 1, denoted as (\u02dc\u03d1(r+1)\n1\n, . . . , \u02dc\u03d1(r+1)\nn(r+1)). Consequently, there exist\n\n\u03d11, \u03d1\u2032\n   1 \u2208 \u02dc\u03d1(r+1)\n       1\n          , . . . , \u03d1n(r+1), \u03d1\u2032\n                     n(r+1) \u2208 \u02dc\u03d1(r+1)\ncan transition to in stage r + 1, and \u03d1\u2032n(r+1), where \u03d11, . . . , \u03d1n(r+1) are signal infosets that \u03d1\n                           1, . . . , \u03d1\u2032\n                                 n(r+1) are signal infosets that \u03d1\u2032 can transition\nto in stage r + 1. According to the induction hypothesis, \u03d1j and \u03d1\u2032\n                                                j are also assigned to the\nsame cluster centroid Cj under the PA algorithm with the given parameters \u03c8. Therefore,\n\u03d1 and \u03d1\u2032 share the same next-stage cluster centroid histogram in the PA algorithm with the\ngiven parameters \u03c8, and their sparse representations are both (C1, . . . , Cn(r+1)). We have\nnow completed the proof by mathematical induction, demonstrating that across all stages,\ndistinct signal infosets within the same potential outcome isomorphism class in the outcome\nisomorphism will be assigned to the same abstracted signal infoset in the PA algorithm with\na set of parameters \u03c8.\n"
    },
    {
        "level": "##",
        "title": "7.3 Limitations Of Potential Outcome Isomorphism",
        "content": "\nThrough the above discussion, we have learned that POI is a common refinement for both the E[HS] algorithm and the PA&PAEMD algorithm. In other words, the strategies trained on the abstracted signal infosets generate by these two algorithms will not surpass those trained using POI, at least in one-player-abstraction-perspective. However, POI has its clear limitations.\n\nTable 1 displays the quantity of original signal infosets at each stage of Texas Hold'em, along with the quantity of abstracted signal infosets that both the LI and POI can identify at each stage. It can be observed that as the game progresses, the of imperfect-recall signal abstraction that demands players to forget all past information, the volume of information gradually diminishes as the game progresses. Consequently, the potential outcome features exhibit an increased probability of repetition due to reduced volume of information, thereby leading to a reduction in the scale of distinct potential outcome isomorphism classes identified. The combined influence of these two factors results in a trend where the quantity of potential outcome isomorphism classes follows a spindleshaped distribution, and the phenomenon of excessive abstraction becomes more evident in the later stages.\n"
    },
    {
        "level": "##",
        "title": "8 K-Recall Outcome Isomorphism",
        "content": "\nWe have identified the underlying reasons for the phenomenon of excessive abstraction in POI. This arises from the gradual reduction of information within potential outcome features, as discussed in the preceding section. During the identification of a signal infoset, only the information spanning from the current stage to the end of the game is employed, i.e., imperfect-recall that demands players to forget all past information. This, in turn, increases the probability of potential outcome feature repetition. In this section, we will introduce the concept of k-recall outcome isomorphism (KROI), which addresses this issue by supplementing information from past stages to mitigate the problem of excessive abstraction.\n\nAs illustrated in Algorithm 3, for a signal infoset at stage r, we can compute its k-recall outcome isomorphism, where k = 0*, . . . , r* \u2212 1. The primary procedure of the algorithm closely mirrors that of the POI algorithm, with the only distinction being the replacement of the original potential outcome features with k-recall outcome features in lines 5 and 11.\n\nThe k-recall outcome features for a signal infoset \u03d1 constitute a vector of length k+1, where the component at index j stores the index of potential outcome isomorphism class for the predecessor signal infoset of \u03d1 at stage r \u2212 j. Since POI incorporates information from the current stage to the end of the game, k-recall outcome features encompass the information of \u03d1 spanning the preceding k + 1 stages, including stage r.\n\nAlgorithm 3 K-Recall Outcome Isomorphism\nRequire:\n   r \u2208 {1, . . . , |r|}. Stages.\n   \u0398(r)\n    i . Signal infoset space.\n   Indexi(r, \u00b7) : \u0398(r)\n              i\n                 \ufffd\u2192 N. Signal infoset index function.\n   D(1)\n    i\n      , . . . , D(r)\n           i . Potential outcome isomorphism maps.\n\n1: procedure KRecallOutcomeIsomorphism(r,k, \u0398(r)\n                                                                           i ,D(1)\n                                                                                 i\n                                                                                     ,..., D(r)\n                                                                                            i )\n\n2:\nInitialize KC(r)\ni\nvector as empty.\n3:\nInitialize KD(r)\ni\narray arbitrarily with length |\u0398(r)\ni |.\n4:\nfor \u03d1 \u2208 \u0398(r)\ni\ndo\n5:\nfeature \u2190 KRecallOutcomeFeature(r, k, \u03d1,D(1)\ni\n,..., D(r)\ni ).\n6:\nAppend *feature* to KC(r)\ni .\n7:\nend for\n8:\nEliminate duplicates from KC(r)\ni .\n9:\nSort the elements of KC(r)\ni\nin lexicographical order.\n10:\nConstruct hash table *KCI*(r)\ni\nfrom KC(r)\ni . Store the index *lexid* and value feature\nof KC(r)\ni\nin *KCI*(r)\ni\nas key-value pairs (*feature, lexid*).\n11:\nfor \u03d1 \u2208 \u0398(r)\ni\ndo\n12:\nfeature \u2190 KRecallOutcomeFeature(r, k, \u03d1,D(1)\ni\n,..., D(r)\ni ).\n13:\nidx \u2190 Indexi(*r, \u03d1*).\n14:\nUpdate KD(r)\ni [idx] with *KCI*(r)\ni [*feature*].\n15:\nend for\n16:\nreturn KD(r)\ni .\n17: end procedure\n18: **procedure** KRecallOutcomeFeature(r,k, \u03d1,D(1)\ni\n,..., D(r)\ni )\n19:\nInitialize *feature* array arbitrarily with length k + 1.\n\n20:\nfor j = r to r \u2212 k do\n\n21:\n\u03d1j \u2190 the signal infoset predecessor in the j-th stage of \u03d1.\n22:\nidxj \u2190 Indexi(*j, \u03d1*j).\n23:\nfeature[r \u2212 j] *\u2190 D*(j)\ni [idxj].\n\n24:\nend for\n25:\nreturn *feature*.\n\n26: end procedure Figure 5 illustrates the process of constructing 1-ROI in Leudc Hold'em. The bottomup part follows the same procedure as constructing POI. In the first stage, only 0-ROI construction is possible, which aligns with the result of POI. The change occurs in the second stage, where each signal infoset is assigned the current stage's POI class label, as well as the POI class label where its predecessor in the previous stage is located. These labels form a vector, known as the 1-recall outcome feature. We group signal infosets with the same 1-recall outcome feature into the same abstracted signal infoset. It can be observed\n\n| Stage   |   0-ROI |    1-ROI |     2-ROI |     3-ROI |\n|---------|---------|----------|-----------|-----------|\n| Preflop |     169 |      169 |           |           |\n| 1       |         |          |           |           |\n| 169     |         |          |           |           |\n| 2       |         |          |           |           |\n| 169     |         |          |           |           |\n| 3       |         |          |           |           |\n| Flop    | 1137132 |  1241210 |   1241210 |           |\n| 2       |         |          |           |           |\n| 1241210 |         |          |           |           |\n| 3       |         |          |           |           |\n| Turn    | 2337912 | 38938975 |  42040233 |  42040233 |\n| 3       |         |          |           |           |\n| River   |   20687 | 39792212 | 586622784 | 638585633 |\n\nthat in Leduc Hold'em, the quantity of 1-ROI classes in the second stage is 7, higher than the 3 abstracted signal infosets of POI. This represents an expansion of the resolution of the outcome-based imperfect-recall algorithm.\n\nTable 2 presents the quantity of abstracted signal infosets identified by k-recall outcome isomorphism at each stage in HUNL&HULHE, varying with k. When k = 0, k-recall outcome isomorphism is essentially equivalent to POI. For stages where r \u2264 k, the quantity of abstracted signal infosets is directly inherited from (k\u22121)-ROI. Furthermore, when incorporating information from all preceding stages (e.g., 3-ROI in HUNL&HULHE), the quantity of abstracted signal infosets follows a triangular distribution, mirroring that observed in the LI and the original game's signal infosets.\n\nIt should be noted that for games with a maximum stage of r, r-ROI serves as a perfectrecall signal abstraction.\n\nHowever, KROI can lead to more generalized outcome-based imperfect-recall signal abstraction algorithms, allowing players to retain partial memory instead of forgetting everything. For instance, when designing abstraction algorithms, we only cluster D(r)\ni at each stage r, without considering the connections between stages. Such an abstraction algorithm remains imperfect-recall, as it does not require consistent paths between abstracted signal infosets. Thus, we obtain a signal abstraction framework with higher resolution, with KROI serving as their resolution boundary.\n"
    },
    {
        "level": "##",
        "title": "9 Experiment And Result",
        "content": "\nFigure 5 and Table 2 illustrate that KROI expands the resolution boundary of the outcomebased imperfect-recall algorithm. However, it also indicates that there is still a gap between the resolution of KROI and LI. We are interested in understanding to what extent this gap can impact its performance in games, as well as how much the resolution improvement of KROI relative to POI can enhance its performance in games.\n\nExperiments were conducted on Numeral211 Hold'em, a simplified version of two-player limit Texas Hold'em, which is divided into three stages; specific rules are detailed in Appendix D.2. In Numeral211 Hold'em, the quantity of abstracted signal infosets identified by each method at different stages is presented in Table 3. The performance of 0-Recall Outcome Isomorphism (i.e., Potential Outcome Isomorphism, POI), 2-Recall Outcome Isomorphism (2-ROI), and Lossless Isomorphism (LI) was evaluated in following experiments.\n\n1. Inherited from 0-ROI 2. Inherited from 1-ROI 3. Inherited from 2-ROI\n\n| Stage   |   0-ROI |   1-ROI |   2-ROI |    LI |\n|---------|---------|---------|---------|-------|\n| Preflop |     100 |     100 |         |       |\n| 1       |         |         |         |       |\n| 100     |         |         |         |       |\n| 2       |         |         |         |       |\n| 100     |         |         |         |       |\n| Flop    |    2250 |    2260 |    2260 |       |\n| 2       |         |         |         |       |\n| 2260    |         |         |         |       |\n| Turn    |    3957 |   51176 |   51228 | 62020 |\n"
    },
    {
        "level": "##",
        "title": "9.1 Asymmetric Abstraction In Cfr Training",
        "content": "\nOur fisrt investigation focuses on the one-player-abstraction-perspective. Given a signal abstraction \u02dc\u03b1\u0398 = (\u02dc\u03b1\u0398\n1 , \u02dc\u03b1\u0398\n2 ), we construct scenarios where player 1 employs the signal abstraction, while player 2 does not, resulting in the signal abstracted game \u02dc\u03931 = \u02dc\u0393(\u02dc\u03b1\u0398\n1 ,\u03982).\n\nConversely, we adjust the setup such that player 1 does not use abstraction, whereas player\n2 does, thereby creating another signal abstracted game \u02dc\u03932 = \u02dc\u0393(\u03981,\u02dc\u03b1\u0398\n2 ).\n\nSubsequently, by applying the chance-sampled counterfactual regret minimization (CSMCCFR) (Zinkevich et al., 2007; Lanctot et al., 2009), we iteratively solve for \u03f5-Nash equilibrium and map the resulting strategies back to the original game \u02dc\u0393 to obtain \u03c31,\u2217 = (\u03c31,\u2217\n1 , \u03c31,\u2217\n2 ) and\n\u03c32,\u2217 = (\u03c32,\u2217\n1 , \u03c32,\u2217\n2 ).\n\nUltimately, by amalgamating these strategies into \u03c3\u2217 = (\u03c31,\u2217\n1 , \u03c32,\u2217\n2 ), which we called **asymmetric abstraction Nash strategy**, we adopt the \u03c3\u2217 strategy in real-game scenarios as a means to counter strategies available in a non-abstracted setting from an abstracted viewpoint. The exploitability of \u03c3 is then analyzed in terms of milli blinds per game (mb/g).\n\nThe experimental results are depicted in Figure 6, where (a)\n1. Inherited from 0-ROI 2. Inherited from 1-ROI\nshowcases the results plotted on a linear scale of exploitability, while (b) presents the same results on a logarithmic scale.\n\nWithin the asymmetric abstraction setting, the issue of abstraction pathology does not arise. All asymmetric abstraction Nash strategy derived from abstraction refined by\n\u02dc\u03b1\u0398 exhibit exploitability that is at least as those asymmetric abstraction Nash strategies derived from \u02dc\u03b1\u0398.\n\nWe note a significant discrepancy between the POI method and the ground truth benchmark of the LI method, indicating that the abstraction refined by the POI, including E[HS] and PA&PAEMD, diverge substantially from the ground truth. In contrast, the performance gap between the 2-ROI method and the ground truth is minimal, demonstrating a high degree of approximation to the ground truth even under logarithmic scale as shown in Figure 6b.\n"
    },
    {
        "level": "##",
        "title": "9.2 Symmetric Abstraction In Cfr Self-Play Training",
        "content": "\nSubsequently, we shift our focus to the setting of symmetric abstraction, which more closely aligns with the practical scenarios of AI training. Given a specific signal abstraction \u02dc\u03b1\u0398, we construct the corresponding signal abstracted game \u02dc\u0393\u02dc\u03b1\u0398. Utilizing the CSMCCFR algorithm, we iteratively solve for the \u03f5-Nash equilibrium and map the resulting strategy back to the original game \u02dc\u0393, obtaining \u03c3\u2217, and then calculate its exploitability. The experimental results are presented in Figure 7.\n\nThe results are consistent with the experiments presented in Section 9.1, where the POI\nmethod exhibits a significant gap from the ground truth, while the 2-ROI method shows results that are closer to the ground truth. Furthermore, within the setting of symmetric abstraction, while both POI and 2-ROI methods reveal a greater disparity from the ground truth due to the extensive assumptions regarding the opponent's strategy space, it is specifically POI that displays overfitting phenomena. In a larger game, abstraction pathology does not significantly affect such overall trends, indicating that future abstraction algorithms utilizing KROI as a common refinement may further enhance AI's competitiveness.\n"
    },
    {
        "level": "##",
        "title": "10 Discussion And Future Work",
        "content": "\nThe main purpose of this study is to identify a low-resolution boundary present in current outcome-based imperfect-recall algorithms, which we refer to as the POI resolution boundary. This boundary affects the competitiveness of AI built using signal abstraction algorithms constrained by the POI resolution boundary, especially when scaling up computational resources, leading to a limited performance. The root of this problem lies in the algorithms neglecting historical information in gameplay.\n\nUnder the outcome-based imperfect-recall framework, we introduce KROI, which incorporates historical information and exhibits a finer resolution boundary compared to POI. We refer to this as the KROI resolution boundary. Experimental results demonstrate that these oversimplified resolution boundaries indeed impact AI performance.\n\nIn future research, we will develop signal abstraction algorithms aiming to surpass the POI resolution boundary and target the KROI resolution boundary. Although KROI, as a signal abstraction, has perfect-recall, signal abstraction algorithms targeting the KROI resolution boundary do not necessarily require perfect-recall.\n\nOur experimental results do not conclusively demonstrate that signal abstraction targeting the KROI resolution boundary outperforms signal abstraction targeting the POI resolution boundary with the same quantity of abstract signal infosets. We will verify this proposition in future research.\n"
    },
    {
        "level": "##",
        "title": "Appendix A. Imperfect-Information Games",
        "content": "\nDefinition 8 *An extensive-form game* \u0393 = \u27e8Nc, H, Z, \u03c1, A, \u03c7, \u03c4, P, u\u27e9 is a structured tuple, where Nc is the set of extended players, H is the set of non-terminal nodes, Z is the set of terminal nodes, \u03c1 is the player function, A is the action set, \u03c7 is the action mapping function, \u03c4 is the successor function, P is the random event function, and u is the vector of payoff functions. More specifically:\n\n- Nc = N \u222a c, where N = {1, ..., N} is the set of players, and c is a special player,\ncalled nature, whose actions represent random events in the game.\n- \u03c1 : H \ufffd\u2192 Nc maps each non-terminal node to the unique extended player who can act\nat that node.\n- X = H \u222a Z is the set of all nodes. Where:\n- xo \u2208 X is the initial node of the game.\n- Hi = {h \u2208 H | \u03c1(h) = i} represents the set of non-terminal nodes where the\nacting player is i, and nodes where the acting player is nature are called chance nodes.\n- \u03c7 : H \ufffd\u2192 2A maps each non-terminal node to the set of actions that can be taken.\n- \u03c4 : H \u00d7 A \ufffd\u2192 X. Specifically, \u03c4(h, a) represents the new node reached after taking\naction a \u2208 \u03c7(h) at non-terminal node h \u2208 H. In extensive-form games, each node has\na unique path of arrival. In other words, if \u03c4(h1, a1) = \u03c4(h2, a2), then it must be that\nh1 = h2 and a1 = a2.\n- P(h) \u2208 \u2206(\u03c7(h)) represents the probability distribution of random events occurring at\nchance node h \u2208 Hc, for convenience, P(a | h) can be used to represent the probability\nof event a \u2208 \u03c7(h) occurring at h.\n- u = (u1, ..., uN), where ui : Z \ufffd\u2192 R, ui(z) represents the payoff obtained by player\ni \u2208 N at terminal node z \u2208 Z.\nDefinition 9 *An imperfect-information game* \u0393 = (Nc, H, Z, \u03c1, A, \u03c7, \u03c4, P, u, I) is a structured tuple, where (Nc, H, Z, \u03c1, A, \u03c7, \u03c4, P, u) constitutes an extensive-form game, and I is the set of infosets. More specifically:\n\n- I = \ufffd\ni\u2208N Ii:\n- Ii is a partition of Hi.\n- I \u2208 Ii is an infoset for player i, consisting of nodes indistinguishable to player i.\nFor any h, h\u2032 \u2208 Hi, a necessary condition for player i being unable to distinguish\nbetween h *and* h\u2032 is \u03c7(h) = \u03c7(h\u2032), and \u03c7(I) can be used to represent the set of\nactions for the infoset I.\n"
    },
    {
        "level": "##",
        "title": "Appendix B. Abstraction In Imperfect-Information Games",
        "content": "\nDefinition 10 In imperfect-information games, \u03b1 = (\u03b11, ..., \u03b1N) is referred to as a ab-\nstraction profile, where for player i, a abstraction \u03b1i =\n                                                \ufffd\n                                                \u03b1I\n                                                  i , \u03b1\u03c7\n                                                     i\n                                                      \ufffd\n                                                        is a tuple consisting of the\nfollowing components:\n\n- \u03b1I\ni is a partition of Hi. For any \u02c6I \u2208 \u03b1I\ni , it is possible to identify some infosets within\nIi that share the same action spaces, such that the collection of these infosets forms\na partition of \u02c6I. \u02c6I is referred to as a abstraction infoset.\n- \u03b1\u03c7\ni is a function defined on Hi. \u03b1\u03c7\ni (h) \u2286 \u03c7(h) represents the abstracted action set\nfor non-terminal node h \u2208 Hi. For all non-terminal nodes h and h\u2032 within the same\nabstracted infoset \u02c6I \u2208 \u03b1I\ni , it holds that \u03b1\u03c7\ni (h) = \u03b1\u03c7\ni (h\u2032).\n"
    },
    {
        "level": "##",
        "title": "Appendix C. Perfect-Recall Games",
        "content": "\nDefinition 11 In an extensive-form imperfect-information game \u0393, player i is said to have perfect-recall if the following two conditions are satisfied:\n\n1. In any path of \u0393, no two nodes within the same information set I \u2208 Ii of player i can\noccur simultaneously. In this case, for any node x satisfying I \u2291 x, I[x] denotes the\nnode in the path from xo to x that belongs to I.\n2. For any path in \u0393 where only the head x and the tail x\u2032 have player i as the acting\nplayer, if there exists a node \u02c6x\u2032 in I(x\u2032)\u2014the infoset of x\u2032\u2014that is different from x\u2032,\nthen there must exist another path \u27e8\u02c6x, . . . , \u02c6x\u2032\u27e9 where \u02c6x \u2208 I(x) and only the head and\nthe tail have player i as the acting player, and the two paths have the same action\nchosen at the heads x and \u02c6x.\nIf each player in an imperfect-information game has perfect-recall, then the game is said to have perfect-recall.\n"
    },
    {
        "level": "##",
        "title": "Appendix D. Some Simplified Texas Hold'Em-Style Games",
        "content": "\nIn essence, Leduc Hold'em provides a strategic platform for two-player poker, balancing simplicity with depth, making it an ideal candidate for computational analysis and the exploration of advanced gameplay strategies.\n"
    },
    {
        "level": "##",
        "title": "D.1 Leduc Hold'Em",
        "content": "\nLeduc Hold'em is a poker variant designed for two players, conceived primarily as a platform for computer game-playing research and introduced by Waugh et al. (2009a). It was engineered to possess a strategic depth akin to Texas Hold'em while maintaining a manageable scale suitable for the development of intelligent gameplay strategies.\n\nThe game unfolds as follows:\n\n1. **Ante:** Each player antes one chip into the pot at the start of the hand.\n\n|   Rank | Hand Equivalence Classes   | Hand Poker   | Prob.   |\n|--------|----------------------------|--------------|---------|\n|      1 | Pair of Kings              | KK           | 1/15    |\n|      2 | Pair of Queens             | QQ           | 1/15    |\n|      3 | Pair of Jacks              | JJ           | 1/15    |\n|      4 | King-high with Queen       | KQ or QK     | 4/15    |\n|      5 | King-high with Jack        | KJ or JK     | 4/15    |\n|      6 | Queen-high with Jack       | QJ or JQ     | 4/15    |\n\n2. **Deck:** The deck consists of only six cards: two Jacks (J), two Queens (Q), and two\nKings (K).\n3. **Hole Card:** Both players are dealt one private card face down, known as the hole\ncard.\n4. **First Betting Stage:** Following the distribution of hole cards, a stage of betting\noccurs. Players can choose to check or bet, with the bet size set at two chips.\n5. **Flop:** After the initial betting stage, a single community card, termed the flop, is\nrevealed from the deck.\n6. **Second Betting Stage:** Another stage of betting takes place after the flop, with the\nbet size increasing to four chips.\n7. **Showdown:** If neither player folds, a showdown occurs. Players reveal their cards,\naiming to form the best possible hand. The player with the highest-ranked hand wins the pot. In the case of a tie, the pot is split evenly. The Table 4 show the hand ranks of Leduc Hold'em.\n8. **Betting Options:** Throughout the game, players have options to fold, call, or raise.\nEach betting stage permits only one bet and one raise per player, with fixed bet sizes of two chips in the first stage and four chips in the second.\n"
    },
    {
        "level": "##",
        "title": "D.2 Numerall211 Hold'Em",
        "content": "\nThe Numeral211 Hold'em introduced in this paper is a poker variant more complex than Leduc and Rhode Island Hold'em, yet significantly simpler than HULHE. With ample diversity in hand possibilities, it serves as an ideal testbed for studying hand abstraction tasks.\n\nThe game unfolds as follows:\n\n1. **Ante:** Each player antes 5 chip into the pot at the start of the hand.\n2. **Hole Card:** Both players are dealt one private card face down, known as the hole\ncard.\n3. **Deck:** The deck consists of a standard poker deck, excluding the Jokers, Kings,\nQueens, and Jacks, resulting in a total of 40 cards.\nThere are four suits: spades\n(\u2660), hearts (\u2661), clubs (\u2663), and diamonds (\u2662), each containing ten cards numbered 2\nthrough 9, and including the ten (T) and ace (A).\n4. **First Betting Stage:** Following the distribution of hole cards, a stage of betting\noccurs. Players can choose to check or bet, with the bet size set at 10 chips.\n5. **Flop:** After the initial betting stage, a single community card, termed the flop, is\nrevealed from the deck.\n6. **Second Betting Stage:** Another stage of betting takes place after the flop, with the\nbet size increasing to 20 chips.\n7. **Turn:** After the Second betting stage, another community card, termed the turn, is\nrevealed from the deck.\n8. **Third Betting Stage:** Another stage of betting takes place after the turn, with the\nbet size still set at 20 chips.\n9. **Showdown:** If neither player folds, a showdown occurs. Players reveal their cards,\naiming to form the best possible hand. The player with the highest-ranked hand wins the pot. In the case of a tie, the pot is split evenly. The Table 5 show the hand ranks of Numeral211 Hold'em.\n10. **Betting Options:** Throughout the game, players have options to fold, call, or raise.\nIn each betting stage, the total sum of bets and raises is limited to a maximum of 4, with fixed bet sizes of 10 chips in the first stage and 20 chips in the last two betting stages.\n"
    },
    {
        "level": "##",
        "title": "Appendix E. A Transition From Games With Ordered Signals To Imperfect-Information Games",
        "content": "\nThe games with ordered signals are a special type of imperfect-information game. We can transform an ordered signal game into an imperfect-information game, and we will demonstrate this process. Given a game with ordered signals \u0393 = ( \u02dc\nN, \u02dcH, \u02dcZ, \u02dc\u03c1, \u02dcA, \u02dc\u03c7, \u02dc\u03c4, \u03b3, \u0398, \u03c2, O, \u03c9,\n\u2ab0, \u02dcu), we make some auxiliary definitions.\n\nLet r = {r = \u03b3(\u02dcx) | \u02dcx \u2208 \u02dcX} be the set of reachable stages in this ordered signal game. We can partition the public nodes by stage, such that \u02dcH(r) = {h \u2208 \u02dcH | \u03b3(h) = r}, \u02dcZ(r) = {z \u2208 \u02dcZ | \u03b3(z) = r}, \u02dcX(r) = \u02dcH(r) \u222a \u02dcZ(r).\n\nConstruct \u0393\u2032 = (Nc*, H, Z, \u03c1, A, \u03c7, \u03c4, P, u,* I), where:\n- Nc = \u02dc\nN \\ {pub}.\n\n- H = \ufffd\nr\u2208r(\u0398(r) \u00d7 \u02dcH(r)), Z = \ufffd\nr\u2208r(\u0398(r) \u00d7 \u02dcZ(r)), X = H \u222a Z.\n- \u03c1 is a function on X, such that for x = (\u03b8, \u02dcx) \u2208 X,\n\u03c1(x) := \u02dc\u03c1(\u02dcx).\n\n| Rank                            | Hand            |   Prob. | Description                    | Example   |\n|---------------------------------|-----------------|---------|--------------------------------|-----------|\n| T                               |                 |         |                                |           |\n| \u2660                               |                 |         |                                |           |\n| 9                               |                 |         |                                |           |\n| \u2660                               |                 |         |                                |           |\n| 8                               |                 |         |                                |           |\n| \u2660                               |                 |         |                                |           |\n| 2                               |                 |         |                                |           |\n| \u2663                               |                 |         |                                |           |\n| 1                               | Straight flush  | 0.00321 | 3 of cards with consecutive    |           |\n| rank and same suit. Ties are    |                 |         |                                |           |\n| broken by highest card.         |                 |         |                                |           |\n| T                               |                 |         |                                |           |\n| \u2660                               |                 |         |                                |           |\n| T                               |                 |         |                                |           |\n| \u2661                               |                 |         |                                |           |\n| T                               |                 |         |                                |           |\n| \u2663                               |                 |         |                                |           |\n| 2                               |                 |         |                                |           |\n| \u2663                               |                 |         |                                |           |\n| 2                               | Three of a kind | 0.01587 | 3 of cards with the same rank. |           |\n| Ties are broken by the card's   |                 |         |                                |           |\n| rank.                           |                 |         |                                |           |\n| T                               |                 |         |                                |           |\n| \u2660                               |                 |         |                                |           |\n| 9                               |                 |         |                                |           |\n| \u2661                               |                 |         |                                |           |\n| 8                               |                 |         |                                |           |\n| \u2663                               |                 |         |                                |           |\n| 2                               |                 |         |                                |           |\n| \u2662                               |                 |         |                                |           |\n| 3                               | Straight        | 0.04347 | 3 of cards with consecutive    |           |\n| rank. Ties are broken by the    |                 |         |                                |           |\n| highest card rank.              |                 |         |                                |           |\n| T                               |                 |         |                                |           |\n| \u2660                               |                 |         |                                |           |\n| 8                               |                 |         |                                |           |\n| \u2660                               |                 |         |                                |           |\n| 6                               |                 |         |                                |           |\n| \u2660                               |                 |         |                                |           |\n| 2                               |                 |         |                                |           |\n| \u2663                               |                 |         |                                |           |\n| 4                               | Flush           | 0.15799 | 3 of cards with the same suit. |           |\n| Ties are broken by the highest  |                 |         |                                |           |\n| card rank, then second high-    |                 |         |                                |           |\n| est card rank, then third high- |                 |         |                                |           |\n| est card rank.                  |                 |         |                                |           |\n| T                               |                 |         |                                |           |\n| \u2660                               |                 |         |                                |           |\n| T                               |                 |         |                                |           |\n| \u2661                               |                 |         |                                |           |\n| 8                               |                 |         |                                |           |\n| \u2663                               |                 |         |                                |           |\n| 2                               |                 |         |                                |           |\n| \u2662                               |                 |         |                                |           |\n| 5                               | Pair            | 0.34065 | 2 of cards with the same rank. |           |\n| Ties are broken by the rank of  |                 |         |                                |           |\n| the pair, then by the rank of   |                 |         |                                |           |\n| the third card.                 |                 |         |                                |           |\n| T                               |                 |         |                                |           |\n| \u2660                               |                 |         |                                |           |\n| 8                               |                 |         |                                |           |\n| \u2661                               |                 |         |                                |           |\n| 6                               |                 |         |                                |           |\n| \u2663                               |                 |         |                                |           |\n| 2                               |                 |         |                                |           |\n| \u2662                               |                 |         |                                |           |\n| 6                               | High card       | 0.43881 | None of the above.             | Ties      |\n| are broken by comparing the     |                 |         |                                |           |\n| highest ranked card, then the   |                 |         |                                |           |\n| second highest ranked card,     |                 |         |                                |           |\n| and then the third highest      |                 |         |                                |           |\n| ranked card                     |                 |         |                                |           |\n\n- A = \u02dcA \u222a {Reveal(\u03b8) | \u03b8 \u2208 \u0398} \\ {Reveal}, *Reveal*(\u03b8) represents the chance player\nunveil a signal \u03b8.\n* $\\chi$ is a function on $H$, such that for $h=(\\theta,\\tilde{h})\\in H$, $$\\chi(h):=\\left\\{\\begin{array}{ll}\\tilde{\\chi}(\\tilde{h})&\\mbox{if$\\tilde{h}\\not\\in\\tilde{H}_{c}$,}\\\\ \\{\\mbox{\\it Reveal}(\\theta^{\\prime})\\mid\\theta^{\\prime}\\in\\Theta,\\varsigma(\\theta^{\\prime}\\mid\\theta)>0\\}&\\mbox{if$\\tilde{h}\\in\\tilde{H}_{c}$.}\\end{array}\\right.$$\n* $\\tau$ is a function on $H\\times A$, such that for $h=(\\theta,\\tilde{h})\\in H$ and $a\\in A$, $$\\tau(h,a):=\\left\\{\\begin{array}{ll}(\\theta^{\\prime},\\tilde{\\tau}(\\tilde{h},\\mbox{\\it Reveal}))&\\mbox{if$a=\\mbox{\\it Reveal}(\\theta^{\\prime})$,}\\\\ (\\theta,\\tilde{\\tau}(\\tilde{h},a))&\\mbox{otherwise.}\\end{array}\\right.$$\n- P is a function on Hc regarding the probability of random events, such that for\nh = (\u03b8, \u02dch) \u2208 Hc,\nP(*Reveal*(\u03b8\u2032) | h) := \u03c2(\u03b8\u2032 | \u03b8).\n- u is a function on Z, such that for z = (\u03b8, \u02dcz) \u2208 Z,\nu(z) := \u02dcu(\u03b8, \u02dcz).\n- I = \ufffd\ni\u2208Nc Ii, where:\n- I(h) = {(\u03b8\u2032, \u02dch) | \u03b8\u2032 \u2208 \u03d1\u03c1(h)(\u03b8)}, for h = (\u03b8, \u02dch).\n\n- Ii = {I(h) | h \u2208 Hi}.\n\nIt can be verified that \u0393\u2032 is an imperfect-information game.\n"
    },
    {
        "level": "##",
        "title": "References",
        "content": "\nD Billings, N Burch, A Davidson, R Holte, J Schaeffer, T Schauenberg, and D Szafron.\nApproximating game-theoretic optimal strategies for full-scale poker. In International\nJoint Conference on Artificial Intelligence (IJCAI), volume 3, pages 661\u2013668, 2003.\nB\u00b4ela Bollob\u00b4as. Combinatorics: Set Systems, Hypergraphs, Families of Vectors, and Combinatorial Probability. Cambridge University Press, USA, 1986. ISBN 0521330599.\nNoam Brown and Tuomas Sandholm. Superhuman ai for heads-up no-limit poker: Libratus\nbeats top professionals. *Science*, 359(6374):418\u2013424, 2018.\nNoam Brown and Tuomas Sandholm. Superhuman ai for multiplayer poker. *Science*, 365\n(6456):885\u2013890, 2019.\nGH Freeman. The tactics of liar dice. Journal of the Royal Statistical Society: Series C\n(Applied Statistics), 38(3):507\u2013516, 1989.\nSam Ganzfried and Tuomas Sandholm. Potential-aware imperfect-recall abstraction with\nearth mover's distance in imperfect-information games. In AAAI Conference on Artificial\nIntelligence, volume 28, 2014.\nAndrew Gilpin and Thomas Sandholm. Expectation-based versus potential-aware automated abstraction in imperfect information games: An experimental comparison using poker. In *National Conference on Artificial Intelligence (NCAI)*, volume 3, pages 1454\u2013\n1457, 2008.\nAndrew Gilpin and Tuomas Sandholm.\nA competitive texas hold'em poker player via\nautomated abstraction and real-time equilibrium computation. In National Conference on Artificial Intelligence (NCAI), volume 21, page 1007. Menlo Park, CA; Cambridge, MA; London; AAAI Press; MIT Press; 1999, 2006.\nAndrew Gilpin and Tuomas Sandholm. Better automated abstraction techniques for imperfect information games, with application to texas hold'em poker. In International Joint Conference on Artificial Intelligence (IJCAI), pages 1\u20138, 2007a.\nAndrew Gilpin and Tuomas Sandholm. Lossless abstraction of imperfect information games.\nJournal of the ACM (JACM), 54(5):25\u2013es, 2007b.\nAndrew Gilpin, Tuomas Sandholm, and Troels Bjerre S\u00f8rensen. Potential-aware automated\nabstraction of sequential games, and holistic equilibrium analysis of texas hold'em poker. In *National Conference on Artificial Intelligence (NCAI)*, volume 22, page 50. Menlo\nPark, CA; Cambridge, MA; London; AAAI Press; MIT Press; 1999, 2007.\nJohn C Harsanyi. Games with incomplete information. *The American Economic Review*,\n85(3):291\u2013303, 1995.\nMichael Johanson.\nRobust strategies and counter-strategies: Building a champion level\ncomputer poker player. Master's thesis, University of Alberta, 2007.\nMichael Johanson, Neil Burch, Richard Valenzano, and Michael Bowling. Evaluating statespace abstractions in extensive-form games. In International Conference on Autonomous Agents and Multiagent Systems (AAMAS), pages 271\u2013278, 2013.\nChristian Kroer and Tuomas Sandholm. Extensive-form game abstraction with bounds. In\nACM Conference on Economics and Computation (EC), pages 621\u2013638, 2014.\nChristian Kroer and Tuomas Sandholm. Imperfect-recall abstractions with bounds in games.\nIn *ACM Conference on Economics and Computation (EC)*, pages 459\u2013476, 2016.\nChristian Kroer and Tuomas Sandholm.\nA unified framework for extensive-form game\nabstraction with bounds.\nInternational Conference on Neural Information Processing\nSystems (NeurIPS), 31, 2018.\nHarold W Kuhn. A simplified two-person poker. *Contributions to the Theory of Games*, 1:\n97\u2013103, 1950.\nHarold W Kuhn. Extensive games and the problem of information. Contributions to the\nTheory of Games, 2(28):193\u2013216, 1953.\nMarc Lanctot, Kevin Waugh, Martin Zinkevich, and Michael Bowling. Monte carlo sampling for regret minimization in extensive games. International Conference on Neural Information Processing Systems (NeurIPS), 22, 2009.\nMarc Lanctot, Richard Gibson, Neil Burch, Martin Zinkevich, and Michael Bowling. Noregret learning in extensive-form games with imperfect recall. In International Coference on International Conference on Machine Learning (ICML), pages 1035\u20131042, 2012.\nMatej Morav\u02c7c\u00b4\u0131k, Martin Schmid, Neil Burch, Viliam Lis`y, Dustin Morrill, Nolan Bard,\nTrevor Davis, Kevin Waugh, Michael Johanson, and Michael Bowling. Deepstack: Expertlevel artificial intelligence in heads-up no-limit poker. *Science*, 356(6337):508\u2013513, 2017.\nJohn Nash. Non-cooperative games. *Annals of Mathematics*, pages 286\u2013295, 1951. Tuomas Sandholm. The state of solving large incomplete-information games, and application to poker. *AI Magazine*, 31(4):13\u201332, 2010.\nTuomas Sandholm and Satinder Singh. Lossy stochastic game abstraction with bounds. In\nACM Conference on Electronic Commerce (ICEC), pages 880\u2013897, 2012.\nJiefu Shi and Michael L Littman.\nAbstraction methods for game theoretic poker.\nIn\nComputers and Games: Second International Conference, CG 2000 Hamamatsu, Japan, October 26\u201328, 2000 Revised Papers 2, pages 333\u2013345. Springer, 2001.\nKevin Waugh. A fast and optimal hand isomorphism algorithm. In AAAI Workshop on\nComputer Poker and Incomplete Information, 2013.\nKevin Waugh, Nolan Bard, and Michael Bowling. Strategy grafting in extensive games. International Conference on Neural Information Processing Systems (NeurIPS), 22, 2009a.\nKevin Waugh, David Schnizlein, Michael Bowling, and Duane Szafron. Abstraction pathologies in extensive games. In International Conference on Autonomous Agents and Multiagent Systems (AAMAS), volume 2, pages 781\u2013788, 2009b.\nKevin Waugh, Martin Zinkevich, Michael Johanson, Morgan Kan, David Schnizlein, and\nMichael Bowling.\nA practical use of imperfect recall.\nIn Symposium on Abstraction,\nReformulation and Approximation (SARA), 01 2009c.\nMartin Zinkevich, Michael Johanson, Michael Bowling, and Carmelo Piccione. Regret minimization in games with incomplete information. In International Conference on Neural\nInformation Processing Systems (NeurIPS), pages 1729\u20131736, 2007."
    }
]