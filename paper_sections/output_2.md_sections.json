[
    {
        "level": "#",
        "title": "Event-Triggered State Estimation Through Confidence Level",
        "content": "\nWei Liu, Senior Member, IEEE\n\n  Abstract\u2014This paper considers the state estimation problem\nfor discrete-time linear systems under event-triggered scheme. In\norder to improve performance, a novel event-triggered scheme\nbased on confidence level is proposed using the chi-square\ndistribution and mild regularity assumption. In terms of the novel\nevent-triggered scheme, a minimum mean squared error (MMSE)\nstate estimator is proposed using some results presented in this\npaper. Two algorithms for communication rate estimation of the\nproposed MMSE state estimator are developed where the first\nalgorithm is based on information with one-step delay, and the\nsecond algorithm is based on information with two-step delay.\nThe performance and effectiveness of the proposed MMSE state\nestimator and the two communication rate estimation algorithms\nare illustrated using a target tracking scenario.\n\n  Index Terms\u2014Event-triggered state estimation, Confidence\nlevel, Communication rate estimation, Discrete-time linear sys-\ntems, Sensor networks\n"
    },
    {
        "level": "##",
        "title": "I. Introduction",
        "content": "\nWith the development of wireless sensor network technology, wireless networked control systems (WNCS) have attracted increasing attention, and have been successfully applied in various fields such as control, signal processing, robotics, power electronics, etc [1]\u2212[6]. In WNCS, sensors, controllers, estimators and actuators are spatially distributed where sensor and estimator are usually far away from each other. In this case, the communication from sensor to remote estimator is costly because the communication requires consuming power of energy limited battery in the sensor where the battery is probably hard to replace due to its physical position.\n\nEvent-triggered scheme is an effective means to reduce sensorto-estimator communication cost since communication is not permitted unless a pre-defined triggered condition is satisfied.\n\nPrevious studies have shown that event-triggered scheme can strike a proper balance of trade-offs between communication cost and estimation performance [7]\u2212[10].\n\nAs a fundamental issue, event-triggered state estimation has been extensively studied [10]\u2212[24]. In [11], for a first order discrete-time linear system, the pre-processor and estimator were sought to minimize a cost with two terms. In [12], a centralized sensor network with multiple nodes were considered where each node yields measurement of the original system. Local event-triggered transmission strategies were developed, and the strategies's stability and performance were studied. For the balance between communication rate and state estimation performance, an event-triggered sensor data This work was partially supported by the National Nature Science Foundation of China (6207312).\n\nWei Liu is with the School of Information and Electronic Engineering, Zhejiang Gongshang University, Hangzhou 310018, China (e-mail: intervalm@163.com).\n\nscheduler was presented in [10] where, for a specific threshold, this scheduler is determined by the H\u00a8older infinity-norm of the innovation's linear operation. Using an approximation technique in nonlinear filtering, an approximate MMSE state estimator was proposed. The results of [10] were extended in [14] and [15] where the results presented in [14] considered separate transmission for each element of the measurement, and measurements from multiple sensors with separate eventtriggering conditions for each measurement were studied in [15]. The measurement prediction variance was used in [16] to determine whether the measurement is transmitted. Based on this kind of measurement transmission, the state estimator was designed, and the corresponding Riccati equation with periodic behavior was developed. In [17], the set-valued Kalman filtering problem for additional information with stochastic uncertainty was studied, and it was applied to event-triggered estimation. Two stochastic event-triggered sensor schedules were proposed in [18] where one schedule depends on the current measurement, and the other one depends on the innovation. Based on the two schedules, the MMSE state estimators were proposed, and the communication rates were analyzed. The results of [18] were generalized and extended in [19] and [20], respectively, where single-sensor was generalized to the case of multi-sensor in [19], and a stochastic eventtriggered mechanism based on information-state contribution was proposed in [20]. More results about event-triggered state estimation were provided in [21]\u2212[24] and references therein.\n\nBecause additional information was introduced to the remote estimator when the measurement is not transmitted to the estimator, the state estimator developed in [10] can yield better performance. However, the results developed in [10] does not establish the connection between the innovation and the trigger threshold, which means the performance can be further improved through establishing a proper connection between them. So, it is necessary to propose an event-triggered scheme which can establish a proper connection of the innovation, the trigger threshold and other related parameters, and to design state estimator based on this scheme, which motivates our research.\n\nIn this paper, using the chi-square distribution, regular Gaussian assumption and the method of confidence level, we first propose an event-triggered scheme which establishes a proper connection of the tolerable upper bound of the innovation covariance, the innovation and the trigger threshold. However, the results proposed in [10] do not obtain any connection of these parameters. Also, to the best of the author's knowledge, the event-triggered scheme proposed in this paper is novel and different from the existing results. The novel event-triggered scheme paves the way for the design of state estimator with better performance.\n\nThen, based on the novel event-triggered scheme, a MMSE\nstate estimator is proposed in a recursive form. It is worth mentioning that, due to the use of the novel event-triggered scheme, the strategy in computing the error covariance of the proposed MMSE state estimator is different in contrast to the existing results. Two algorithms for estimating the communication rate of the proposed state estimator are developed where the first algorithm uses information with one-step delay, and the second algorithm utilizes information with two-step delay. As far as the author knows, the strategy used in the second algorithm, namely, using information with two-step delay, cannot be found in the existing results for estimating the communication rate of event-triggered state estimator. In addition, the simulation results show that the second algorithm yields a better communication rate estimation of the proposed state estimator, which means that the strategy of using information with two-step delay is effective. Due to using information with two-step delay, the proof of the second algorithm becomes very challenging. In order to prove the second algorithm, we first prove Lemma 4 and Theorem 2 in Appendix C, and then we prove the second algorithm in Appendix D.\n\nThe remainder of this paper is organized as follows. The system and problem under consideration are provided in Section II. We also present an event-triggered scheme in Section II. A MMSE state estimator based on the presented eventtriggered scheme is proposed in Section III. Two algorithms for estimating the communication rate of the proposed MMSE state estimator are developed in Section IV. In Section V, the performance and effectiveness of the proposed results, including the MMSE state estimator and the communication rate estimation algorithms, are demonstrated via a target tracking scenario. The conclusion is drawn in Section VI.\n\nNotation: The n-dimensional real Euclidean space is denoted by Rn, and N > 0 is used to denote the positive definite matrix N. For a matrix A, its transpose, determinant and inverse are represented by AT, |A| and A\u22121, respectively. The probability density function is denoted by f, and the n \u00d7 n identity matrix is denoted by In.\n\n\ufffd \u03a6(\u03b7)d\u03b7 is used to stand for\n\ufffd \u03a6(\u03b7)d\u03b71d\u03b72 \u00b7\u00b7\u00b7d\u03b7n where \u03b7 = (\u03b71,\u03b72,\u00b7\u00b7\u00b7 ,\u03b7n)T \u2208 Rn, and \u03a6(\u03b7) is a function of \u03b7. We use E[\u00b7] and Var(\u00b7) to stand for the expectation operation and the covariance operation, respectively.\n"
    },
    {
        "level": "##",
        "title": "Ii. Problem Formulation A. System Description",
        "content": "\nConsider the following system\n\n$$X_{k+1}=Ax_{k}+\\omega_{k},\\tag{1}$$ $$Y_{k}=Cx_{k}+\\omega_{k},k=0,1,\\cdots\\tag{2}$$\nwhere xk \u2208 Rn is the unknown state; \u03c9k \u2208 Rn is the process noise; yk \u2208 Rp is the measurement; \u03c5k \u2208 Rp is the measurement noise; A and C are matrices of appropriate dimensions; and the initial state x0 is a random vector with mean \u00afx0 and covariance matrix \u00afP0.\n\nThroughout the paper, we introduce the following two assumptions.\n\n1) \u03c9k and \u03c5k are zero-mean white Gaussian noise sequences with covariance matrices Q and R, respectively.\n2) \u03c9k is independent of \u03c5k, and x0 is independent of \u03c9k\nand \u03c5k.\nConsidering the event-triggered state estimation problem whose structure is given in Fig. 1. \u03b3k has two possible values\n0 and 1, and the value of \u03b3k is determined by the trigger scheme. When \u03b3k = 1, the measurement yk is transmitted to the estimator via network, and the information Ik available for the estimator is Ik = (Ik\u22121,yk). When \u03b3k = 0, there is no data tramission, and the information Ik available for the estimator is Ik = (Ik\u22121,\u03b3k = 0). Hence, we have Ik =\n\ufffd\n(Ik\u22121,\u03b3k = 0),\n\u03b3k = 0;\n(Ik\u22121,yk),\n\u03b3k = 1\nwith I0 =\n\ufffd\n(\u03b30 = 0),\n\u03b30 = 0;\n(y0),\n\u03b30 = 1\n.\n\nThe trigger scheme is based on confidence level, and it will\nbe proposed in the next part.\n  Remark 1: For a joint probability density function f(x,y) in\nprobability theory, f(x = a,y = b) denotes the joint probability\ndensity of x and y given (x = a,y = b) where (x = a,y = b)\nstands for {x = a} \u2229 {y = b} instead of {x = a} \u222a {y = b}.\nAs an extension, the conditional probability density of x = a\ngiven y = b is defined as f(x = a|y = b) = f(x=a,y=b)\n\n                                                                                        f(y=b)\n                                                                                                       . It has to\nbe said that the conditional probability f(x = a|y = b) is not\nequal to f(x=a\u222ay=b)\n\nf(y=b)\n               , that is, f(x = a|y = b) \u0338= f(x=a\u222ay=b)\n\n                                                                                            f(y=b)\n                                                                                                            , where\n(x = a\u222ay = b) denotes {x = a}\u222a{y = b} which is the union of\ntwo random variables. The conditional probability was used in\nthe wrong way in [10], which expressed the probability density\nwith the union of two random variables. For example, in [10],\nthe term f\u03b5k(\u03b5|Ik\u22121) is equal to\n                                                                   f(\u03b5k=\u03b5\u222aIk\u22121)\n\n                                                                        f(Ik\u22121)\n                                                                                        , and f\u03b5k(\u03b5|Ik\u22121)\nis obviously not equal to the conditional probability density\nof \u03b5k = \u03b5 given Ik\u22121. However, the term f\u03b5k(\u03b5|Ik\u22121) was used\nas the conditional probability density, that is, the results were\ndeveloped based on the condition\n                                                                       f(\u03b5k=\u03b5\u222aIk\u22121)\n\nf(Ik\u22121)\n                 = f(\u03b5k=\u03b5,Ik\u22121)\n\n                                                                                                         f(Ik\u22121)\n                                                                                                                         .\nHence, the correctness of the corresponding results presented\nin [10] is doubtful unless the information Ik\u22121 \u2229 {\u03b3k = 0} is\nused to replace Ik\u22121 \u222a{\u03b3k = 0}.\n    Remark 2: In\n                                       [18],\n                                                        Ik\n                                                                  is\n                                                                             defined\n                                                                                                  by\n                                                                                                               Ik\n                                                                                                                      \u225c\n{\u03b30,\u03b31,\u00b7\u00b7\u00b7 ,\u03b3k,\u00b7\u00b7\u00b7 ,\u03b30y0,\u03b31y1,\u03b3kyk} = {Ik\u22121,\u03b3k,\u03b3kyk}. Because\nthe relation between Ik\u22121, \u03b3k and \u03b3kyk in Ik is not clearly\nstated, we first assume that Ik = Ik\u22121 \u2229 (\u03b3k \u222a \u03b3kyk). Then, we\n\nhave \u03b3k \u222a \u03b3kyk =\n                \ufffd\n                   \u03b3k = 0,\n                                \u03b3k = 0;\n                   (\u03b3k = 1)\u222ayk,\n                                \u03b3k = 1\n                                        , which means\n\nthat\n      Ik =\n             \ufffd Ik\u22121 \u2229(\u03b3k = 0),\n                                          \u03b3k = 0;\n                Ik\u22121 \u2229\n                       \ufffd\n                        (\u03b3k = 1)\u222ayk\n                                      \ufffd\n                                       ,\n                                          \u03b3k = 1\n                                                   .\n                                                      We\n                                                            easily\n\nsee that, under the above assumption, Ik is equal to the\ndescription presented in [18] for \u03b3k = 0, but is not equal to\nthat for \u03b3k = 1. Second, we assume that Ik = Ik\u22121 \u2229(\u03b3k \u2229\u03b3kyk).\nThen, we get \u03b3k \u2229 \u03b3kyk = 0 in \u03b3k = 0. As a result, we derive\nIk = Ik\u22121 in \u03b3k = 0. It is obvious that, under the assumption\nof Ik = Ik\u22121 \u2229 (\u03b3k \u2229 \u03b3kyk), Ik is not equal to the description\npresented in [18] for \u03b3k = 0. Hence, no matter how we choose\nthe relation between Ik\u22121, \u03b3k and \u03b3kyk, Ik cannot completely\n\nembody\n       the\n           description\n                     Ik =\n                         \ufffd (Ik\u22121,\u03b3k = 0),\n                                        \u03b3k = 0;\n                           (Ik\u22121,yk),\n                                        \u03b3k = 1\npresented\n        in\n           [18].\n                This\n                     means\n                            that\n                                the\n                                    definition\n                                             of\nIk \u225c {\u03b30,\u03b31,\u00b7\u00b7\u00b7 ,\u03b3k,\u00b7\u00b7\u00b7 ,\u03b30y0,\u03b31y1,\u03b3kyk} given in [18] is not\nrigorous.\n"
    },
    {
        "level": "##",
        "title": "B. Event-Triggered Scheme Based On Confidence Level",
        "content": "\nIn order to propose the event-triggered scheme based on confidence level, we first present the following two remarks and one lemma.\n\nRemark 3: Let w \u2208 Rp be a Gaussian random vector with mean \u00afw and covariance matrix S. Then, it was presented in Result 4.7 of [28] that (w \u2212 \u00afw)TS\u22121(w \u2212 \u00afw) obeys the distribution of \u03c72\np where \u03c72\np stands for the chi-square distribution with p degrees of freedom.\n\nRemark 4: Let \u00b51, \u00b52, \u00b7\u00b7\u00b7, \u00b5m be Gaussian and mutually independent. Then, it is well known that the linear combination of \u00b51, \u00b52, \u00b7\u00b7\u00b7, \u00b5m is still Gaussian.\n\nLemma 1: Under the assumption that f(xk\u22121|Ik\u22121) is Gaussian, it holds that:\n1). f(xk|Ik\u22121) is Gaussian.\n\n2). f(yk|Ik\u22121) is Gaussian.\n\nProof: See Appendix A.\n\nFor notational simplicity, define\n\n$$\\hat{V}_{k,k-1}\\stackrel{{\\Delta}}{{=}}\\mbox{E}[y_{k}|\\mbox{I}_{k-1}],\\tag{3}$$ $$\\hat{V}_{k}\\stackrel{{\\Delta}}{{=}}y_{k}-\\hat{V}_{k,k-1},$$ (4) $$N_{k}\\stackrel{{\\Delta}}{{=}}\\mbox{Var}(y_{k}|\\mbox{I}_{k-1}).\\tag{5}$$\nUnder the assumption that f(xk\u22121|Ik\u22121) is Gaussian, we see from 2) of Lemma 1 that f(yk|Ik\u22121) is Gaussian. Then, using Remark 3, we find that \u02dcyT\nk N\u22121\nk\n\u02dcyk is distributed as \u03c72\np where \u02dcyk and Nk are defined in (4) and (5), respectively. Let N > 0 be a tolerable upper bound of Nk. When Nk exceeds the tolerable upper bound, namely, Nk > N, we need to take \u03b3k = 1 so that Nk+1 does not exceed the tolerable upper bound. When Nk > N, we have\n\n$\\Phi_{k}>\\tilde{y}_{k}^{\\rm T}N_{k}^{-1}\\tilde{y}_{k}$ (6)\nwhere\n\n$\\Phi_{k}=\\tilde{\\Psi}_{k}\\Sigma_{k},\\Sigma=\\overline{N}^{-1}$.\n\nLet \u03c72\n\u03b1(p) denote the upper (l00\u03b1)th percentile of the \u03c72\np distribution, that is, P\n\ufffd\n\u02dcyT\nk N\u22121\nk\n\u02dcyk \u2264 \u03c72\n\u03b1(p)\n\ufffd\n= 1 \u2212 \u03b1. In frequentist statistics, the 95% confidence level is the most often.\n\nHence, we can take 1 \u2212 \u03b1 = 0.95 in confidence level for\n\u02dcyT\nk N\u22121\nk\n\u02dcyk. Then, we conclude from the theory of confidence level that \u02dcyT\nk N\u22121\nk\n\u02dcyk does not obey the \u03c72\np distribution if\n\n\u02dcyT\n k N\u22121\n    k\n       \u02dcyk > \u03c72\n                \u03b1(p). Then, using (6), we get \u03d5k > \u02dcyT\n                                                               k N\u22121\n                                                                  k\n                                                                      \u02dcyk >\n\u03c72\n \u03b1(p) =\u21d2 \u03d5k > \u03c72\n                       \u03b1(p) when Nk > N. Based on the above\ndiscussion, we present the following event-triggered scheme:\n\n$$\\gamma_{k}=\\begin{cases}\\gamma_{k}=0,&\\varphi_{k}\\leq\\chi_{\\alpha}^{2}(p);\\\\ \\gamma_{k}=1,&\\varphi_{k}>\\chi_{\\alpha}^{2}(p).\\end{cases}\\tag{8}$$\nwhere 1 \u2212 \u03b1 = 0.95 is suggested to be taken considering the theory of confidence level. Since \u03a3 is positive definite, \u03a3 can be expressed as \u03a3 = \u03a6T\u03a6 such that \u03a6 is invertible. Then, using (7) and noticing yk \u2208 Rp, we have\n\n$$\\varphi_{k}=\\tilde{y}_{k}^{\\rm T}\\Sigma\\tilde{y}_{k}=\\tilde{y}_{k}^{\\rm T}\\Phi^{\\rm T}\\Phi\\tilde{y}_{k}=\\tilde{z}_{k}^{\\rm T}\\tilde{z}_{k}=\\sum_{i=1}^{P}\\tilde{z}_{k,i}^{2}\\tag{9}$$\nwhere\n\n$\\mathbb{Z}_{k}\\stackrel{{\\Delta}}{{=}}\\Phi\\mathbb{Y}_{k}$ (10)\nand zk,i denotes the ith element of zk.\n\nRemark 5: An advantage of the event-triggered scheme proposed in this paper is that a proper connection of the tolerable upper bound N, the innovation \u02dcyk and the trigger threshold \u03c72\n\u03b1(p) is established via confidence level and chisquare distribution, which leads to the performance improvement of the state estimator proposed in Section III in contrast to the state-of-the-art state estimator proposed in [10]. However, the event-triggered schemes provided in [10] and [17] do not establish any connection of these parameters. Also, the proposed event-triggered scheme is novel and different those presented in [11]\u2212[16] and [18]\u2212[27].\n\nLet \u02c6xk \u225c E[xk|Ik] which is the optimal MMSE estimate of xk given Ik. The rest of the study has two main objectives.\n\nThe first objective is to design a MMSE state estimator using the above event-triggered scheme based on confidence level, which can recursively compute \u02c6xk under a regular assumption.\n\nThe second objective is to develop two algorithms for estimating the communication rate of the proposed MMSE state estimator.\n"
    },
    {
        "level": "##",
        "title": "Iii. Mmse State Estimation",
        "content": "\nIn this section, we study the MMSE state estimation problem based on the event-triggered scheme. More precisely, the computational strategy for the MMSE estimate \u02c6xk is studied in the section. For notational simplicity, let\n\n$$P_{k}\\stackrel{{\\triangle}}{{=}}\\text{Var}(x_{k}|\\text{I}_{k}),\\tag{11}$$ $$\\Omega_{k}\\stackrel{{\\triangle}}{{=}}\\{z_{k}\\in\\mathbb{R}^{P}|\\varphi_{k}\\leq\\chi_{\\alpha}^{2}(p)\\},$$ (12) $$\\hat{x}_{k}^{[z]}\\stackrel{{\\triangle}}{{=}}\\text{E}[x_{k}|\\text{I}_{k-1},z_{k}],$$ (13) $$P_{k}^{[z]}\\stackrel{{\\triangle}}{{=}}\\text{Var}(x_{k}|\\text{I}_{k-1},z_{k}),$$ (14) $$\\hat{x}_{k,k-1}\\stackrel{{\\triangle}}{{=}}\\text{E}[x_{k}|\\text{I}_{k-1}],$$ (15) $$\\hat{x}_{k}\\stackrel{{\\triangle}}{{=}}x_{k}-\\hat{x}_{k,k-1},$$ (16) $$M_{k}\\stackrel{{\\triangle}}{{=}}\\text{Var}(x_{k}|\\text{I}_{k-1}),$$ (17) $$N_{k}^{[z]}\\stackrel{{\\triangle}}{{=}}\\text{Var}(z_{k}|\\text{I}_{k-1}),$$ (18) $$K_{k}\\stackrel{{\\triangle}}{{=}}\\text{E}\\Big{[}\\tilde{x}_{k}(z_{k}-\\text{E}[z_{k}|\\text{I}_{k-1}])^{\\text{T}}\\Big{]}\\big{(}N_{k}^{[z]}\\big{)}^{-1}.\\tag{19}$$ _Lemma 2:_ Under the assumption that $f(x_{k-1}|\\mathrm{I}_{k-1})$ is Gaussian, it holds that:\n\n1. $f(z_{k}|\\mathrm{I}_{k-1})$ is Gaussian.\n2. $f(z_{k}|\\mathrm{I}_{k-1})=\\frac{g(z_{k})}{(2\\pi)^{0.5p}\\left|N_{k}^{[z]}\\right|^{1.5}}$ with\n\n$$g(z_{k})\\triangleq\\exp\\{-\\,0.5z_{k}^{\\mathrm{T}}(N_{k}^{[z]})^{-1}z_{k}\\}.$$\n\n_Proof:_ See Appendix A.\n\n_Lemma 3:_ Under the assumption that $f(x_{k-1}|\\mathrm{I}_{k-1})$ is Gaussian, it holds that:\n\n1. $\\int_{\\Omega_{k}}f(z_{k}|\\mathrm{I}_{k-1})dz_{k}=\\frac{h_{k}}{(2\\pi)^{0.5p}\\left|N_{k}^{[z]}\\right|^{0.5}}$ where\n\n$$h_{k}=\\int\\limits_{-b}^{\\tilde{b}}dz_{k,1}\\int\\limits_{-\\tilde{z}_{k,1}}^{\\tilde{z}_{k,2}}dz_{k,3}\\cdots\\int\\limits_{-\\tilde{z}_{k,p-1}}g(z_{k})dz_{k,p}$$\nwith\n\n$$\\chi_{\\alpha}^{2}(p)-z_{k,1}^{2},$$ $$\\tilde{b}\\triangleq\\sqrt{\\chi_{\\alpha}^{2}(p),\\tilde{z}_{k,1}}\\triangleq\\sqrt{\\cdot}$$\n\u02c7zk,2 \u225c\n\ufffd\n\n\u03c72\u03b1(p)\u2212 2 \u2211 i=1 z2 k,i,\u00b7\u00b7\u00b7 , \u02c7zk,p\u22121 \u225c p\u22121 \u2211 i=1 z2 k,i.\n\n\ufffd\n\ufffd\n\ufffd\n\ufffd\u03c72\u03b1(p)\u2212\n\n2).\n   \ufffd\n    \u03a9k f(zk|Ik\u22121)zkzT\n                      k dzk =\n                                    \u03a8k\n\n(2\u03c0)0.5p\ufffd\ufffdN[z] k \ufffd\ufffd0.5 with \u03a8k = (\u03c8k,ij)p\u00d7p where \u03c8k,ij = \u2212\u02c7zk,1 dzk,2 \u00b7\u00b7\u00b7 \u2212\u02c7zk,p\u22121 g(zk)zk,izk,jdzk,p. \u2212\u02c7b dzk,1 \u02c7b\ufffd \u02c7zk,1 \ufffd \u02c7zk,p\u22121 \ufffd\nProof: See Appendix A.\n\nConsidering that \u03b3k has two possible values 0 and 1, we deal with the problem under the following two cases:\n1) \u03b3k = 1. Noticing the definition of Ik, we have Ik =\n(Ik\u22121,yk). Then, using Kalman filter, we derive\n\n\u02c6xk =\u02c6xk,k\u22121 + MkCT(CMkCT + R)\u22121 \u02dcyk, (20) Pk =Mk \u2212 MkCT(CMkCT + R)\u22121CMk (21)\nwhere \u02dcyk = yk \u2212C\u02c6xk,k\u22121, \u02c6xk,k\u22121 = A\u02c6xk\u22121 and Mk = APk\u22121AT +\nQ.\n\n2) \u03b3k = 0. We have Ik = (Ik\u22121,\u03b3k = 0) when \u03b3k = 0. Then, we present the following theorem to compute \u02c6xk in \u03b3k = 0.\n\nTheorem 1: When f(xk\u22121|Ik\u22121) is Gaussian, the MMSE\nstate estimation \u02c6xk and the corresponding error covariance Pk in\n\u03b3k = 0 can be computed according to the following equalities:\n\n\u02c6xk =\u02c6xk,k\u22121, (22) Kk =MkCT(CMkCT + R)\u22121\u03a6\u22121, (23) P[z] k =Mk \u2212 MkCT(CMkCT + R)\u22121CMk, (24) Pk =P[z] k + 1 hk Kk\u03a8kKT k . (25)\nProof: See Appendix B.\n\nRemark 6: In fact, \u02c6xk in (22) of Theorem 1 should be com-\n\u03c8k\n\nputed via \u02c6xk = \u02c6xk,k\u22121+ek with ek \u225c\n                                   Kk\n                                      \ufffd\n                                     \ufffd \u03a9k f(zk|Ik\u22121)zkdzk\n                                      \u03a9k f(zk|Ik\u22121)dzk\n                                                      in which\n\ufffd\n \u03a9k f(zk|Ik\u22121)zkdzk can be obtained via\n                                         \ufffd\n                                          \u03a9k f(zk|Ik\u22121)zkdzk =\n\n(2\u03c0)0.5p\ufffd\ufffdN[z]\n           k\n              \ufffd\ufffd0.5 where \u03c8k = (\u03c8k,1,\u03c8k,2,\u00b7\u00b7\u00b7 ,\u03c8k,p)T with \u03c8k,i =\n\n\u2212\u02c7zk,1\ndzk,2 \u00b7\u00b7\u00b7\n\u2212\u02c7zk,p\u22121\ng(zk)zk,idzk,p, i = 1,2,\u00b7\u00b7\u00b7 , p. Since \u03c8k is\n\u2212\u02c7b dzk,1\n\u02c7zk,1\n\ufffd\n\u02c7zk,p\u22121\n\ufffd\n\u02c7b\ufffd\nalmost equal to zero vector, we conclude that ek is almost equal to zero vector. Hence, \u02c6xk in Theorem 1 is calculated using (22).\n\nNow, we can present the MMSE state estimator.\n\nStarting with \u02c6xk\u22121 and Pk\u22121, the MMSE state estimator includes the following two steps.\n\nStep 1: Compute \u02c6xk,k\u22121, \u02dcyk, Mk, hk and \u03a8k according to\n\n$$\\hat{X}_{k,k-1}=\\hat{A}\\hat{X}_{k-1},\\tag{26}$$ $$\\hat{Y}_{k}=\\mathcal{Y}_{k}-C\\hat{X}_{k,k-1},$$ (27) $$M_{k}=AP_{k-1}A^{\\mathrm{T}}+Q,$$ (28) $$N_{k}^{[\\hat{z}]}=\\Phi(CM_{k}C^{\\mathrm{T}}+R)\\Phi^{\\mathrm{T}},$$ (29) $$h_{k}=\\int\\limits_{\\begin{array}{c}\\hat{b}\\\\ -\\hat{b}\\end{array}}^{\\hat{b}}dz_{k,1}\\int\\limits_{\\begin{array}{c}\\hat{z}_{k,p-1}\\\\ -\\hat{z}_{k,p-1}\\end{array}}^{\\hat{z}_{k,p-1}}g(z_{k})dz_{k,p},$$ (30) $$\\Psi_{k,ij}=\\int\\limits_{\\begin{array}{c}\\hat{b}\\\\ -\\hat{b}\\end{array}}^{\\hat{b}}dz_{k,1}\\int\\limits_{\\begin{array}{c}\\hat{z}_{k,p-1}\\\\ -\\hat{z}_{k,p-1}\\end{array}}^{\\hat{z}_{k,p-1}}g(z_{k})z_{k,i}\\bar{z}_{k,j}dz_{k,p},$$ (31) \\[\\Psi_{k}=(\\,\\\nwhere g(zk) is defined in 2) of Lemma 2, as well as \u02c7b and \u02c7zk,i with i = 1,2,\u00b7\u00b7\u00b7 , p \u2212 1 are defined in 1) of Lemma 3.\n\nStep 2: Compute \u02c6xk and Pk in terms of\n\n$$P_{k}^{[z]}=M_{k}-M_{k}C^{\\rm T}(CM_{k}C^{\\rm T}+R)^{-1}CM_{k},\\tag{33}$$ $$\\hat{x}_{k}=\\hat{x}_{k,k-1}+\\gamma_{k}M_{k}C^{\\rm T}(CM_{k}C^{\\rm T}+R)^{-1}\\tilde{y}_{k},$$ (34) $$K_{k}=M_{k}C^{\\rm T}(CM_{k}C^{\\rm T}+R)^{-1}\\Phi^{-1},$$ (35) $$P_{k}=P_{k}^{[z]}+\\frac{(1-\\gamma_{k})}{h_{k}}K_{k}\\Psi_{k}K_{k}^{\\rm T}\\tag{36}$$\nwhere \u03b3k is determined by (8) and (7). For the proposed MMSE\nstate estimator, we easily see that we only need to prove (34) and (36) where we easily obtain (34) by using (20) and (22).\n\nUsing (21) and (24), we see that\n\n$P_{k}=P_{k}^{[z]}$ when $\\gamma_{k}=1$. (37)\nPutting (37) and (25) together, we prove (36).\n\nRemark 7: The results for MMSE state estimation problem based on different event-triggered schemes were presented in [10], [14], [15], [16], [18], [19], [21], [22], [23] and [27]. However, compared with the results, the MMSE state estimator presented in this paper has a different strategy in computing the error covariance Pk because a novel confidence level based event-triggered scheme is applied to the design of the MMSE state estimator.\n\nRemark 8: For the MMSE state estimator presented in\n(26)\u2212(36), we need to know the initial conditions \u02c6x0 and P0.\n\nHence, we present the following scheme to obtain \u02c6x0 and P0.\n\n\u02c6x0 and P0 can be computed according to\n\n$$\\hat{\\lambda}_{0}=\\bar{x}_{0}+\\gamma_{0}\\bar{P}_{0}C^{\\rm T}(C\\bar{P}_{0}C^{\\rm T}+R)^{-1}(y_{0}-C\\bar{x}_{0}),\\tag{38}$$\n\n$$\\bar{N}_{0}^{[z]}=\\Phi(C\\bar{P}_{0}C^{\\rm T}+R)\\Phi^{\\rm T},\\tag{39}$$ $$\\bar{\\Psi}_{0,ij}=\\int\\limits_{\\begin{array}{c}b\\\\ -b\\end{array}}dz_{0,1}\\int\\limits_{\\begin{array}{c}z_{0,p-1}\\\\ -\\bar{z}_{0,p-1}\\end{array}}\\rho(z_{0})z_{0,i}z_{0,j}dz_{0,p},\\tag{40}$$ $$\\bar{\\Psi}_{0}=(\\bar{\\Psi}_{0,ij})_{p\\times p},$$ (41) $$\\alpha_{0}=\\int\\limits_{\\begin{array}{c}b\\\\ dz_{0,1}\\int dz_{0,2}\\cdots\\int\\limits_{\\begin{array}{c}z_{0,p-1}\\\\ -\\bar{z}_{0,1}\\end{array}}\\rho(z_{0})dz_{0,p},$$ (42) $$\\bar{K}_{0}=\\bar{P}_{0}C^{\\rm T}(C\\bar{P}_{0}C^{\\rm T}+R)^{-1}\\Phi^{-1},$$ (43) $$P_{0}^{[z]}=\\bar{P}_{0}-\\bar{P}_{0}C^{\\rm T}(C\\bar{P}_{0}C^{\\rm T}+R)^{-1}C\\bar{P}_{0},$$ (44) $$P_{0}=P_{0}^{[z]}+\\frac{(1-\\gamma_{0})}{\\alpha_{0}}\\bar{K}_{0}\\bar{\\Psi}_{0}\\bar{K}_{0}^{\\rm T}\\tag{45}$$\nwhere \u03b30 is determined by (8) with \u03d50 = (y0 \u2212C \u00afx0)T\u03a3(y0 \u2212\nC \u00afx0), as well as\n\u03b10 \u225c\n\ufffd\n\u03a90 \u03c1(z0)dz0,\n\u03c1(z0) \u225c exp\n\ufffd\n\u2212\n0.5zT\n0( \u00afN[z]\n0 )\u22121z0\n\ufffd\n, \u00afN[z]\n0 \u225c Var(z0) and \u00afK0 \u225c Cov(x0,z0)\n\ufffd \u00afN[z]\n0\n\ufffd\u22121.\n\nMaking reference to the derivation of the MMSE state estimator, we can easily obtain (38)\u2212(45).\n\nIV. COMMUNICATION RATE ESTIMATION\nIn this section, we study the communication rate estimation problem for the proposed MMSE state estimator. More precisely, we will present two strategies for approximately computing E[\u03b3k].\n\nE[\u03b3k] can be expressed as\n\n$$\\begin{array}{l}\\mbox{E}[\\gamma_{k}]=0\\times P(\\gamma_{k}=0)+1\\times P(\\gamma_{k}=1)\\\\ =P(\\gamma_{k}=1)=1-P(\\gamma_{k}=0)\\end{array}\\tag{46}$$\nwhere\n\nP(\u03b3k = 0) = \ufffd f(\u03b3k = 0,Ik\u22121)dIk\u22121 = \ufffd f(Ik\u22121)P(\u03b3k = 0|Ik\u22121)dIk\u22121. (47)\nRemark 9: From (47), we see that the computation of P(\u03b3k = 0) is intractable because the computational complex of\n\ufffd f(Ik\u22121)P(\u03b3k = 0|Ik\u22121)dIk\u22121 increases with k. Then, it follows from (46) that the computation of E[\u03b3k] is intractable.\n\nIn order to approximately compute E[\u03b3k], we will use two types of approximations where one type of approximation is E[\u03b3k] \u2248 E[\u03b3k|Ik\u22121], and the other one is E[\u03b3k] \u2248 E[\u03b3k|Ik\u22122]. We will present a strategy for computing E[\u03b3k|Ik\u22121] and E[\u03b3k|Ik\u22122], and we will test the two different approximations for E[\u03b3k] in Section V-A.\n\nFor notational simplicity, let\n\n\u02c6\u03b3k,k\u2212i \u225cE[\u03b3k|Ik\u2212i], (48) Pk,k\u2212i(0) \u225cP(\u03b3k = 0|Ik\u2212i), (49) \u20d7P[z] k (0) \u225cP(\u03b3k = 0|Ik\u22122,zk\u22121), (50) \u02d8Pk(0) \u225cP(\u03b3k = 0|Ik\u22122,\u03b3k\u22121 = 0), (51) \u02c6z\u22b2 k,k\u22121 \u225cE[zk|Ik\u22122,zk\u22121], (52) \u02dcz\u22b2 k \u225czk \u2212 \u02c6z\u22b2 k,k\u22121, (53) \u20d7N[z] k \u225cVar(zk|Ik\u22122,zk\u22121), (54) \u02c6zk,k\u22121(0) \u225cE[zk|Ik\u22122,\u03b3k\u22121 = 0], (55) Nk(0) \u225cVar(zk|Ik\u22122,\u03b3k\u22121 = 0), (56) $$\\Omega_{k}\\stackrel{{\\Delta}}{{=}}\\{z_{k}\\in\\mathbb{R}^{P}|\\varphi_{k}>\\chi_{\\alpha}^{2}(p)\\}\\tag{57}$$\nwith i = 1,2.\n\nStarting with \u02c6xk\u22121 and Pk\u22121, \u02c6\u03b3k,k\u22121 can be recursively computed according to Algorithm 1. For Algorithm 1, we only\n"
    },
    {
        "level": "##",
        "title": "Algorithm 1 : Communication Rate Based On Information Up To K \u2212 1 Step 1: Compute \u02c6\u0393k,K\u22121 According To",
        "content": "\n$$P_{k,k-1}(0)=\\frac{h_{k}}{(2\\pi)^{0.5p}|N_{k}^{[\\bar{z}]}|0.5}\\,^{\\dagger}\\tag{58}$$ $$\\hat{\\gamma}_{k,k-1}=1-P_{k,k-1}(0)\\tag{59}$$\nwhere N[z]\nk and hk are computed using (28)\u2212(30) in sequence.\n\nStep 2: Compute and store \u02c6xk and Pk for the derivation of \u02c6\u03b3k+1,k where \u02c6xk and Pk are computed via (26)\u2212(36) in sequence.\n\nneed to prove (58) and (59). P(\u03b3k = 0|Ik\u22121) can be rewritten as\n\n$$P(\\gamma_{k}=0|\\mathrm{I}_{k-1})=P(z_{k}\\in\\Omega_{k}|\\mathrm{I}_{k-1})$$ $$=\\int_{\\Omega_{k}}f(z_{k}|\\mathrm{I}_{k-1})dz_{k}=\\frac{h_{k}}{(2\\pi)^{0.5p}\\left|N_{k}^{[z]}\\right|^{0.5}}\\tag{60}$$ $$\\mathrm{st\\ equality\\ is\\ due\\ to\\ 1}$$ $$\\mathrm{I}_{k-1})\\ \\mathrm{by}\\ P_{k-1}(0)\\ \\mathrm{we}$$\nwhere \u03a9k is defined in (12), and the last equality is due to 1)\nof Lemma 3. Then, replacing P(\u03b3k = 0|Ik\u22121) by Pk,k\u22121(0), we prove (58). Making reference to (46), we easily obtain (59).\n\nIn order to compute \u02c6\u03b3k,k\u22122, we propose the following theorem.\n\nTheorem 2: When f(xk\u22121|Ik\u22121) is Gaussian, \u02c6\u03b3k,k\u22122 can be computed in terms of the following equalities:\n\n\u20d7N[z] k =\u03a6 \ufffd C(AP[z] k\u22121AT + Q)CT + R)\u03a6T, (61) hk\u22121 Kk\u22121\u03a8k\u22121KT k\u22121)AT + Q \ufffd CT + R \ufffd Nk(0) = \u03a6 \ufffd C \ufffd A(P[z] k\u22121 + 1 \u00d7 \u03a6T, (62) f(zk|Ik\u22122,zk\u22121) = \u20d7g(zk) f(zk|Ik\u22122,zk\u22121) = \u20d7g(zk) (2\u03c0)0.5p\ufffd\ufffd\u20d7N[z] k \ufffd\ufffd0.5 , (63) f(zk|Ik\u22122,\u03b3k\u22121 = 0) = \u02d8g(zk) (2\u03c0)0.5p\ufffd\ufffd\u20d7N[z] k \ufffd\ufffd0.5 , (64) (2\u03c0)0.5p\ufffd\ufffdNk(0) \ufffd\ufffd0.5 , (65) \u03a9k f(zk|Ik\u22122,zk\u22121)dzk, (66) \u20d7P[z] k (0) = \ufffd \u03a9k f(zk|Ik\u22122,\u03b3k\u22121 = 0)dzk, (67) \u02d8Pk(0) = \ufffd \u02d8\u03a9k\u22121 \u20d7P[z] k (0)f(zk\u22121|Ik\u22122)dzk\u22121, Pk,k\u22122(0) =Pk\u22121,k\u22122(0) \u02d8Pk(0)+ \ufffd (68) \u02c6\u03b3k,k\u22122 =1 \u2212 Pk,k\u22122(0) (69) where $$\\vec{g}(z_{k})\\stackrel{{\\triangle}}{{=}}\\exp\\bigl{\\{}-\\,0.5z_{k}^{\\mathrm{T}}(\\vec{N}_{k}^{[z]})^{-1}z_{k}\\bigr{\\}},$$ $$\\vec{g}(z_{k})\\stackrel{{\\triangle}}{{=}}\\exp\\bigl{\\{}-\\,0.5z_{k}^{\\mathrm{T}}N_{k}(0)^{-1}z_{k}\\bigr{\\}}.\\tag{70}$$\n\n_Proof:_ See Appendix C.\n\nBased on the above discussion, we present an algorithm to compute $\\hat{\\gamma}_{k,k-2}$ in a recursive structure. Starting with $P_{k-1}^{[c]}$, $h_{k-1},\\ K_{k-1},\\ \\Psi_{k-1},\\ \\hat{x}_{k-1},\\ P_{k-1}$ and $P_{k-1,k-2}(0),\\ \\hat{\\gamma}_{k,k-2}$ can be recursively computed according to Algorithm 2 where the proof of Algorithm 2 is presented in Appendix D.\n"
    },
    {
        "level": "##",
        "title": "Algorithm 2 : Communication Rate Based On Information Up To K \u2212 2",
        "content": "\nStep 1: Compute \u20d7N[z]\nk and Nk(0) using (61) and (62), respectively.\n\nStep 2: Compute \u20d7P[z]\nk (0) and \u02d8Pk(0) according to\n\n$$\\begin{array}{c}\\tilde{b}\\\\ \\tilde{b}\\\\ \\tilde{R}_{k}^{[z]}(0)=\\frac{-\\tilde{b}}{\\tilde{b}}\\\\ \\tilde{R}_{k}^{[z]}(0)=\\frac{-\\tilde{b}}{\\tilde{b}}\\\\ \\tilde{R}_{k}^{[z]}(0)=\\frac{-\\tilde{b}}{\\tilde{b}}\\\\ \\tilde{R}_{k}^{[z]}(0)=\\frac{-\\tilde{b}}{\\tilde{b}}\\\\ \\tilde{R}_{k}^{[z]}(0)=\\frac{-\\tilde{b}}{\\tilde{b}}\\\\ \\tilde{R}_{k}^{[z]}(0)=\\frac{-\\tilde{b}}{\\tilde{b}}\\\\ \\tilde{R}_{k}^{[z]}(0)=\\frac{-\\tilde{b}}{\\tilde{b}}\\\\ \\tilde{R}_{k}^{[z]}(0)=\\frac{-\\tilde{b}}{\\tilde{b}}\\\\ \\tilde{R}_{k}^{[z]}(0)=\\frac{-\\tilde{b}}{\\tilde{b}}\\\\ \\tilde{R}_{k}^{[z]}(0)=\\frac{-\\tilde{b}}{\\tilde{b}}\\\\ \\tilde{R}_{k}^{[z]}(0)=\\frac{-\\tilde{b}}{\\tilde{b}}\\\\ \\tilde{R}_{k}^{[z]}(0)=\\frac{-\\tilde{b}}{\\tilde{b}}\\\\ \\tilde{R}_{k}^{[z]}(0)=\\frac{-\\tilde{b}}{\\tilde{b}}\\\\ \\tilde{R}_{k}^{[z]}(0)=\\frac{-\\tilde{b}}{\\tilde{b}}\\\\ \\tilde{R}_{k}^{[z]}(0)=\\frac{-\\tilde{b}}{\\tilde{b}}\\\\ \\end{array}\\tag{71}$$\nwhere \u20d7g(zk) and \u02d8g(zk) are defined in (70).\n\nStep 3: Compute Pk,k\u22122(0) using\n\n$$P_{k,k-2}(0)=\\vec{P}_{k}^{[z]}(0)+P_{k-1,k-2}(0)\\big{(}\\vec{P}_{k}(0)-\\vec{P}_{k}^{[z]}(0)\\big{)}.\\tag{73}$$\n\n**Step 4:** Compute $\\hat{\\gamma}_{k,k-2}$ in terms of (69).\n\n**Step 5:** For computing the communication rate at time step $k+1$, update $P_{k}^{[z]}$, $h_{k}$, $K_{k}$, $\\Psi_{k}$, $\\hat{x}_{k}$, $P_{k}$ and $P_{k,k-1}(0)$ using the MMSE state estimator presented in (26)$-$(36) and using (58).\n\n  Remark 10: Under the assumption that\n                                       f(xk\u22121|Ik\u22121) is\nGaussian, we obtain \u02c6\u03b3k,k\u22122 using Algorithm 2 in a recursive\nform where the proof of the algorithm is very challenging.\nIn order to prove Algorithm 2, Lemma 4 and Theorem 2 are\nfirst proved in Appendix C, and then Algorithm 2 is proved\nin Appendix D.\n  Remark 11: If we take the approximation E[\u03b3k] \u2248 \u02c6\u03b3k,k\u22121\nwhere \u02c6\u03b3k,k\u22121 can be obtained from Algorithm 1, we need to\nadditionally obtain E[\u03b30] since Algorithm 1 starts with k = 1.\nIn the same way, we need to know E[\u03b30] and E[\u03b31] if we take\nthe approximation E[\u03b3k] \u2248 \u02c6\u03b3k,k\u22122 using Algorithm 2. Hence,\nwe need to obtain E[\u03b30] and E[\u03b31].\nWe present a strategy for computing E[\u03b30] and E[\u03b31] with the\nfollowing content:\n\n$$P(\\gamma_{0}=0)=\\frac{\\alpha_{0}}{(2\\pi)^{0.5p}|\\tilde{N}_{0}^{[z]}|^{0.5}},\\tag{74}$$ $$\\mathrm{E}[\\gamma_{0}]=1-P(\\gamma_{0}=0),$$ (75) $$\\tilde{N}_{1}^{[z]}=\\Phi\\big{(}C(AP_{0}^{[z]}A^{\\mathrm{T}}+Q)C^{\\mathrm{T}}+R\\big{)}\\Phi^{\\mathrm{T}},$$ (76) $$\\tilde{N}_{1}(0)=\\Phi\\Big{(}C\\big{(}A(P_{0}^{[z]}+\\frac{1}{\\alpha_{0}}\\tilde{K}_{0}\\tilde{W}_{0}\\tilde{K}_{0}^{\\mathrm{T}})A^{\\mathrm{T}}+Q\\big{)}C^{\\mathrm{T}}+R\\Big{)}\\Phi^{\\mathrm{T}},\\tag{77}$$ $$\\begin{array}{c}\\stackrel{{b}}{{\\int}}dz_{1,1}\\stackrel{{z_{1,1}}}{{\\int}}dz_{1,2}\\cdots\\stackrel{{z_{1,p-1}}}{{\\int}}\\tilde{\\rho}(z_{1})dz_{1,p}\\\\ \\tilde{P}_{1}(0)=\\stackrel{{-b}}{{\\longrightarrow}}\\stackrel{{-z_{1,1}}}{{\\longrightarrow}}\\stackrel{{z_{1,p-1}}}{{\\longrightarrow}}\\stackrel{{z_{1,p-1}}}{{\\longrightarrow}},\\\\ \\stackrel{{b}}{{\\longrightarrow}}\\stackrel{{z_{1,1}}}{{\\int}}dz_{1,2}\\cdots\\stackrel{{z_{1,p-1}}}{{\\longrightarrow}}\\stackrel{{z_{1,p-1}}}{{\\longrightarrow}},\\\\ \\stackrel{{P[z]}}{{\\longrightarrow}}(0)=\\stackrel{{-b}}{{\\longrightarrow}}\\stackrel{{-z_{1,1}}}{{\\longrightarrow}}\\stackrel{{z_{1,p-1}}}{{\\longrightarrow}},\\\\ \\end{array}\\tag{78}$$\n\n\\[\\begin{array}{c}\\stackrel{{b}}{{\\longrightarrow}}\\stackrel{{z_{1,1}}}{{\\longrightarrow}}\\stackrel{{z_{1,p-1}}}{{\\longrightarrow}}\\stackrel{{z_{1,p-1}}}{{\\longrightarrow}} \\stackrel{{z_{1,p-1}}}{{\\longrightarrow}},\\\\ \\stackrel{{P[z]}}{{\\longrightarrow}}(0)=\\stackrel{{-b}}{{\\longrightarrow}}\\stackrel{{-z_{1,1}}}{{\\longrightarrow}}\\stackrel{{z_{1,p-1}}}{{\\longrightarrow}} \\stackrel{{z_{1,p-1}}}{{\\longrightarrow}},\\\\ \\\nwhere \u00afN[z]\n0 , \u03b10 and P[z]\n0 are computed using (39), (42) and (44);\nand \u00afN1(0) \u225c Var(z1|\u03b30 = 0), \u00afN[z]\n1 \u225c Var(z1|z0), \u02d8\u03c1(z1) \u225c exp\n\ufffd\n\u2212\n0.5zT\n1\n\ufffd \u00afN1(0)\n\ufffd\u22121z1\n\ufffd\n, \u20d7\u03c1(z1) \u225c exp\n\ufffd\n\u22120.5zT\n1\n\ufffd \u00afN[z]\n1\n\ufffd\u22121z1\n\ufffd\n, \u00afP1(0) \u225c\nP(\u03b31 = 0|\u03b30 = 0) and \u00afP[z]\n1 (0) \u225c P(\u03b31 = 0|z0). Making reference to the derivation of Algorithm 1, we easily derive (74). Using\n(46), we directly derive (75) and (81). Similar to the derivation of Algorithm 2, we easily obtain (76)\u2212(80).\n"
    },
    {
        "level": "##",
        "title": "V. Simulation Example",
        "content": "\nIn this section, we illustrate the performance of the MMSE\nstate estimator and the communication rate estimation algorithms proposed in this paper via a target tracking scenario including two parts. More precisely, we test the performance of the proposed results in Section V-A, and we compare the MMSE state estimator proposed in this paper with the state estimator proposed in [10] in Section V-B. The state estimator proposed in [10] is referred as SEHI considering that its eventtriggered scheduler is based on H\u00a8older infinity-norm.\n"
    },
    {
        "level": "##",
        "title": "A. Performance Evaluation Of The Proposed Results",
        "content": "\nConsider a target tracking problem [29] where the statespace formulation of the target can be written as (1) with\n\n$$x_{k}=\\left(\\begin{array}{c}p_{k}\\\\ v_{k}\\\\ a_{k}\\end{array}\\right),\\,A=\\left(\\begin{array}{ccc}1&T&T^{2}\\\\ 0&1&T\\\\ 0&0&1\\end{array}\\right),$$\n\n$$Q=2a\\sigma_{m}^{2}\\left(\\begin{array}{ccc}T^{5}/20&T^{4}/8&T^{3}/6\\\\ T^{4}/8&T^{3}/3&T^{2}/2\\\\ T^{3}/6&T^{2}/2&T\\end{array}\\right).$$\n\n$p_{k}$, $v_{k}$ and $a_{k}$ stand for the position, velocity and acceleration, respectively, of the target. $T$, $a$ and $\\sigma_{m}^{2}$ denote the sampling period, the maneuver time constant's reciprocal and the target acceleration's variance, respectively. The measurement of the \ntarget can be modeled as (2) where C =\n\ufffd 1\n0\n0\n0\n0\n1\n\ufffd\nand R =\n\ufffd 60\n0\n0\n10\n\ufffd\n. The initial position, velocity and accelera-\n\ntion of this target are 3410m, 30m/s and 0m/s${}^{2}$, respectively. We select\n\n$$\\bar{x}_{0}=\\left(\\begin{array}{cc}3500\\\\ 40\\\\ 0\\end{array}\\right),\\,P_{0}=\\left(\\begin{array}{cc}60^{2}&60^{2}/T&0\\\\ 60^{2}/T&2\\times60^{2}/T^{2}&0\\\\ 0&0&0\\end{array}\\right).$$\n\nAlso, we take $T=1$, $a=2$ and $\\sigma_{m}^{2}=0.5$. We select $1-\\alpha=0.95$ in confidence level. Then, noticing $p=2$ and using the  chi-square distribution table, we have $\\chi_{\\alpha}^{2}(p)=5.991$. For the tolerable upper bound $\\overline{N}$, we take three different parameter values given by the following three cases:\n\n$$\\text{Case1:}\\overline{N}=\\left(\\begin{array}{cc}50&4\\\\ 4&8\\end{array}\\right);\\text{Case2:}\\overline{N}=0.5\\times\\left(\\begin{array}{cc}50&4\\\\ 4&8\\end{array}\\right);\\text{Case3:}\\overline{N}=\\left(\\begin{array}{cc}60&10\\\\ 10&20\\end{array}\\right).$$\n\nWe test the performance of the presented results using a Monte Carlo simulation with $N=5000$ trials, and we take $k=0,1,\\cdots,100$ for each trial. We use the root-mean-square (RMS) error, the communication rate and the average communication rate as the performance evaluation criteria. At time step $k$, the RMS error is defined as $\\sqrt{\\frac{1}{N}\\sum_{i=1}^{N}(\\xi_{k,i}-\\hat{\\xi}_{k,i})^{2}}$ for $N$ trials where $\\xi_{k,i}$ stands for the state of $\\xi_{k}$ at the $i$th trial, and $\\hat{\\xi}_{k,i}$ stands for an estimate of $\\xi_{k,i}$. Let $\\gamma_{k,i}$ denote the state of $\\gamma_{k}$ at the $i$th trial, and the communication rate for the proposed MMSE state estimator at time step $k$ can be computed using the approximation $\\text{E}[\\gamma_{k}]\\approx\\frac{1}{N}\\sum_{i=1}^{N}\\gamma_{k,i}$ where $\\gamma_{k,i}$ is the \nN \u2211N\ni=1\u03b3k,i where E[\u03b3k] = 1\n\n      N \u2211N\n         i=1 \u03b3k,i when N approaches infinity. The average\ncommunication rate is defined as \u03b3 = lim\n                                 k\u2192\u221e\n                                     1\n                                     k \u2211k\u22121\n                                       j=0 E[\u03b3j], and\n\nthe average communication rate is approximately computed\nvia \u03b3 \u2248\n         1\n        101 \u2211100\n             j=0 E[\u03b3j] in the Monte Carlo simulation. The\n\n|   Case |   SECL |   Algorithm 1 |   Algorithm 2 |\n|--------|--------|---------------|---------------|\n|      1 | 0.3812 |        0.373  |        0.3761 |\n|      2 | 0.5684 |        0.5696 |        0.5678 |\n|      3 | 0.2798 |        0.275  |        0.2712 |\n\nMMSE state estimator based on confidence level proposed in this paper is referred to as SECL. The RMS position and velocity errors of SECL for three different cases are given in Figs. 2 and 3, respectively. The communication rates of SECL, Algorithm 1 and Algorithm 2 at Cases 1, 2 and 3 are provided in Figs. 4, 5 and 6, respectively, where, without loss of generality, we take the information at the 40th trial for running Algorithms 1 and 2. From Figs. 2\u22126, we find that, for both position and velocity estimate at the three different cases, SECL has different performances, and the performance is connected with the communication rate. More precisely, the performance of SECL becomes better and better with the increase of communication rate. This indicates the effectiveness of the MMSE state estimator based on confidence level proposed in this paper. Figs. 4\u22126 also shows that Algorithm\n2 provides a good estimate for the communication rate of SECL because the communication rate yielded by Algorithm 2 is close to the communication rate of SECL. The average communication rates of SECL, Algorithm 1 and Algorithm 2 for the three cases are provided in Table I. We see from Table I that the average communication rates of SECL, Algorithm 1 and Algorithm 2 are very close at all the three cases, which means that both Algorithm 1 and Algorithm 2 yield good performance for estimating the average communication rates of SECL.\n\nHence, the simulation results indicate that SECL is effective in solving state estimation with the trade-off between communication rate and state estimation performance, and that Algorithm 2 yields a good performance in estimating the communication rate and the average communication rate of SECL.\n"
    },
    {
        "level": "##",
        "title": "B. Comparison With Sehi",
        "content": "\nWe compare SECL with SEHI still using the above target tracking example where we take the same parameter values except for the tolerable upper bound N. In the comparison with SEHI, we take N = Na \u225c 0.695\u00d7\n\ufffd 60\n10\n10\n20\n\ufffd\nwhich is a slight change of N at Case 3 in Section V-A through multiplying by 0.695. After a Monte Carlo simulation, we get the average communication rate of SECL is 0.35 when N = Na.\n\nConsidering fairness, we compare SECL with SEHI under the same average communication rate. Using Monte Carlo simulation, we get \u03b4 = 1.5565 when the average communication rate of SEHI is 0.35. The target's RMS position errors of SECL\nand SEHI under the same average communication rate 0.35 are provided in Fig. 7, and the corresponding velocity errors are provided in Fig. 8.\n\nFrom observing Figs. 7 and 8, we find that SECL performs better than SEHI in target tracking accuracy for both position and velocity. Hence, the simulation results show that SECL yields better tracking performance in contrast to SEHI.\n"
    },
    {
        "level": "##",
        "title": "Vi. Conclusion",
        "content": "\nBased on confidence level, a novel event-triggered scheme has been proposed using the chi-square distribution and regular Gaussian assumption. The novel scheme was applied to the state estimation problem for discrete-time linear systems in the environment of wireless sensor network so that a MMSE state estimator was proposed. Two algorithms for estimating the communication rate of the proposed state estimator have been developed where, at time step k, the first algorithm is based on information up to k\u22121, and the second algorithm is based on information up to k\u22122. A target tracking scenario has been given to examine the performance of the proposed results, and the simulation results have shown that the proposed state estimator performs better than SEHI under the same average communication rate. The simulation results have also shown that Algorithm 2 provides a good estimate for the communication rate of the proposed state estimator.\n"
    },
    {
        "level": "##",
        "title": "Appendix A Proof Of Lemmas 1\u22123",
        "content": "\nProof of Lemma 1: Using (1), we have\n\n$$f(x_{k}|{\\rm I}_{k-1})=f(Ax_{k-1}+\\omega_{k-1}|{\\rm I}_{k-1}).\\tag{82}$$\nFrom Assumptions 1 and 2, we see that \u03c9k\u22121 is independent of xk\u22121 and Ik\u22121. Hence, f(xk|Ik\u22121) is a linear combination of two Gaussian and mutually independent random vectors f(xk\u22121|Ik\u22121) and \u03c9k\u22121, that is Af(xk\u22121|Ik\u22121) + \u03c9k\u22121.\n\nThen, using Remark 4, we prove 1). Applying (2), we have f(yk|Ik\u22121) = f(Cxk + \u03c5k|Ik\u22121). Then, using 1) of Lemma 1, and referring to the proof of 1) of Lemma 1, we prove 2).\n\nProof of Lemma 2: 1). Using (10), (4) and (2), we get\n\n$\\mathbb{Z}=\\Phi\\mathbb{C}x_{k}+\\Phi\\mathbb{D}_{k}-\\Phi\\mathbb{D}_{k,k-1}$. (83)\nThen, using 1) of Lemma 1, and making reference to the proof of 1) of Lemma 1, we prove 1). 2). Applying (10), (4) and (3), we get\n\n$$\\mathrm{E}[z_{k}|\\mathrm{I}_{k-1}]=\\Phi\\mathrm{E}[\\hat{y}_{k}|\\mathrm{I}_{k-1}]=\\Phi(\\hat{y}_{k,k-1}-\\hat{y}_{k,k-1})=0.\\tag{84}$$\n\nThen, applying 1) of Lemma 2, we prove 2).\n  Proof of Lemma 3: 1). From (8) and (9), it follows that\n\u03d5k \u2264 \u03c72\n      \u03b1(p) is equivalent to \u2211p\n                           i=1 z2\n                               k,i \u2264 \u03c72\n                                     \u03b1(p). Then, using the\ndefinition of \u03a9k presented in (12), we obtain\n\np \u2211 i=1 z2 k,i \u2264 \u03c72 \u03b1(p) \ufffd . (85) \u03a9k = \ufffd zk,1,zk,2,\u00b7\u00b7\u00b7 ,zk,p \u2208 R \ufffd\ufffd\ufffd\ufffd \u03a9k f(zk|Ik\u22121)zkzT k dzk\n\nThen, using (85) and 2) of Lemma 2, we prove 1).\n2). Noticing zk \u2208 Rp, we have zkzT\n                                k = (\u03b6k,ij)p\u00d7p with \u03b6k,ij =\nzk,izk,j. Then, using 2) of Lemma 2, we have\n \ufffd\n\ng(zk) \u03a9k = \ufffd = 1 (2\u03c0)0.5p\ufffd\ufffdN[z] k \ufffd\ufffd0.5 (\u03b6k,ij)p\u00d7pdzk,1dzk,2 \u00b7\u00b7\u00b7dzk,p \u03a9k g(zk)\u03b6k,ijdzk,1dzk,2 \u00b7\u00b7\u00b7dzk,p p\u00d7p . \ufffd \ufffd\ufffd (86) (2\u03c0)0.5p\ufffd\ufffdN[z] k \ufffd\ufffd0.5 \u03a9k g(zk)\u03b6k,ijdzk,1dzk,2 \u00b7\u00b7\u00b7dzk,p\nUsing (85) and noticing \u03b6k,ij = zk,izk,j, we have\n\ufffd\n\n= dzk,1 g(zk)zk,izk,jdzk,p (87) dzk,2 \u00b7\u00b7\u00b7 \u02c7b \ufffd \u02c7zk,1 \ufffd \u02c7zk,p\u22121 \ufffd \u2212\u02c7zk,1 \u2212\u02c7zk,p\u22121 \u2212\u02c7b \u03a9k f(zk|Ik\u22121)zkzT k dzk = (\u03c8k,ij)p\u00d7p\nwhere \u02c7b and \u02c7zk,i with i = 1,2,\u00b7\u00b7\u00b7 , p \u2212 1 are defined in 1) of Lemma 3. Substituting (87) into (86), as well as using the definition of \u03c8k,ij and \u03a8k given in 2) of Lemma 3, we have\n\ufffd\n\n(88) (2\u03c0)0.5p\ufffd\ufffdN[z] k \ufffd\ufffd0.5 = \u03a8k (2\u03c0)0.5p\ufffd\ufffdN[z] k \ufffd\ufffd0.5 .\nThis complete the proof of the statement.\n"
    },
    {
        "level": "##",
        "title": "Appendix B Proof Of Theorem 1 Derivation Of (22). When \u0393k = 0, We Have",
        "content": "\n$$\\hat{\\hat{x}}_{k}=\\int_{\\mathbb{R}^{n}}x_{k}f(x_{k}|\\mathrm{I}_{k})dx_{k}=\\int_{\\mathbb{R}^{n}}x_{k}f(x_{k}|\\mathrm{I}_{k-1},\\gamma_{k}=0)dx_{k}.\\tag{89}$$\nBy (8), f(xk|Ik\u22121,\u03b3k = 0) can be expressed as\n\n= f(xk|Ik\u22121,zk \u2208 \u03a9k) f(xk|Ik\u22121,\u03b3k = 0) = f \ufffd xk|Ik\u22121,\u03d5k \u2264 \u03c72 \u03b1(p) \ufffd = f(xk,Ik\u22121,zk \u2208 \u03a9k) f(Ik\u22121,zk \u2208 \u03a9k) = \ufffd \u03a9k f(xk,Ik\u22121,zk)dzk \ufffd \u03a9k f(Ik\u22121,zk)dzk = \ufffd \u03a9k f(xk|Ik\u22121,zk)f(zk|Ik\u22121)dzk \ufffd \u03a9k f(zk|Ik\u22121)dzk (90)\nwhere the second and last equalities are due to (12) and Bayes' rule, respectively. Substituting (90) into (89) yields that\n\nRn xk \u02c6xk = \ufffd \ufffd \u03a9k f(xk|Ik\u22121,zk)f(zk|Ik\u22121)dzk \ufffd \u03a9k f(zk|Ik\u22121)dzk dxk = \ufffd Rn xk \ufffd \u03a9k f(xk|Ik\u22121,zk)f(zk|Ik\u22121)dzkdxk \ufffd \u03a9k f(zk|Ik\u22121)dzk = \ufffd \u03a9k f(zk|Ik\u22121) \ufffd Rn xk f(xk|Ik\u22121,zk)dxkdzk \ufffd \u03a9k f(zk|Ik\u22121)dzk = \ufffd \u03a9k f(zk|Ik\u22121)\u02c6x[z] k dzk \ufffd \u03a9k f(zk|Ik\u22121)dzk . (91) Making reference to the proof of Theorem 3.2 in [10], we can obtain \ufffd \u03a9k f(zk|Ik\u22121)\u02c6x[z] k dzk \ufffd \u03a9k f(zk|Ik\u22121)dzk =\u02c6xk,k\u22121. (92)\nwhere \u02c6xk,k\u22121 is defined in (15). Substituting (92) into (91), we derive (22). Derivation of (23). Using (18) and the definition of conditional covariance matrix, we have Substituting (84) into (93), and using (10), we derive\n\nN[z] k = E \ufffd (zk \u2212 E[zk|Ik\u22121])(zk \u2212 E[zk|Ik\u22121])T\ufffd . (93) N[z] k = E \ufffd zkzT k \ufffd = E \ufffd \u03a6 \u02dcyk \u02dcyT k \u03a6T\ufffd = \u03a6(CMkCT + R)\u03a6T (94)\nwhere Mk is defined in (17). Similarly, we have\n\n$$\\mathrm{E}\\Big{[}\\tilde{x}_{k}(z_{k}-[z_{k}|\\mathrm{I}_{k-1}])^{\\mathrm{T}}\\Big{]}=\\mathrm{E}\\Big{[}\\tilde{x}_{k}z_{k}^{\\mathrm{T}}\\Big{]}=M_{k}C^{\\mathrm{T}}\\Phi^{\\mathrm{T}}.\\tag{95}$$\n\nSubstituting (94) and (95) into (19) yields (23).\n\nDerivation of (24). Utilizing Kalman filter, we get\n\n$$\\hat{x}_{k}^{[z]}=\\hat{x}_{k,k-1}+K_{k}(z_{k}-\\mathrm{E}[z_{k}|\\mathrm{I}_{k-1}])\\tag{96}$$\nwhere \u02c6x[z]\nk and Kk are defined in (13) and (19), respectively, and N[z]\nk in Kk is defined in (18). Substituting (84) into (96), we obtain\n\n\u02c6x[z] k = \u02c6xk,k\u22121 + Kkzk. (97)\nFrom (14), (13) and the definition of conditional covariance matrix, it follows that\n\n$$P_{k}^{[z]}=\\mathrm{E}\\bigg{[}\\left(x_{k}-\\hat{x}_{k}^{[z]}\\right)\\left(x_{k}-\\hat{x}_{k}^{[z]}\\right)^{\\mathrm{T}}\\bigg{]}.\\tag{98}$$\n\nSubstituting (97) into (98) and using (16), we obtain  $$P(\\gamma_{k}=0|\\mathrm{I}_{k-2},\\bar{z}_{k-1})=P(z_{k}\\in\\Omega_{k}|\\mathrm{I}_{k-2},\\bar{z}_{k-1})$$ $$=\\int_{\\Omega_{k}}f(z_{k}|\\mathrm{I}_{k-2},\\bar{z}_{k-1})dz_{k}.\\tag{142}$$\nThen, replacing P(\u03b3k = 0|Ik\u22122,zk\u22121) by \u20d7P[z]\nk (0), we derive (66).\n\nIn the same way, we can obtain (67) where \u02d8Pk(0) is defined in (51).\n\nDerivation of (68). P(\u03b3k = 0|Ik\u22122) can be given by\n\n$$P(\\gamma_{k}=0|{\\rm I}_{k-2})$$ $$=P(\\gamma_{k-1}=0|{\\rm I}_{k-2})P(\\gamma_{k}=0|{\\rm I}_{k-2},\\gamma_{k-1}=0)$$ $$\\quad+P(\\gamma_{k-1}=1|{\\rm I}_{k-2})P(\\gamma_{k}=0|{\\rm I}_{k-2},\\gamma_{k-1}=1).\\tag{143}$$\nP(\u03b3k = 0|Ik\u22122,\u03b3k\u22121 = 1) can be given by\n\n$$P(\\gamma_{k}=0|\\mathrm{I}_{k-2},\\gamma_{k-1}=1)$$ $$=\\frac{P(\\mathrm{I}_{k-2},\\gamma_{k-1}=1,\\gamma_{k}=0)}{P(\\mathrm{I}_{k-2},\\gamma_{k-1}=1)}$$ $$=\\frac{P(\\mathrm{I}_{k-2},z_{k-1}\\in\\tilde{\\Omega}_{k-1},\\gamma_{k}=0)}{P(\\mathrm{I}_{k-2},z_{k-1}\\in\\tilde{\\Omega}_{k-1})}$$ $$=\\frac{\\int_{\\tilde{\\Omega}_{k-1}}f(\\mathrm{I}_{k-2},z_{k-1},\\gamma_{k}=0)dz_{k-1}}{\\int_{\\tilde{\\Omega}_{k-1}}f(\\mathrm{I}_{k-2},z_{k-1})dz_{k-1}}$$ $$=\\frac{\\int_{\\tilde{\\Omega}_{k-1}}\\tilde{P}_{k}^{(2)}(0)f(\\mathrm{I}_{k-2},z_{k-1})dz_{k-1}}{\\int_{\\tilde{\\Omega}_{k-1}}f(\\mathrm{I}_{k-2},z_{k-1})dz_{k-1}}$$ $$=\\frac{\\int_{\\tilde{\\Omega}_{k-1}}\\tilde{P}_{k}^{(2)}(0)f(z_{k-1}|\\mathrm{I}_{k-2})dz_{k-1}}{\\int_{\\tilde{\\Omega}_{k-1}}f(z_{k-1}|\\mathrm{I}_{k-2})dz_{k-1}}$$ $$=\\frac{\\int_{\\tilde{\\Omega}_{k-1}}\\tilde{P}_{k}^{(2)}(0)f(z_{k-1}|\\mathrm{I}_{k-2})dz_{k-1}}{P(\\gamma_{k-1}=1|\\mathrm{I}_{k-2})}\\tag{144}$$\nwhere \u02d8\u03a9k and \u20d7P[z]\nk (0) are defined in (57) and (50), respectively.\n\nSubstituting (144) into (143), as well as replacing P(\u03b3k\u22121 =\n0|Ik\u22122) by Pk\u22121,k\u22122(0), we obtain\n\n$$P(\\gamma_{k}=0|{\\rm I}_{k-2})=P_{k-1,k-2}(0)P(\\gamma_{k}=0|{\\rm I}_{k-2},\\gamma_{k-1}=0)$$ $$+\\int_{\\Omega_{k-1}}\\vec{P}_{k}^{[\\varepsilon]}(0)f(z_{k-1}|{\\rm I}_{k-2})dz_{k-1}.\\tag{145}$$\nThen, replacing P(\u03b3k = 0|Ik\u22122) and P(\u03b3k = 0|Ik\u22122,\u03b3k\u22121 = 0)\nby Pk,k\u22122(0) and \u02d8Pk(0), respectively, we derive (68). Making reference to (46), we easily obtain (69).\n"
    },
    {
        "level": "##",
        "title": "Appendix D Proof Of Algorithm 2",
        "content": "\nMaking reference to the proof of 1) of Lemma 3, we can obtain (71) by using (64) and (66). Similarly, we obtain (72) by using (65) and (67). From (66), (64) and (70), we see that $\\vec{P}_{k}^{[z]}(0)$ does not contain the random vector $z_{k-1}$. Hence, we have\n\n$$\\int_{\\Omega_{k-1}}\\vec{P}_{k}^{[z]}(0)f(z_{k-1}|\\mathrm{I}_{k-2})dz_{k-1}$$ $$=\\vec{P}_{k}^{[z]}(0)\\int_{\\hat{\\Omega}_{k-1}}f(z_{k-1}|\\mathrm{I}_{k-2})dz_{k-1}$$ $$=\\vec{P}_{k}^{[z]}(0)\\Big{(}\\int_{\\mathbb{R}^{p}}f(z_{k-1}|\\mathrm{I}_{k-2})dz_{k-1}-\\int_{\\Omega_{k-1}}f(z_{k-1}|\\mathrm{I}_{k-2})dz_{k-1}\\Big{)}$$ $$=\\bar{P}_{k}^{[z]}(0)\\Big{(}1-\\int_{\\Omega_{k-1}}f(z_{k-1}|\\mathrm{I}_{k-2})dz_{k-1}\\Big{)}$$ $$=\\bar{P}_{k}^{[z]}(0)\\Big{(}1-\\frac{h_{k-1}}{(2\\pi)^{0.5}p\\big{|}N_{k-1}^{[z]}}\\big{|}^{0.5}\\Big{)}$$ $$=\\bar{P}_{k}^{[z]}(0)\\big{(}1-P_{k-1,k-2}(0)\\big{)}\\tag{146}$$\n\nwhere the fourth equality is due to 1) of Lemma 3, and the last equality is because of (58). Substituting (146) into (68), we get\n\n$$P_{k,k-2}(0)=P_{k-1,k-2}(0)\\bar{P}_{k}(0)+\\bar{P}_{k}^{[z]}(0)\\big{(}1-P_{k-1,k-2}(0)\\big{)}$$ $$=\\bar{P}_{k}^{[z]}(0)+P_{k-1,k-2}(0)\\big{(}\\bar{P}_{k}(0)-\\bar{P}_{k}^{[z]}(0)\\big{)},\\tag{1}$$\nwhich means that (73) holds.\n\n$$=\\vec{P}_{k}^{[z]}(0)+P_{k-1,k-2}(0)(\\vec{P}_{k}(0)-\\vec{P}_{k}^{[z]}(0)),\\tag{147}$$\n\nthat (73) holds.\n"
    },
    {
        "level": "##",
        "title": "References",
        "content": "\n[1] J. P. Hespanha, P. Naghshtabrizi, and Y. Xu, \"A survey of recent results\nin networked control systems\", *Proc. IEEE*, vol. 95, no. 1, pp. 138-162,\nJan. 2007.\n[2] S. Wildhagen, J. Berberich, M. Hertneck, and F. Allg\u00a8ower, \"Data-driven\nanalysis and controller design for discrete-time systems under aperiodic\nsampling\", *IEEE Trans. Autom. Control*, vol. 68, no. 6, pp. 3210-3225,\nJun. 2023.\n[3] J. Shang, H. Yu, and T. Chen, \"Worst-case stealthy attacks on stochastic\nevent-based state estimation\", *IEEE Trans. Autom. Control*, vol. 67, no.\n4, pp. 2052-2059, Apr. 2022.\n[4] W. Liu, P. Shi, and S. Wang, \"Distributed Kalman filtering through trace\nproximity\", *IEEE Trans. Autom. Control*, vol. 67, no. 9, pp. 4908-4915,\nSep. 2022.\n[5] J. Hu, B. Lennox, and F. Arvin, \"Robust formation control for networked\nrobotic systems using negative imaginary dynamics\", *Automatica*, vol.\n140, 2022, Art. no. 110235.\n[6] I. Z. Petric, P. Mattavelli, and S. Buso, \"Multi-sampled grid-connected\nVSCs: A path toward inherent admittance passivity\", IEEE Trans. Power Electron., vol. 37, no. 7, pp. 7675-7687, Jul. 2022.\n[7] J. J. Xiao, A. Ribeiro, Z. Q. Luo, and G. B. Giannakis, \"Distributed\ncompression-estimation using wireless sensor networks\", IEEE Trans. Signal Process. Mag., vol. 23, no. 4, pp. 27-41, Jul. 2006.\n[8] A. Ribeiro, G. B. Giannakis, and S. I. Roumeliotis, \"SOI-KF: Distributed\nKalman filtering with low-cost communications using the sign of innovations\", *IEEE Trans. Signal Process.*, vol. 54, no. 12, pp. 4782-4795,\nDec. 2006.\n[9] E. J. Msechu, S. I. Roumeliotis, A. Ribeiro, and G. B. Giannakis,\n\"Decentralized quantized Kalman filtering with scalable communication\ncost\", *IEEE Trans. Signal Process.*, vol. 56, no. 8, pp. 3727-3741, Aug.\n2008.\n[10] J. Wu, Q. S. Jia, K. H. Johansson, and L. Shi, \"Event-based sensor\ndata scheduling: Trade-off between communication rate and estimation\nquality\", *IEEE Trans. Autom. Control*, vol. 58, no. 4, pp. 1041-1046,\nApr. 2013.\n[11] G. M. Lipsa and N. C. Martins, \"Remote state estimation with communication costs for first-order LTI systems\", *IEEE Trans. Autom. Control*,\nvol. 56, no. 9, pp. 2013-2025, Sep. 2011.\n[12] G. Battistelli, A. Benavoli, and L. Chisci, \"Data-driven communication\nfor state estimation with sensor networks\", *Automatica*, vol. 48, no. 5,\npp. 926-935, May 2012.\n[13] J. Sijs and M. Lazar, \"Event based state estimation with time synchronous updates\", *IEEE Trans. Autom. Control*, vol. 57, no. 10, pp.\n2650-2655, Oct. 2012.\n[14] K. You and L. Xie, \"Kalman filtering with scheduled measurements\",\nIEEE Trans. Signal Process., vol. 61, no. 6, pp. 1520-1530, Mar. 2013.\n[15] D. Shi, T. Chen, and L. Shi, \"An event-triggered approach to state estimation with multiple point- and set-valued measurements\", *Automatica*,\nvol. 50, no. 6, pp. 1641-1648, Jun. 2014.\n[16] S. Trimpe and R. D'Andrea, \"Event-based state estimation with\nvariance-based triggering\", *IEEE Trans. Autom. Control*, vol. 59, no. 12,\npp. 3266-3281, Dec. 2014.\n[17] D. Shi, T. Chen, and L. Shi, \"On set-valued Kalman filtering and its\napplication to event-based state estimation\", *IEEE Trans. Autom. Control*,\nvol. 60, no. 5, pp. 1275-1290, May 2015.\n[18] D. Han, Y. Mo, J. Wu, S. Weerakkody, B. Sinopoli, and L. Shi,\n\"Stochastic event-triggered sensor schedule for remote state estimation\",\nIEEE Trans. Autom. Control, vol. 60, no. 10, pp. 2661-2675, Oct. 2015.\n[19] S. Weerakkody, Y. Mo, B. Sinopoli, D. Han, and L. Shi, \"Multi-sensor\nscheduling for state estimationwith event-based, stochastic triggers\",\nIEEE Trans. Autom. Control, vol. 61, no. 9, pp. 2695-2701, Sep. 2016.\n[20] A. Mohammadi and K. N. Plataniotis, \"Event-based estimation with\ninformation-based triggering and adaptive update\", IEEE Trans. Signal\nProcess., vol. 65, no. 18, pp. 4924-4939, Sep. 2017.\n[21] L. He, J. Chen, and Y. Qi, \"Event-based state estimation: Optimal\nalgorithm with generalized closed skew normal distribution\", IEEE Trans.\nAutom. Control, vol. 64, no. 1, pp. 321-328, Jan. 2019.\n[22] Z. Hu, B. Chen, R. Wang, and L. Yu, \"Remote state estimation with\nposterior-based stochastic event-triggered schedule\", IEEE Trans. Autom. Control, vol. 69, no. 2, pp. 1194-1201, Feb. 2024.\n[23] H. Yu, J. Shang, and T. Chen, \"On stochastic and deterministic eventbased state estimation\", *Automatica*, vol. 123, 2021, Art. no. 109314.\n[24] G. Battistelli, L. Chisci, and D. Selvi, \"A distributed Kalman filter with\nevent-triggered communication and guaranteed stability\", *Automatica*,\nvol. 93, pp. 75-82, Jul. 2018.\n[25] M. Miskowicz, \"Send-on-delta concept: An event-based data reporting\nstrategy\", *Sensors*, vol. 6, no. 1, pp. 49-63, Jan. 2006.\n[26] R. Cogill, S. Lall, and J. P. Hespanha, \"A constant factor approximation\nalgorithm for event-based sampling\", *in Proc. 2007 Amer. Control Conf.*,\nNew York, USA, Jul. 2007, pp. 305-311.\n[27] L. Li, M. Lemmon, and X. Wang, \"Event-triggered state estimation in\nvector linear processes\", *in Proc. 2010 Amer. Control Conf.*, Baltimore,\nUSA, Jun. 2010, pp. 2138-2143.\n[28] R. A. Johnson and D. W. Wichern, Applied multivariate statistical\nanalysis, 6th ed., Upper Saddle River: Pearson prentice hall, 2007.\n[29] R. A. Singer, \"Estimating optimal tracking filter performance for manned\nmaneuvering targets\", *IEEE Trans. Aerosp. Electron. Syst.*, vol. AES-6,\nno. 4, pp. 473-483, Jul. 1970."
    }
]