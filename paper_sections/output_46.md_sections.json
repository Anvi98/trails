[
    {
        "level": "#",
        "title": "Online Multi-Agent Pickup And Delivery With Task Deadlines",
        "content": "\nHiroya Makino1,\u2217, and Seigo Ito1\nAbstract\u2014 Managing delivery deadlines in automated warehouses and factories is crucial for maintaining customer satisfaction and ensuring seamless production. This study introduces the problem of online multi-agent pickup and delivery with task deadlines (MAPD-D), which is an advanced variant of the online MAPD problem incorporating delivery deadlines. MAPD-D presents a dynamic deadline-driven approach that includes task deadlines, with tasks being added at any time (online), thus challenging conventional MAPD frameworks. To tackle MAPD-\nD, we propose a novel algorithm named deadline-aware token passing (D-TP). The D-TP algorithm is designed to calculate pickup deadlines and assign tasks while balancing execution cost and deadline proximity. Additionally, we introduce the D-TP with task swaps (D-TPTS) method to further reduce task tardiness, enhancing flexibility and efficiency via taskswapping strategies. Numerical experiments were conducted in simulated warehouse environments to showcase the effectiveness of the proposed methods. Both D-TP and D-TPTS demonstrate significant reductions in task tardiness compared to existing methods, thereby contributing to efficient operations in automated warehouses and factories with delivery deadlines.\n"
    },
    {
        "level": "##",
        "title": "I. Introduction",
        "content": "\nIn the industrial automation landscape, the development of automated guided vehicles (AGVs) has revolutionized operational efficiencies. Enhancing multi-agent path finding (MAPF) to optimize the utilization of AGVs for more effective transportation solutions has been extensively researched [1], [2]. These advancements have been integrated into various domains, including logistics automation [3], [4], traffic control systems [5], automated valet parking [6], airport surface operations [7], and video games [8].\n\nThe multi-agent pickup and delivery (MAPD) problem is an extension of MAPF, wherein paths for multiple items are planned from pickup locations to delivery locations [9], [10], [11]. MAPD can be applied to various environments, including automated warehouses and factories [9], [12], [13]. In such settings, the importance of managing delivery deadlines cannot be overstated. Warehouses must tailor deadlines for individual orders to ensure customer satisfaction, whereas factories require timely deliveries to maintain seamless production. Therefore, satisfying the deadlines appropriately is essential for operational efficiency and economic success.\n\nTo consider deadlines in MAPD, we define the online multi-agent pickup and delivery with task deadlines (MAPD- D) as a new problem (Fig. 1). Existing studies [14], [15] have no longer be accessible.\n\nexplored MAPD with deadlines in an *offline* setting, where all task information is provided in advance. However, to the best of our knowledge, no study has addressed deadline-aware MAPD in an *online* setting where tasks may be added at any time. Hence, this study introduces new problem definitions for MAPD-D.\n\nWe propose the deadline-aware token passing (D-TP)\nalgorithm to tackle MAPD-D. This algorithm is designed to calculate pickup deadlines and assign tasks while striking a balance between execution cost and deadline proximity. Additionally, we introduce the D-TP with task swaps (D-TPTS) method to reduce task tardiness. D-TPTS enhances flexibility and efficiency by employing task-swapping strategies among agents and within a single agent.\n\nThe primary contributions of this study can be summarized as follows:\n\n- A new problem (MAPD-D) is defined considering delivery deadlines and the possibility of adding tasks at any time.\n- A method for solving MAPD-D by calculating pickup\ndeadlines and deadline-aware task assignments is pro-\nposed.\n\n- Task-swapping methods are introduced to reduce task tardiness.\n\nThe remainder of this paper is structured as follows. Section II describes the related work on MAPD. Section III defines the MAPD-D problem, and Section IV describes the proposed algorithm for solving this problem. Section V presents the numerical experiments performed to evaluate the proposed method. Finally, Section VI summarizes the study findings and concludes the paper.\n"
    },
    {
        "level": "##",
        "title": "Ii. Related Work",
        "content": "\nMAPF is the problem of moving multiple agents to their respective destination locations without collisions. The MAPF task ends when all agents reach their destinations. In contrast, MAPD requires agents to attend to a stream of delivery tasks [9], [10], wherein each delivery task is assigned a starting point (pickup location) and a destination point (delivery location). The system assigns these tasks to agents, which then move to the delivery location via the pickup location. The agents receive new tasks after reaching the delivery location. Ma et al. [9], [10] described an online version of MAPD, in which tasks can be added to the set at any time. Conversely, Liu et al. [11] discussed an offline variant where tasks and their release times are generally predetermined.\n\nMa et al. [9] reported that online MAPD instances are solvable if they are well-formed. They introduced locations referred to as endpoints, where agents can remain without blocking other agents. Endpoints include all pickup and delivery locations along with the initial positions and designated parking locations. The pickup and delivery locations are referred to as task endpoints, whereas the other locations serve as non-task endpoints. An MAPD instance is wellformed if and only if (a) the number of tasks is finite, (b) the number of agents is not greater than non-task endpoints, and (c) a path exists between any two endpoints without traversing others.\n\nTo address online MAPD, Ma et al. [9] employed the token passing (TP) algorithm. Tokens are a type of shared memory that stores all agent paths as well as the task set and agent assignments. Agents sequentially access the token, are assigned tasks, and find paths without colliding with already reserved paths. The token is updated after identifying a path.\n\nSeveral researchers have investigated MAPF and MAPD\nwith deadlines. In this study, we classified related studies from the literature considering four perspectives (Table I). \"Multi-task\" indicates whether each agent is continuously assigned tasks; \"Deadlines\" denote whether each task is set with a deadline; \"Individual release times\" denote whether the release time of each task is the same; and \"Online\" indicate whether tasks are added at any time. As shown in Table I, Ma et al. [16], Wang and Chen [17], and Huang et al. [18] considered deadlines in the context of MAPF. Wu et al. [14] and Ramanathan et al. [15] introduced deadlines in MAPD. However, the perspective of online tasks in MAPD was not considered in [14], [15]. In this study, the proposed MAPD-D considers online tasks with deadlines, where tasks can be added at any time.\n\nIII. PROBLEM DEFINITION\nIn this section, we describe the shared definitions of MAPD [9] and MAPD-D and define the tasks specific to MAPD-D.\n\nAn instance of MAPD and MAPD-D consists of m agents in A = a1, \u00b7 \u00b7 \u00b7 *, a*m, a connected simple undirected graph G = (*V, E*), and a set of unexecuted tasks T = \u03c41, \u00b7 \u00b7 \u00b7 *, \u03c4*k.\n\nHere, V represents the vertices, E denotes the edges, and li(t) \u2208 V indicates the location of agent ai at timestep t.\n\nA path is a sequence of vertices associated with timesteps, indicating the vertex at which the agent is located at each timestep.\n\nAgents either remain at their current node li(t) = li(t+1)\nor move to an adjacent node via an edge (li(t), li(t + 1)) \u2208\nE at each timestep. Agents must avoid collisions with each other. MAPD and MAPD-D define two types of collisions [1], [9]: (1) Vertex conflict, where two agents cannot occupy the same location at the same timestep, i.e., for all agents ai, aj (i \u0338= j) and all timesteps t, li(t) \u0338= lj(t) must hold; and\n(2) Swapping conflict, where two agents cannot move along the same edge in opposite directions at the same timestep, i.e., for all agents ai, aj (i \u0338= j) and all timesteps t, li(t) \u0338=\nlj(t + 1) or lj(t) \u0338= li(t + 1) must hold.\n\nWe further provide an extended definition of tasks in MAPD-D. Each task \u03c4j *\u2208 T* consists of a pickup location vp j \u2208 V , a delivery location vd j \u2208 V , and a delivery deadline dd j . New tasks can be added to the task set T at each timestep.\n\nWhen an agent assigned to a task reaches the delivery location via the pickup location, the task is completed, and its completion time is denoted as cj. Once a task is completed, the agent is assigned to a new task.\n\nThe objective of MAPD is to identify paths that execute all tasks in a timely manner, whereas MAPD-D aims to minimize task tardiness. We define the tardiness for the jth task as \u03f5j = max(0, cj \u2212 dd j ). For each task \u03c4j, \u03f5j = 0\nindicates the success of the task, whereas \u03f5j > 0 indicates task failure. The objective function of MAPD-D is selected from the following two options:\n\n* Minimizing the number of task failures [14], [16], [18]: $$\\min\\ \\sum_{1\\leq j\\leq k}U(\\epsilon_{j}),$$ (1) where $U(\\cdot)$ is a unit step function [1].\n* Minimizing the cumulative tardiness [15], [17]: $$\\min\\ \\sum_{1\\leq j\\leq k}\\epsilon_{j}.$$ (2) In this study, we used the cumulative tardiness (2) as the objective function because it provides a more detailed evaluation of tardiness compared to the objective function (1), which only considers success or failure.\n\n1The unit step function.\n\n$$U(x)=\\begin{cases}0&\\text{if}x\\leq0\\\\ 1&\\text{if}x>0\\end{cases}$$\n\nLifelong multi-agent path finding for online pickup and delivery tasks (MAPD) [9]\n\u2713\n\u00d7\n\u2713\n\u2713\nMulti-agent path finding with deadlines (MAPF-DL) [16]\n\u00d7\n\u2713\n\u00d7\n\u00d7\nMulti-robot path planning with due times (MRPP-DT) [17]\n\u00d7\n\u2713\n\u00d7\n\u00d7\nDeadline-aware multi-agent tour planning (DA-MATP) [18]\n\u00d7\n\u2713\n\u00d7\n\u00d7\nMulti-agent pickup and delivery with task deadlines (MAPD-TD) [14]\n\u2713\n\u2713\n\u00d7\n\u00d7\nMinimizing task tardiness for multi-agent pickup and delivery [15]\n\u2713\n\u2713\n\u2713\n\u00d7\nProposed (MAPD-D)\n\u2713\n\u2713\n\u2713\n\u2713\n"
    },
    {
        "level": "##",
        "title": "Iv. Proposed Method",
        "content": "\nThis section outlines the D-TP algorithm employed to address the MAPD-D problem, which is an extension of the existing TP method. Typically, TP assigns tasks to agents solely based on execution cost. To reduce task tardiness, we introduce enhancements in two key areas: the calculation of pickup deadlines and deadline-aware task assignment. Additionally, we present D-TPTS, which improves flexibility and efficiency through task-swapping strategies.\n"
    },
    {
        "level": "##",
        "title": "A. D-Tp",
        "content": "\n1) Calculation of Pickup Deadlines: The pickup deadline is calculated based on the delivery deadline when a new task \u03c4j is added. We prepared a dummy agent, implemented using prioritized path planning [11]. D-TP calculates the path for the dummy agent to depart from the delivery location vd j at time dd j and move towards the pickup location vp j by reversing the timesteps. During the path calculation, the order of the pickup and delivery locations is reversed because the time required for transportation can vary depending on the paths of other agents in the environment. The proposed method searches for a path from the delivery location to the pickup location by reversing the order of time, thus calculating the latest possible path (dummy path) that meets the delivery deadline. The pickup deadline dp j represents the time obtained by subtracting the length (timesteps) of the dummy path from the delivery deadline dd j .\n\n2) Deadline-aware Task Assignment: The disparity between the calculated pickup deadline dp j and the current time t indicates the temporal margin of the deadline. In TP, the system assigns tasks to minimize the execution cost at the moment of assignment. In contrast, in D-TP, the system assigns tasks to agents in a manner that minimizes the weighted sum of the execution cost and the temporal margin relative to the deadline.\n\n$$\\operatorname*{argmin}_{\\tau_{j}\\in\\mathcal{T}^{\\prime}}\\left(\\alpha\\cdot(d_{j}^{\\mathrm{P}}-t)+(1-\\alpha)\\cdot h\\left(loc(a_{i}),v_{j}^{\\mathrm{P}}\\right)\\right),\\tag{3}$$\n\nwhere $0\\leq\\alpha\\leq1$ and $\\mathcal{T}^{\\prime}$ denotes the set of tasks that can be assigned to agent $a_{i}$. The first term $(d_{j}^{\\mathrm{P}}-t)$ denotes the temporal margin for the deadline of task $\\tau_{j}$; the second term $h(loc(a_{i}),v_{j}^{\\mathrm{P}})$ indicates the h-value from the current location of agent $a_{i}$ to the pickup location of the task, which represents the execution cost; and the parameter $\\alpha$ indicates the weight for the urgency of the pickup deadline. When\n\n| Multi-task   | Deadlines   | Individual release times   | Online   |\n|--------------|-------------|----------------------------|----------|\n\n\u03b1 = 0, it is equivalent to the existing method [9] that does not take the deadline into account.\n\n3) Algorithm: Algorithm 1 provides the pseudocode for D-TP; parts that differ from TP [9] are indicated in red. In lines 17\u201320, we define the UpdatePickupDeadline function. In line 19, a dummy agent is prepared to calculate the dummy path from the delivery location vd j to the pickup location vp j using the reversed-path finding function RP(*dummy, v*d j , vp j *, token, d*d j ). In line 20, the pickup deadline dp j is calculated by subtracting the length of the dummy path. Here, *|P|* represents the length of the path, that is, the number of steps required to move.\n\nIn line 1, the token is initialized with trivial paths where all agents remain in their initial locations. At each timestep, the system adds all new tasks to the task set T (line 3).\n\nSubsequently, in line 4, the pickup deadline is calculated for the newly added tasks. Lines 5\u201315 handle the task assignment process. If one or more tasks are assignable, the system assigns a task considering both the execution cost and the margin until the pickup deadline dp j . The path from vp j to vd j is calculated by the function P(ai, vp j , vd j *, token, t*). In cases where no tasks are assignable, the system handles deadlock resolution or maintains the current position of agents, as outlined in [9]. If new task assignments overwrite the dummy paths, the pickup deadline is recalculated (line 15). Finally, agents proceed along their paths in the token (line 16).\n"
    },
    {
        "level": "##",
        "title": "B. D-Tpts",
        "content": "\nIn this section, we introduce two methods for task swapping that incorporate deadlines in MAPD-D: Task swapping among agents and task switching. Task swapping among agents involves swapping tasks between agents, while task switching focuses on swapping tasks within a single agent.\n\n1) Task Swapping Among Agents: Ma et al. [9] proposed the token passing with task swaps (TPTS) algorithm as a solution to MAPD. In TP with task swapping, agents can be assigned not only \"unassigned\" tasks but also \"tasks assigned to a different agent but not yet picked up.\" This flexibility can be advantageous, particularly when one agent can pick up a task faster than another. In such cases, the system reassigns the task from one agent to another, allowing for more efficient task completion.\n\nIn contrast to TPTS, which focuses solely on execution cost considerations, the proposed method modifies this approach to incorporate a weighted sum of the execution cost and temporal margin for deadlines, as expressed in (3).\n"
    },
    {
        "level": "##",
        "title": "Algorithm 1 Token Passing For Tasks With Deadlines (Tp-D)",
        "content": "\n1: Initialize *token* with the (trivial) path [loc(ai)] for each agent ai\n2: **while** true do\n3:\nAdd all new tasks, if any, to task set T\n4:\nUPDATEPICKUPDEADLINE(new tasks, *token*)\n5:\nwhile agent ai that requests *token* exists do\n6:\nT \u2032 \u2190 {\u03c4j *\u2208 T |* no other path in *token* ends in vp\nj or vd\nj }\n7:\nif T \u2032 \u0338= \u03d5 then\n8:\nt \u2190 current timestep\n9:\n\u03c4j\u2217 \u2190 argmin\n\u03c4j\u2208T \u2032\n\ufffd\n\u03b1 \u00b7 (dp\nj \u2212 t) + (1 \u2212 \u03b1) \u00b7 h(loc(ai), vp\nj )\n\ufffd\n10:\nAssign ai to \u03c4j\u2217\n11:\nRemove \u03c4j\u2217 from T\n12:\nUpdate ai's path in *token* with P(ai, vp\nj\u2217, vd\nj\u2217*, token, t*)\n13:\nelse\n14:\nRemove deadlock or stay\n15:\nUPDATEPICKUPDEADLINE(T whose dummy path is overwritten, *token*)\n16:\nAll agents move along their paths in token for one timestep\n17: **function** UPDATEPICKUPDEADLINE(*tasks, token*)\n18:\nfor \u03c4j \u2208 *tasks* do\n19:\nUpdate\n\u03c4j's\ndummy\npath\nin\ntoken\nwith\nRP(*dummy, v*d\nj , vp\nj *, token, d*d\nj )\n20:\nUpdate\n\u03c4j's\npickup\ndeadline\ndp\nj\nwith\ndd\nj\n\u2212\n|RP(*dummy, v*d\nj , vp\nj *, token, d*d\nj )|\n2) Task Switching: In this approach, the agent is allowed to abandon its current task and undertake a more urgent task if a task with higher urgency appears closer when an agent is en route to the pickup location. We anticipate that task switching can reduce tardiness by prioritizing tasks with higher urgency.\n\nAn agent will abandon its current task if both of the following conditions are met:\n\n- The urgency of the new task is higher than that of the\ncurrent task.\n- The execution cost of the new task is lower than that\nof the current task.\nIn other words, the following inequalities should hold simultaneously:\n\n$$d_{\\rm new}^{\\rm P}<d_{\\rm cur}^{\\rm P}\\tag{4}$$ $$h\\left(loc(a_{i}),v_{\\rm new}^{\\rm P}\\right)<h\\left(loc(a_{i}),v_{\\rm cur}^{\\rm P}\\right),\\tag{5}$$\nwhere cur denotes the index of the current task of the agent ai and new represents the index of the new task.\n\n3) Algorithm: Algorithm 2 provides the pseudocode for D-TPTS. The overall flow mirrors that of TPTS [9], with differences highlighted in red. Lines 5\u201310 implement task switching. When an agent is en route to the pickup locations, it abandons its current task and accepts a different task if the new task has an earlier pickup deadline and a lower execution cost than the current task. Task swapping is performed in the function GetTask (lines 15\u201332). As indicated in line 19, the system considers both the temporal margin of the pickup deadline and the weighted sum of the task execution cost.\n"
    },
    {
        "level": "##",
        "title": "Algorithm 2 Deadline-Aware Token Passing With Task Swaps (D-Tpts)",
        "content": "\n1: Initialize *token* with the (trivial) path [loc(ai)] for each agent ai\n2: **while** true do\n3:\nAdd all new tasks, if any, to task set T\n4:\nUPDATEPICKUPDEADLINE(new tasks, *token*)\n5:\nfor \u03c4j \u2208 new tasks do\n6:\nfor agent ai that is moving to the pickup location do\n7:\n\u03c4j\u2032 \u2190 task that ai is executing\n8:\nif dp\nj < dp\nj\u2032 and h(loc(ai), vp\nj ) < h(loc(ai), vp\nj\u2032) then\n9:\nUnassign a\u2032\ni from \u03c4j\u2032\n10:\nRemove a\u2032\ni's path from token\n11:\nwhile agent ai that requests *token* exists do\n12:\nGETTASK(ai*, token*)\n13:\nAll agents move along their paths in token for one timestep\n14:\nRemove tasks from T when agents start to execute them\n15: **function** GETTASK(ai*, token*)\n16:\nT \u2032 \u2190 {\u03c4j *\u2208 T |* no other path in *token* ends in vp\nj or vd\nj }\n17:\nwhile T \u2032 \u0338= \u03d5 do\n18:\nt \u2190 current timestep\n19:\n\u03c4j\u2217 \u2190 argmin\n\u03c4j\u2208T \u2032\n\ufffd\n\u03b1 \u00b7 (dp\nj \u2212 t) + (1 \u2212 \u03b1) \u00b7 h(loc(ai), vp\nj )\n\ufffd\n20:\nRemove \u03c4 from T\n21:\nif no agent is assigned to \u03c4j\u2217 then\n22:\nAssign ai to \u03c4j\u2217\n23:\nUpdate ai's path in *token* with P(ai, vp\nj\u2217, vd\nj\u2217*, token, t*)\n24:\nelse\n25:\na\u2032\ni \u2190 agent that is assigned to \u03c4j\u2217\n26:\nif ai reaches vp\nj\u2217 before a\u2032\ni then\n27:\nUnassign a\u2032\ni from \u03c4j\u2217 and assign ai to \u03c4j\u2217\n28:\nRemove a\u2032\ni's path from token\n29:\nBreak\n30:\nif no task is assigned to ai then\n31:\nRemove deadlock or stay\n32:\nUPDATEPICKUPDEADLINE(T whose dummy path is overwritten,\ntoken)\n"
    },
    {
        "level": "##",
        "title": "V. Numerical Experiments",
        "content": "\nThis section outlines the numerical experiments conducted to compare the existing method (TP) with the proposed algorithms (D-TP and D-TPTS). Our primary focus is to evaluate the effectiveness of the proposed algorithms in reducing tardiness in an online setting.\n"
    },
    {
        "level": "##",
        "title": "A. Evaluation Of Task Tardiness",
        "content": "\nThe numerical experiments were carried out in a grid environment, representing an automated warehouse, as illustrated in Fig. 1. We generated 151 tasks by randomly selecting pickup and delivery locations from the task endpoints, ensuring no duplication. Each agent moved to the delivery location via the pickup location for the assigned task. We varied parameters such as task-release times and deadline duration after task release to examine their significant impact during the experiments (see Table II). The experiment involved 15 agents, with their initial positions randomly selected from the non-task endpoints.\n\nWe also examined an offline setting where tasks and their release times are predetermined, in contrast to the online setting where tasks can be added at any time. In an offline setting, tasks can be allocated with foresight to accommodate future tasks and preemptively moved in\n(a) Dense task release frequency and short deadlines.\n\n(b) Dense task release frequency and long deadlines.\n\n(c) Sparse task release frequency and short deadlines.\n\n(d) Sparse task release frequency and long deadlines.\n\n| Task-release times                                        | Dense [0, 300]   | Sparse [0, 500]   |\n|-----------------------------------------------------------|------------------|-------------------|\n| Deadline duration after release                           | Short [20, 80]   | Long [60, 120]    |\n| *Values are randomly selected from a uniform distribution |                  |                   |\n| in [min, max].                                            |                  |                   |\n\nanticipation of release times. Generally, offline methods tend to yield solutions closer to the optimal solution compared to online methods. In this context, we referred to the method by Ramanathan et al. [15], who regarded deadlines in offline tasks as ideal benchmarks. They employed a method that sorted tasks based on deadlines and assigned tasks to agents with lower execution costs.\n\nFig. 2 illustrates the results of the proposed method alongside ideal values in the offline setting. The horizontal axis represents the weight \u03b1 used during task assignment, where smaller values prioritize execution cost and larger values prioritize deadlines. When \u03b1 = 0 and task switching is not employed, the method is equivalent to TP and TPTS [9]. The vertical axis indicates the total tardiness for each task, averaged across the results of 30 experiments. Our analysis demonstrates that the cumulative tardiness varies depending on the value of \u03b1 and the presence of task exchanges, regardless of the release frequency and deadlines.\n"
    },
    {
        "level": "##",
        "title": "B. Discussion",
        "content": "\nWe begin by examining the variations in tardiness based on task-release frequency and deadline length. In Fig. 2, both the proposed and conventional methods exhibit notable trends in tardiness. Tardiness increases when tasks are released frequently and when deadlines are short. Densely released tasks leave agents with limited spare time, leading to a buildup of unexecuted tasks and an increase in cumulative tardiness. Similarly, shorter deadlines elevate the likelihood of tasks missing their deadlines, further contributing to cumulative tardiness.\n\nNext, we explore the weight \u03b1 in the proposed method.\n\nWe compare the disparities in cumulative tardiness caused by varying \u03b1 when neither task swapping nor task switching is implemented. Minimum tardiness is observed for dense task releases and short deadlines (Fig. 2(a)) at \u03b1 = 0.0, for dense releases and long deadlines (Fig. 2(b)) at \u03b1 = 0.1, for sparse releases and short deadlines (Fig. 2(c)) at \u03b1 = 0.025, and for sparse releases and long deadlines (Fig. 2(d)) at \u03b1 = 0.2. When tasks are released frequently and deadlines are short, prioritizing tasks with lower execution costs is crucial for timely management. However, in scenarios where tasks are not released frequently or deadlines are not short, there is some flexibility to consider deadlines. While TP and TPTS [9] solely considered execution costs (\u03b1 = 0), the proposed method integrates temporal margin for deadlines along with execution costs, resulting in reduced tardiness. Nonetheless, excessively prioritizing the temporal margin of deadlines may escalate the execution costs of each task. This can overwhelm agents and increasing cumulative tardiness. Hence, adjusting the value of \u03b1 based on the situation is imperative.\n\nIn all experiments, the lowest tardiness was achieved when both task swapping and task switching were implemented. For example, in Fig. 2(b), implementing only task swapping reduced cumulative tardiness by 569.4, whereas implementing both task swapping and task switching further reduced tardiness by an additional 116.7. Task switching facilitates task reassignment when more urgent tasks are added. Additionally, task swapping enables task exchanges between agents, leading to further reduction in cumulative tardiness.\n\nHowever, implementing only task switching may elevate cumulative tardiness compared to not implementing anything, especially when task releases are frequent (Figs. 2(a) and 2(b)). This aligns with the discussion on the value of \u03b1; in scenarios with frequent task releases, minimizing execution costs outweighs considering task urgency. Task reassignment based on urgency through task switching increases execution costs, consequently amplifying tardiness.\n\nFinally, we compare the proposed method (online) with the ideal values (offline). In most cases, the tardiness of the proposed method was equivalent to or worse than the ideal values (Figs. 2(a), (c), and (d)). However, in scenarios with dense tasks and long deadlines, the proposed method outperformed the ideal values (Fig. 2(b)). Ramanathan et al. [15] sorted tasks in advance based on deadlines and assigned them to agents with lower execution costs. This indicated that they prioritized deadlines over execution costs. They noted that their method excelled with extremely short deadlines, exhibiting less tardiness than the proposed method in settings with frequent releases and short deadlines. However, maintaining a balance between execution costs and tardiness becomes crucial when handling numerous tasks and longer deadlines. The effectiveness of the proposed method is evidenced in such scenarios despite operating online.\n"
    },
    {
        "level": "##",
        "title": "Vi. Conclusions",
        "content": "\nThis study addresses task deadlines by introducing a modified version of the MAPD problem, termed online MAPD- D. In online MAPD-D, tasks can be added at any time and assigned deadlines. To address MAPD-D, we propose two algorithms, namely D-TP and D-TPTS. D-TP allocates tasks by considering their pickup deadlines along with execution costs; meanwhile, D-TPTS facilitates task exchanges among agents and within a single agent. The conducted numerical experiments demonstrate that both D-TP and D-TPTS effectively reduce task tardiness compared to existing methods.\n\nThese experiments are conducted in a 35 \u00d7 21 grid environment; however, our ability to solve MAPD-D in larger environments is limited due to computational constraints. In the future, exploring the development of decentralized algorithms could enable the solution of large-scale MAPD- D. Additionally, algorithms should be devised to handle more realistic scenarios, such as paths being obstructed by uncertain obstacles [19].\n"
    },
    {
        "level": "##",
        "title": "Acknowledgments",
        "content": "\nWe thank Kenji Ito, Keisuke Otaki, and Yasuhiro Yogo for their insightful inputs and discussions.\n"
    },
    {
        "level": "##",
        "title": "References",
        "content": "\n[1] R. Stern, N. Sturtevant, A. Felner, S. Koenig, H. Ma, T. Walker, J. Li,\nD. Atzmon, L. Cohen, T. K. Kumar, R. Bart\u00b4ak, and E. Boyarski,\n\"Multi-Agent Pathfinding: Definitions, Variants, and Benchmarks,\" in Proceedings of the International Symposium on Combinatorial Search, vol. 10, 2019, pp. 151\u2013158.\n[2] O. Salzman and R. Stern, \"Research Challenges and Opportunities\nin Multi-Agent Path Finding and Multi-Agent Pickup and Delivery\nProblems,\" in Proceedings of the International Joint Conference on Autonomous Agents and Multiagent Systems, 2020, pp. 1711\u20131715.\n[3] P. R. Wurman, R. D'Andrea, and M. Mountz, \"Coordinating Hundreds\nof Cooperative, Autonomous Vehicles in Warehouses.\" *AI Magazine*, vol. 29, no. 1, pp. 9\u201320, 2008.\n[4] W. Honig, S. Kiesel, A. Tinka, J. W. Durham, and N. Ayanian,\n\"Persistent and Robust Execution of MAPF Schedules in Warehouses,\" IEEE Robotics and Automation Letters, vol. 4, no. 2, pp. 1125\u20131131, 2019.\n[5] K. Dresner and P. Stone, \"A Multiagent Approach to Autonomous\nIntersection Management,\" *Journal of Artificial Intelligence Research*,\nvol. 31, pp. 591\u2013656, 2008.\n[6] A. Okoso, K. Otaki, and T. Nishi, \"Multi-Agent Path Finding with\nPriority for Cooperative Automated Valet Parking,\" in 2019 IEEE\nIntelligent Transportation Systems Conference (ITSC), 2019, pp. 2135\u2013 2140.\n[7] J. Li, H. Zhang, M. Gong, Z. Liang, W. Liu, Z. Tong, L. Yi, R. Morris,\nC. Pasareanu, and S. Koenig, \"Scheduling and Airport Taxiway Path Planning Under Uncertainty,\" in Proceedings of the 2019 Aviation and Aeronautics Forum and Exposition, 2019, pp. 1\u20138.\n[8] D. Silver, \"Cooperative Pathfinding,\" in Proceedings of the AAAI Conference on Artificial Intelligence and Interactive Digital Entertainment,\nvol. 1, 2005, pp. 117\u2013122.\n[9] H. Ma, J. Li, T. K. S. Kumar, and S. Koenig, \"Lifelong Multi-Agent\nPath Finding for Online Pickup and Delivery Tasks,\" in Proceedings\nof the International Joint Conference on Autonomous Agents and\nMultiagent Systems, 2017, pp. 837\u2013845.\n[10] H. Ma, W. H\u00a8onig, T. K. S. Kumar, N. Ayanian, and S. Koenig, \"Lifelong path planning with kinematic constraints for multi-agent pickup and delivery,\" in Proceedings of the AAAI Conference on Artificial Intelligence, ser. AAAI'19/IAAI'19/EAAI'19, 2019, pp. 7651\u20137658.\n[11] M. Liu, H. Ma, J. Li, and S. Koenig, \"Task and Path Planning for\nMulti-Agent Pickup and Delivery,\" in Proceedings of the International\nJoint Conference on Autonomous Agents and Multiagent Systems,\n2019, pp. 1152\u20131160.\n[12] J. Li, A. Tinka, S. Kiesel, J. W. Durham, T. K. S. Kumar, and\nS. Koenig, \"Lifelong Multi-Agent Path Finding in Large-Scale Warehouses,\" in Proceedings of the AAAI Conference on Artificial Intelligence, vol. 35, 2021, pp. 11 272\u201311 281.\n[13] H. A. Aryadi, R. Bezerra, K. Ohno, K. Gunji, S. Kojima, M. Kuwahara, Y. Okada, M. Konyo, and S. Tadokoro, \"Multi-Agent Pickup and Delivery in Transformable Production,\" in Proceedings of the\n2023 IEEE 19th International Conference on Automation Science and\nEngineering (CASE), 2023, pp. 1\u20138.\n[14] X. Wu, Y. Liu, X. Tang, W. Cai, F. Bai, G. Khonstantine, and\nG. Zhao, \"Multi-Agent Pickup and Delivery with Task Deadlines,\" in Proceedings of the International Symposium on Combinatorial Search,\nvol. 12, 2021, pp. 206\u2013208.\n[15] S. Ramanathan, Y. Liu, X. Tang, W. Cai, and J. Li, \"Minimising Task\nTardiness for Multi-Agent Pickup and Delivery,\" in Proceedings of the\n2023 International Conference on Autonomous Agents and Multiagent\nSystems, 2023, pp. 2349\u20132351.\n[16] H. Ma, G. Wagner, A. Felner, J. Li, T. K. S. Kumar, and S. Koenig,\n\"Multi-Agent Path Finding with Deadlines,\" in Proceedings of the\nTwenty-Seventh International Joint Conference on Artificial Intelligence (IJCAI-18), 2018, pp. 417\u2013423.\n[17] H. Wang and W. Chen, \"Multi-Robot Path Planning With Due Times,\"\nIEEE Robotics and Automation Letters, vol. 7, no. 2, pp. 4829\u20134836, 2022.\n[18] T. Huang, V. Shivashankar, M. Caldara, J. Durham, J. Li, B. Dilkina,\nand S. Koenig, \"Deadline-Aware Multi-Agent Tour Planning,\" in\nProceedings of the International Conference on Automated Planning\nand Scheduling, vol. 33, 2023, pp. 189\u2013197.\n[19] B. Shofer, G. Shani, and R. Stern, \"Multi Agent Path Finding under\nObstacle Uncertainty,\" in Proceedings of the International Conference on Automated Planning and Scheduling, vol. 33, 2023, pp. 402\u2013410."
    }
]